{"chunk_id": "AVGO_TRANSCRIPT_2025_Q1_chunk_0000", "doc_id": "AVGO_TRANSCRIPT_2025_Q1", "source_units": ["AVGO_TRANSCRIPT_2025_Q1_u_0000", "AVGO_TRANSCRIPT_2025_Q1_u_0001", "AVGO_TRANSCRIPT_2025_Q1_u_0002"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q1.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q1", "period": "2025-Q1", "section_id": null, "section_title": null, "speaker": "Charlie Kawwas", "speaker_role": "President", "phase": "prepared_remarks", "chunk_tokens": 800, "start_token": 0, "end_token": 800, "chunk_type": "windowed_overlap", "overlap_with_prev": 0, "overlap_with_next": 120, "text": "financial performance for the first quarter of fiscal year 2025. If you did not receive a copy, you may obtain the information from the investors section of\nBroadcom's website at broadcom.com. This conference call is being webcast live, and an audio replay of the call can be accessed for one year through the\ninvestors section of Broadcom's website. During the prepared comments, Hock and Kirsten will be providing details of our first quarter fiscal year 2025 results,\nguidance for our second quarter of fiscal year 2025, as well as commentary regarding the business environment. We will take questions after the end of our\nprepared comments. Please refer to our press release today and our recent filings with the SEC for information on the specific risk factors that could cause our\nactual results to differ materially from the forward-looking statements made on this call. In addition to US GAAP reporting, Broadcom reports certain financial\nmeasures on a non-GAAP basis. A reconciliation between GAAP and non-GAAP measures is included in the tables attached to today's press release. Comments\nmade during today's call will primarily refer to our non-GAAP financial results. I'll now turn the call over to Hock. Thank you, Gu. And thank you everyone for joining today. In our fiscal Q1 2025, total revenue was a record $14.9 billion, up 25% year on year. And consolidated\nadjusted EBITDA was a record again, $10.1 billion, up 41% year on year. So let me first provide color on our semiconductor business. Q1 semiconductor revenue\nwas $8.2 billion, 11% year on year. Growth was driven by AI, as AI revenue of $4.1 billion was up 77% year on year. We repeat our guidance for AI revenue of\n$3.8 billion due to stronger shipments of networking solutions to hyperscalers on AI. Our hyperscale partners continue to invest aggressively in the next\ngeneration Frontier models, which do require high-performance accelerators as well as AI data centers with larger clusters. Consistent with this, we are stepping\nup our R&D investment on two fronts. One, we're pushing the envelope of technology in creating the next generation of accelerators. We're taping out the\nindustry's first two-nanometer AI XPU packaging 3.5D, as we drive towards a 10,000 teraflops XPU. Secondly, we have a view towards scaling clusters of\n500,000 accelerators for hyperscale customers. We have doubled the radix capacity of this of the existing Tomahawk 5. And beyond this, to enable AI clusters to\nscale up on Ethernet towards one million XPUs. We have taped out our next-generation 100 terabit Tomahawk 6 switch running 200G SerDes and 1.6 terabit\nbandwidth. We will be delivering samples to customers within the next few months. These R&D investments are very aligned with the roadmap of our three\nhyperscale customers as they each race towards one million XPU clusters by the end of 2027. And, accordingly, we do reaffirm what we said last quarter, that we\nexpect these three hyperscale customers will generate a serviceable addressable market or SAM in the range of $60 to $90 billion in fiscal 2027. Beyond these\nthree customers, we had also mentioned previously that we are deeply engaged with two other hyperscalers in enabling them to create their own customized AI\naccelerator. We are on track to tape out their XPUs this year. In the process of working with the hyperscalers, it has become very clear that while they are\nexcellent in software, Broadcom is the best in hardware. Working together is what optimizes large language models. It is therefore no surprise to us since our last\nearnings call", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q1_chunk_0001", "doc_id": "AVGO_TRANSCRIPT_2025_Q1", "source_units": ["AVGO_TRANSCRIPT_2025_Q1_u_0000", "AVGO_TRANSCRIPT_2025_Q1_u_0001", "AVGO_TRANSCRIPT_2025_Q1_u_0002"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q1.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q1", "period": "2025-Q1", "section_id": null, "section_title": null, "speaker": "Charlie Kawwas", "speaker_role": "President", "phase": "prepared_remarks", "chunk_tokens": 800, "start_token": 680, "end_token": 1480, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 120, "text": " the range of $60 to $90 billion in fiscal 2027. Beyond these\nthree customers, we had also mentioned previously that we are deeply engaged with two other hyperscalers in enabling them to create their own customized AI\naccelerator. We are on track to tape out their XPUs this year. In the process of working with the hyperscalers, it has become very clear that while they are\nexcellent in software, Broadcom is the best in hardware. Working together is what optimizes large language models. It is therefore no surprise to us since our last\nearnings call, the two additional hyperscalers have selected Broadcom to develop custom accelerators to train their next-generation Frontier models. So even as\nwe have three hyperscale customers, we are shipping XPUs in volume today. There are now four more who are deeply engaged with us to create their own\naccelerators. And to be clear, of course, these four are not included in our estimated SAM of $60 billion to $90 billion in 2027. So we do see an exciting trend\nhere. New Frontier models and techniques put unexpected pressures on AI systems. It's difficult to serve all classes of models with a single system design point.\nAnd therefore, it is hard to imagine that a general-purpose accelerator can be configured and optimized across multiple Frontier models. And as I mentioned\nbefore, the trend towards XPUs is a multiyear journey. So coming back to 2025, we see a steady ramp in deployment of all our XPUs and networking products.\nSo Q1 AI revenue was $4.1 billion, and we expect Q2 AI revenue to grow to $4.4 billion, which is up 44% year on year. Turning to non-AI semiconductors,\nrevenue of $4.1 billion was down 9% sequentially on a seasonal decline in wireless. In aggregate, during Q1, the recovery in non-AI semiconductors continues to\nbe slow. Broadband, which bottomed in Q4 2024, showed a double-digit sequential recovery in Q1 and is expected to be up similarly in Q2 as service providers\nand telcos step up spending. Server storage was down single digits sequentially in Q1 but is expected to be up high single digits sequentially in Q2. Meanwhile,\nenterprise networking continues to remain flattish in the first half of fiscal 2025 as customers continue to work through channel inventory. Wireless was down\nsequentially due to a seasonal decline. It remained flat year on year. In Q2, wireless is expected to be the same, flat again year on year. Resales in industrial\nwere down double digits in Q1 and are expected to be down in Q2. So reflecting the foregoing puts and takes, we expect non-AI semiconductor revenue in Q2 to\nbe flattish sequentially even though we are seeing bookings continue to grow year on year. In summary, for Q2, we expect total semiconductor revenue to grow\n2% sequentially and up 17% year on year to $8.4 billion. Turning now to infrastructure software. Q1 infrastructure software revenue of $6.7 billion was up 47%\nyear on year and up 15% sequentially, exaggerated though by deals which slipped from Q4 to Q1. Now this is the first quarter Q1 2025 where the year on year\ncomparables include VMware in both quarters. We're seeing significant growth in the software segment for two reasons. One, we're converting from a footprint of\nlargely perpetual licenses to one of full subscription. And as of today, we are over 60% done. Two, these perpetual licenses were only largely for virtualization,\notherwise called vSphere. We are upselling customers to a full stack VCF, which enables the entire data center to be virtualized and enables customers to create\ntheir own private cloud environment on-pre", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q1_chunk_0002", "doc_id": "AVGO_TRANSCRIPT_2025_Q1", "source_units": ["AVGO_TRANSCRIPT_2025_Q1_u_0000", "AVGO_TRANSCRIPT_2025_Q1_u_0001", "AVGO_TRANSCRIPT_2025_Q1_u_0002"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q1.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q1", "period": "2025-Q1", "section_id": null, "section_title": null, "speaker": "Charlie Kawwas", "speaker_role": "President", "phase": "prepared_remarks", "chunk_tokens": 800, "start_token": 1360, "end_token": 2160, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 120, "text": " first quarter Q1 2025 where the year on year\ncomparables include VMware in both quarters. We're seeing significant growth in the software segment for two reasons. One, we're converting from a footprint of\nlargely perpetual licenses to one of full subscription. And as of today, we are over 60% done. Two, these perpetual licenses were only largely for virtualization,\notherwise called vSphere. We are upselling customers to a full stack VCF, which enables the entire data center to be virtualized and enables customers to create\ntheir own private cloud environment on-prem. And as of the end of Q1, approximately 70% of our largest 10,000 customers have adopted VCF. As these\ncustomers consume VCF, we do see a further opportunity for future growth. As large enterprises adopt AI, they have to run their AI workloads on their on-prem\ndata centers, which will include both GPU servers as well as traditional CPUs. And just as VCF virtualizes these traditional data centers using CPUs, VCM will\nalso virtualize GPUs on a common platform and then enable enterprises to import AI models to run their own data on-prem. This platform, which virtualizes the\nGPU, is called the VMware Private AI Foundation. And as of today, in collaboration with NVIDIA, we have 39 enterprise customers for the VMware Private AI\nFoundation. Customer demand has been driven by our open ecosystem, superior load balancing, and automation capabilities, which allow them to intelligently\npool and run workloads across both GPU and CPU infrastructure, leading to very reduced costs. Moving on to Q2 outlook for software, we expect revenue of $6.5\nbillion, up 23% year on year. So in total, we're guiding Q2 consolidated revenue to be approximately $14.9 billion, up 19% year on year. And we expect this will\ndrive Q2 adjusted EBITDA to approximately 66% of revenue. With that, let me turn the call over to Kirsten. Thank you, Hock. Let me now provide additional detail on our Q1 financial performance. From a year on year comparable basis, keep in mind that Q1 of fiscal\n2024 was a 14-week quarter and Q1 of fiscal 2025 is a 13-week quarter. Consolidated revenue was $14.9 billion for the quarter, up 25% from a year ago. Gross\nmargin was 79.1% of revenue in the quarter, better than we originally guided on higher infrastructure software revenue and more favorable semiconductor\nrevenue mix. Consolidated operating expenses were $2 billion, of which $1.4 billion was for R&D. Q1 operating income of $9.8 billion was up 44% from a year\nago with operating margin at 66% of revenue. Adjusted EBITDA was a record $10.1 billion or 68% of revenue, above our guidance of 66%. This figure excludes\n$142 million of depreciation. Now a review of the P&L for our two segments. Starting with semiconductors. Revenue for our semiconductor solutions segment was\n$8.2 billion and represented 55% of total revenue in the quarter. This was up 11% year on year. Gross margin for our semiconductor solutions segment was\napproximately 68%, up 70 basis points year on year driven by revenue mix. Operating expenses increased 3% year on year to $890 million on increased\ninvestment in R&D for leading-edge AI semiconductors, resulting in semiconductor operating margin of 57%. Now moving on to infrastructure software. Revenue\nfor infrastructure software of $6.7 billion was 45% and up 47% year on year based primarily on increased revenue from VMware. Gross margin for infrastructure\nsoftware was 92.5% in the quarter compared to 88%", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q1_chunk_0003", "doc_id": "AVGO_TRANSCRIPT_2025_Q1", "source_units": ["AVGO_TRANSCRIPT_2025_Q1_u_0000", "AVGO_TRANSCRIPT_2025_Q1_u_0001", "AVGO_TRANSCRIPT_2025_Q1_u_0002"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q1.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q1", "period": "2025-Q1", "section_id": null, "section_title": null, "speaker": "Charlie Kawwas", "speaker_role": "President", "phase": "prepared_remarks", "chunk_tokens": 800, "start_token": 2040, "end_token": 2840, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 120, "text": " for our semiconductor solutions segment was\napproximately 68%, up 70 basis points year on year driven by revenue mix. Operating expenses increased 3% year on year to $890 million on increased\ninvestment in R&D for leading-edge AI semiconductors, resulting in semiconductor operating margin of 57%. Now moving on to infrastructure software. Revenue\nfor infrastructure software of $6.7 billion was 45% and up 47% year on year based primarily on increased revenue from VMware. Gross margin for infrastructure\nsoftware was 92.5% in the quarter compared to 88% a year ago. Operating expenses were approximately $1.1 billion in the quarter, resulting in infrastructure\nsoftware operating margin of 76%. This compares to operating margin of 59% a year ago. This year on year improvement reflects our disciplined integration of\nVMware and sharp focus on deploying our VCF strategy. Moving on to cash flow. Free cash flow in the quarter was $6 billion and represented 40% of revenue.\nFree cash flow as a percentage of revenue continues to be impacted by cash interest expense from debt related to the VMware acquisition and cash taxes due to\nthe mix of US taxable income, the continued delay in the reenactment of section 174, and the impact of Corporate AMT. We spent $100 million on capital\nexpenditures. Day sales outstanding were 30 days in the first quarter compared to 41 days a year ago. We ended the first quarter with inventory of $1.9 billion, up\n8% sequentially, to support revenue in future quarters. Our days of inventory on hand were 65 days in Q1 as we continue to remain disciplined on how we\nmanage inventory across the ecosystem. We ended the first quarter with $9.3 billion of cash and $68.8 billion of gross principal debt. During the quarter, we\nrepaid $495 million of fixed-rate debt and $7.6 billion of floating-rate debt with new senior notes, commercial paper, and cash on hand, reducing debt by a net\n$1.1 billion. Following these actions, the weighted average coupon rate and years to maturity of our $58.8 billion in fixed-rate debt is 3.8% and 7.3 years\nrespectively. The weighted average coupon rate and years to maturity of our $6 billion in floating-rate debt is 5.4% and 3.8 years respectively. And our $4 billion\nin commercial paper is at an average rate of 4.6%. Turning to capital allocation. In Q1, we paid stockholders $2.8 billion of cash dividends based on a quarterly\ncommon stock cash dividend of $59 per share. We spent $2 billion to repurchase 8.7 million AVGO shares from employees as those shares vested or withholding\ntaxes. In Q2, we expect the non-GAAP diluted share count to be approximately 4.95 billion shares. Now moving on to guidance. Our guidance for Q2 is for\nconsolidated revenue of $14.9 billion with semiconductor revenue of approximately $8.4 billion, up 17% year on year. We expect Q2 AI revenue of $4.4 billion, up\n44% year on year. For non-AI semiconductors, we expect Q2 revenue of $4 billion. We expect Q2 infrastructure software revenue of approximately $6.5 billion,\nup 23% year on year. We expect Q2 adjusted EBITDA to be about 66%. For modeling purposes, we expect Q2 consolidated gross margin to be down\napproximately 20 basis points sequentially on the revenue mix of infrastructure software. As Hock discussed earlier, we are increasing our R&D investment in\nleading-edge AI in Q2 and accordingly, we expect adjusted EBITDA to be approximately 66%. We expect the non-GAAP tax rate", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q1_chunk_0004", "doc_id": "AVGO_TRANSCRIPT_2025_Q1", "source_units": ["AVGO_TRANSCRIPT_2025_Q1_u_0000", "AVGO_TRANSCRIPT_2025_Q1_u_0001", "AVGO_TRANSCRIPT_2025_Q1_u_0002"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q1.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q1", "period": "2025-Q1", "section_id": null, "section_title": null, "speaker": "Charlie Kawwas", "speaker_role": "President", "phase": "prepared_remarks", "chunk_tokens": 240, "start_token": 2720, "end_token": 2960, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 0, "text": " we expect Q2 revenue of $4 billion. We expect Q2 infrastructure software revenue of approximately $6.5 billion,\nup 23% year on year. We expect Q2 adjusted EBITDA to be about 66%. For modeling purposes, we expect Q2 consolidated gross margin to be down\napproximately 20 basis points sequentially on the revenue mix of infrastructure software. As Hock discussed earlier, we are increasing our R&D investment in\nleading-edge AI in Q2 and accordingly, we expect adjusted EBITDA to be approximately 66%. We expect the non-GAAP tax rate for Q2 and fiscal year 2025 to\nbe approximately 14%. That concludes my prepared remarks. Operator, we will now open for questions.\nOperator\nThank you. As a reminder, to ask a question, you will need to press star one one on your telephone. To withdraw your question, press star one one again. Due to\ntime restraints, we ask that you please limit yourself to one question. Please standby while we compile the Q&A roster. And our first question will come from the\nline of Ben Reitzes with Melius. Your line is open.", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q1_chunk_0005", "doc_id": "AVGO_TRANSCRIPT_2025_Q1", "source_units": ["AVGO_TRANSCRIPT_2025_Q1_u_0006", "AVGO_TRANSCRIPT_2025_Q1_u_0007"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q1.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q1", "period": "2025-Q1", "section_id": null, "section_title": null, "speaker": "Harlan Sur", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 347, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Good afternoon, and great job on the strong quarterly results, Hock and team. Great to see the continual momentum in the AI business here in the first half of\nyour fiscal year, and the continued broadening out of your AI ASIC customers. I know, Hock, last earnings, you did call out a strong ramp in the second half of the\nfiscal year, driven by new three-nanometer AI accelerated programs kinda ramping. You just help us either qualitatively, quantitatively, profile the second half step\nup relative to what the team just delivered here in the first half? Has the profile changed? Either favorably less favorably versus what you thought, maybe ninety\ndays ago because quite frankly, I mean, a lot has happened since last earnings. Right? You've had the dynamics like deep seek and focus on AI model efficiency.\nBut on the flip side, you've had strong CapEx outlooks by your cloud and hyperscale customers. So any color on the second half AI profile would be helpful. You're asking me to look into the minds of my customers. And I hate to tell you they don't tell me, they don't show me the entire mindset here. But one why are we\nbeating the numbers so far in Q1? Seems to be encouraging in Q2. Pardon me? From improved networking shipments, as I indicate that's to foster those XPUs\nand AI accelerators even in some cases GPUs together, for the hyperscalers. And that's good. And partly, also, we think there is some pull-ins of shipments and\nacceleration, call it that way, of shipments yes, in fiscal 2025.", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q1_chunk_0006", "doc_id": "AVGO_TRANSCRIPT_2025_Q1", "source_units": ["AVGO_TRANSCRIPT_2025_Q1_u_0008", "AVGO_TRANSCRIPT_2025_Q1_u_0009"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q1.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q1", "period": "2025-Q1", "section_id": null, "section_title": null, "speaker": "Harlan Sur", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 55, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "And on the second half, that you talked about ninety days ago, the second half three-nanometer ramp, is that still very much on track? Alan, thank you. I only got you two. Sorry. Let me let's not speculate on the second half.", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q1_chunk_0007", "doc_id": "AVGO_TRANSCRIPT_2025_Q1", "source_units": ["AVGO_TRANSCRIPT_2025_Q1_u_0010", "AVGO_TRANSCRIPT_2025_Q1_u_0012"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q1.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q1", "period": "2025-Q1", "section_id": null, "section_title": null, "speaker": "Harlan Sur", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 800, "start_token": 0, "end_token": 800, "chunk_type": "windowed_overlap", "overlap_with_prev": 0, "overlap_with_next": 120, "text": "Okay. Thank you, Hock.\nOperator\nThank you. One moment for our next question. And that will come from the line of William Stein with Truist Securities. Your line is open. You post a very interesting set of issues and questions. And those are very relevant interesting issues. And don't need issue the only problem we have at this\npoint is I would say it's really toward to no way we're all linked. I mean, there's the threat, the noise of tariffs, especially on chips, that has a material lines in it. Nor\ndo we know how it will be structured. So we don't know. But we do experience and we are leaving it now. Is the disruption on that is paused in a positive way. I\nshould add a very positive disruption in semiconductors, on a generative AI. Generative AI for sure. And we I said that before, so at the risk of repeating, you\nknow, but it's we feel it more than ever. Is really accelerating the development of semiconductor technology. Both process and packaging as well as design.\nTowards higher and higher performance accelerators and networking functionality. We've seen that innovation that those upgrades occur on a every month. As\nwe face new interesting challenges. And when particularly with XPUs. We're trying within as to optimize to Frontier models of our partners, our customers, as well\nas our hyperscale partners. And we it's a lot of I mean, it's a it's a privilege almost for us to be to participate in it and try to optimize. And by optimize, I mean, you\nlook at an accelerator. You can look at it for simple terms, high level, to to perform, to want to maybe mention not just on one single mentoring, which is compute\ncapacity, how many teraflops? It's more than that. It's also tied to the fact that this is a distributed computing problem. It's not just the sing the compute capacity of\na single XPU or GPU. It's also the network bandwidth. It ties itself to the next adjacent XPU or GPU. So that has an impact. So you're doing that. You'll have the\nbalance with that. Then you decide, are you doing training or you're doing prefilling? Post training. Fine tuning. And again then comes how much memory do you\nbalance against that? And with it, how much latency you can afford, which is memory bandwidth. So you will look at the at least four variables, maybe even five. If\nyou're in clone in memory bandwidth. Not just memory capacity, when you go straight to inference. So we we have all these variables to play with and we try to\noptimize it. So all this is very, very I mean, it's a great experience for our engineers to push their envelope on how to create all those chips and so that's the\nbiggest disruption we see right now. From sheer trying to create and push the envelope on generative AI. Trying to create the best hardware infrastructure to run\nit. Beyond that, yeah, there are there are other things too that come into play because with AI, as I indicated, just not just drive hardware for enterprises, it drives\nthe way the architect their data centers. You know, data requirement they keep keeping data private on on under control becomes important. So suddenly, the\npush of what loads towards public cloud. May take a little pause as large enterprises particularly, have to they have to take direct device that you want to run AI\nworkloads. You're probably thinking very hard about running them on-prem. And suddenly, push yourself to a saying, got to upgrade your own data centers. To\ndo you know, and manage the your own data to run it on-prem. And that's also pushing a trend that with we have been seeing now over the past", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q1_chunk_0008", "doc_id": "AVGO_TRANSCRIPT_2025_Q1", "source_units": ["AVGO_TRANSCRIPT_2025_Q1_u_0010", "AVGO_TRANSCRIPT_2025_Q1_u_0012"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q1.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q1", "period": "2025-Q1", "section_id": null, "section_title": null, "speaker": "Harlan Sur", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 238, "start_token": 680, "end_token": 918, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 0, "text": " requirement they keep keeping data private on on under control becomes important. So suddenly, the\npush of what loads towards public cloud. May take a little pause as large enterprises particularly, have to they have to take direct device that you want to run AI\nworkloads. You're probably thinking very hard about running them on-prem. And suddenly, push yourself to a saying, got to upgrade your own data centers. To\ndo you know, and manage the your own data to run it on-prem. And that's also pushing a trend that with we have been seeing now over the past twelve months.\nHence, my comments on VMware Private AI Foundation. This is to especially enterprises pushing direction at quickly recognizing that how where do they run\ntheir AI workloads. So those are trends we see today and a lot of it coming out of AI, a lot of it coming out of sensitive rules on sovereignty, in cloud and in data.\nOn as far as you're mentioning tariffs is concerned, I think that's too early for us to figure out where to online. And probably maybe give it another three, six\nmonths we probably have a better idea where to go.", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q1_chunk_0009", "doc_id": "AVGO_TRANSCRIPT_2025_Q1", "source_units": ["AVGO_TRANSCRIPT_2025_Q1_u_0014", "AVGO_TRANSCRIPT_2025_Q1_u_0015"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q1.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q1", "period": "2025-Q1", "section_id": null, "section_title": null, "speaker": "Ross Seymore", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 502, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "May I speak to a ask a question. I want to go back to the XPU side of things. And going from the four new engagements, not yet named customers, two last\nquarter and two more today that you announced. I wanna talk about going from kind of design winded deployment. How do you judge that? Because there is\nsome debate about, you know, tons of design wins, but the deployments actually don't happen either that they never occur or that the volume is never what is\noriginally promised. How do you view that kind of conversion ratio with there a wide range around it? Or is there some way you could help us kind of understand\nhow that works? Well, it's and, Ross, the interesting question I'll take the opportunity to say the way we look at designing is probably very different from the way many of our peers\nlook at it out there. Number one, to begin with, we believe design win when we know our product is at in produced in scale, at scale and is actually deployed.\nLiterally deployed in production. So that takes a long lead time because from taping out getting in the product, it takes a year. Easily from the product in the\nhands. Of our partner to when it goes into scale production, it will take six months to a year. It's our experience that we've seen. Number one and number two. I\nmean, producing and deploying five thousand SKUs that's that's a joke. That's not real production in my in our view. And so we also limit ourselves in selecting\npartners to people who really need that large volume. You need that large volume from our viewpoint in scale right now. In mostly framing, training of large\nlanguage models from tier models in a continuing trajectory. So we limit ourselves to how many customers or how many potential customers that exist out there,\nRoss. And we tend to be very selective who we pick. The beginning. So when we say design win, it really is at scale. It's not something that starts in six months\nand die or a year and die again. Basically, it's a selection of custom. It just the way we run our ASIC business in general for the last fifteen years. We pick and\nchoose the customers because we know this guy and we do multi multi-year roadmaps with these customers because we know these customers are sustainable.\nI put it bluntly. We don't do it for start-ups.", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q1_chunk_0010", "doc_id": "AVGO_TRANSCRIPT_2025_Q1", "source_units": ["AVGO_TRANSCRIPT_2025_Q1_u_0016"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q1.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q1", "period": "2025-Q1", "section_id": null, "section_title": null, "speaker": "Ross Seymore", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 33, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Thank you.\nOperator\nAnd one moment for our next question. And that will come from the line of Stacy Rasgon with Bernstein Research. Your line is open.", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q1_chunk_0011", "doc_id": "AVGO_TRANSCRIPT_2025_Q1", "source_units": ["AVGO_TRANSCRIPT_2025_Q1_u_0017", "AVGO_TRANSCRIPT_2025_Q1_u_0018"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q1.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q1", "period": "2025-Q1", "section_id": null, "section_title": null, "speaker": "Stacy Rasgon", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 167, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Hi, guys. Thanks for taking my question. I wanted to go to the three customers that you do have in volume today. And what I wanted to ask was is there any\nconcern about some of the new regulations or the AI diffusion rules that are gonna get put in place supposedly in May impacting any of those design wins or\nshipments. It sounds like you think all three of those are still on at this point. But anything you could tell us about worries about new regulations or AI diffusions\nimpacting any of those wins would be helpful. Thank you. In this era or this current era of geopolitical tensions, and fairly dramatic actions all around by governments, yes, always some concern at the back of\neverybody's mind. But to answer your question directly, no. We don't have any concerns.", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q1_chunk_0012", "doc_id": "AVGO_TRANSCRIPT_2025_Q1", "source_units": ["AVGO_TRANSCRIPT_2025_Q1_u_0019", "AVGO_TRANSCRIPT_2025_Q1_u_0020"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q1.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q1", "period": "2025-Q1", "section_id": null, "section_title": null, "speaker": "Stacy Rasgon", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 30, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Got it. So none of those are going into China? Or to Chinese customers then? No comment. Are you trying to locate who they are?", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q1_chunk_0013", "doc_id": "AVGO_TRANSCRIPT_2025_Q1", "source_units": ["AVGO_TRANSCRIPT_2025_Q1_u_0021"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q1.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q1", "period": "2025-Q1", "section_id": null, "section_title": null, "speaker": "Stacy Rasgon", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 43, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Okay. That's helpful. Thank you.\nOperator\nThank you. One moment for our next question. And that will come from the line of Vivek Arya with Bank of America. Your line is open.", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q1_chunk_0014", "doc_id": "AVGO_TRANSCRIPT_2025_Q1", "source_units": ["AVGO_TRANSCRIPT_2025_Q1_u_0022", "AVGO_TRANSCRIPT_2025_Q1_u_0023"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q1.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q1", "period": "2025-Q1", "section_id": null, "section_title": null, "speaker": "Vivek Arya", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 305, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Thanks for taking my question. Hock, whenever you have described your AI opportunity, you've always emphasized the training workload. But the perception is\nthat the AI market could be dominated by the inference workload, especially with these new reasoning models. So what happens to your opportunity and share if\nthe mix moves more towards inference, does it, you know, does it create a bigger TAM you than the $60 to $90 billion? You know, does it keep it the same, but is\nthere is a different mix of product? Or does a more inference-heavy market favor a GPU over an XPU? Thank you. That's a good interesting question. By the way, I never I do talk a lot about training. We do out check our experience as also focus on inference as a separate \nproduct line. They do. And that's why I can say the architecture of those chips are very different from the architecture of the training chips. And so it's a \ncombination of those two, I should add. That adds up to this $60 to $90 billion. So if I had not been clear I do apologize. It's a combination of both. But having said\n\nthat, the larger part of the dollars come from training. Not inference. If within the server service, the same that we have talked about so far. Thank you.\nOperator\nOne moment for our next question. And that will come from the line of Harsh Kumar with Piper Sandler. Your line is open.", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q1_chunk_0015", "doc_id": "AVGO_TRANSCRIPT_2025_Q1", "source_units": ["AVGO_TRANSCRIPT_2025_Q1_u_0024", "AVGO_TRANSCRIPT_2025_Q1_u_0025"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q1.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q1", "period": "2025-Q1", "section_id": null, "section_title": null, "speaker": "Harsh Kumar", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 574, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Thanks, Broadcom team. And again, great execution. Just talk had a quick question. We've been hearing that almost all of the large clusters that are 100k plus\nthey're all going to Ethernet. I was wondering if you could help us understand the importance of when the customer's making a selection, you know, choosing\nbetween a guy that has the best switch ASICs such as you, versus a guy that might have to compute there. Can you talk about what the customer is thinking and\nwhat are the final points that they wanna hit upon when they make that selection for the mixed cards? Okay. I see. No. It's a com yeah. It's down to in the in the case of the in the case of the hyperscalers, now very much so, it's very driven by performance. And it's\nperformance what you're mentioning about on connecting scaling up, and scaling out those AI accelerators, be they XPU or GPU. Among extra scalers. And in\nmain most cases, among those hyperscalers we engage with, when it comes to connecting those clusters. They're very driven. By performance. I mean, you if\nyou are in the race to really get the best performance out of your hardware as you train and continue to train your Frontier models, that matters more than\nanything else. So the basic first thing they go for is proven. That's a proven piece of hardware is a proven net it's a proven system subsystem in our case that\nmakes it work. And in that case, we tend to have a big advantage. Because, I mean, networking is ours. You know, switching and routing is ours for the last ten\nyears at least. And the fact that it's AI just makes it more interesting for our engineers to work on. And but it's basically based on proven technology and\nexperience in pushing that and pushing the envelope on going from 800 gigabit per second bandwidth to 1.6 and moving on to 3.2, which is exactly why we keep\nstepping up the rate of investment in coming up with our products where we take a ton of five. We doubled the radix to deal with just one hyperscaler because\nthey want high radix to create larger clusters while running, bandwidth that are smaller but that doesn't stop us from moving ahead to the next generation of\nTomahawk 6 and I dare say, we even planning to come out 7 and 8 right now. And we're speeding up the rate of development. And it's all actually for that few\nguys, by the way. So we're making a lot of investment for very few customers, hopefully, with very large serve available markets. That's if I'm nothing else, that's\nthe big bets we are placing.", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q1_chunk_0016", "doc_id": "AVGO_TRANSCRIPT_2025_Q1", "source_units": ["AVGO_TRANSCRIPT_2025_Q1_u_0026"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q1.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q1", "period": "2025-Q1", "section_id": null, "section_title": null, "speaker": "Harsh Kumar", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 38, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Thank you, Hock.\nOperator\nThank you. One moment for our next question. And that will come from the line of Timothy Arcuri with UBS. Your line is open.", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q1_chunk_0017", "doc_id": "AVGO_TRANSCRIPT_2025_Q1", "source_units": ["AVGO_TRANSCRIPT_2025_Q1_u_0027", "AVGO_TRANSCRIPT_2025_Q1_u_0028"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q1.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q1", "period": "2025-Q1", "section_id": null, "section_title": null, "speaker": "Timothy Arcuri", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 216, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Thanks a lot. Hock, in the past, you have mentioned XPU units growing from about two million last year to about seven million, you said, in the 2027, 2028 time\nframe. My question is, do these four new customers, do they add to that seven million unit number? I know in the past, you sort of talked about an ASP. It was,\nyou know, twenty grand by then. So those three the first three customers are clearly a subset of that seven million units. So do these new four engagements drive\nthat seven higher, or do they just fill in to get to that seven million? Thanks. Thanks, Tim, for asking that. To clarify, as I made I thought I made it clear in my comments. No. The market we're talking about include when you translate the\nunit it's only among the three customers we have today. The other four, we talk about engagement partners, we don't consider that as customers yet, and\ntherefore, are not in our served available market.", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q1_chunk_0018", "doc_id": "AVGO_TRANSCRIPT_2025_Q1", "source_units": ["AVGO_TRANSCRIPT_2025_Q1_u_0029", "AVGO_TRANSCRIPT_2025_Q1_u_0030"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q1.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q1", "period": "2025-Q1", "section_id": null, "section_title": null, "speaker": "Timothy Arcuri", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 605, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Okay. So they would add to that number. Okay. Thanks, Hock.\nOperator\nThanks. One moment for our next question. And that will come from the line of CJ Muse with Cantor Fitzgerald. Your line is open.\nCJ Muse\nYeah. Good afternoon. Thank you for taking the question. I guess, I'll have to follow-up on your prepared remarks and comments earlier around optimization with\nyour best hardware and hyperscalers with their great software. I'm curious how you're expanding your portfolio now to six mega scale kind of frontier models. Will\nenable you to, you know, a more plush, you know, share tremendous information, but at the same time, a world where these six truly wanna differentiate. So,\nobviously, you know, the goal for all of these players is exaflops, per second per dollar of capex per watt. And I guess to what degree are you aiding them in these\nefforts? And where does maybe the Chinese wall kinda start where they wanna kinda differentiate and not share with you kind of some of the work that you're\ndoing. You. Oh, you know, we only provide very base basic fundamental technology in semiconductors to enable these guys to use what we have and optimize it to their \nown particular models. And algorithms that relate to those models. That's it. That's all we do. So that's the level of a lot of that optimization we do for each of \nthem. And as I mentioned earlier, there are maybe five degrees of freedom. Yeah. We do. And we play with that. And so even if there are five degrees of \nfreedom, there's only so much we can do at that point. But it is and how did you and then basically, how we optimize it is all tied to the partner telling us how they\n\nwant to do to do it. So that's only so much we also have visibility on. But it's but it's what we do now is what the XPU model is. She optimization translating to\nperformance but also power. That's very important how they play. It's not just cost. The power come translates into total cost of ownership. Eventually. It's it's how\ndesign it in power and how we balance it in terms of the size of the cluster and whether they use it for training. No. Pretraining? Post training? Inference you\nknow, time test time scaling, all of them have their own characteristics. And that's the advantage of doing that XPU and working closely with them to create that\nstuff. Now as far as your question on China and all that, frankly, I don't have any opinion on that at all. To us, it's a technical game.\nCJ Muse\nThank you very much.\nOperator\nOne moment for our next question. And that will come from the line of Christopher Rolland with Susquehanna. Your line is open.", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q1_chunk_0019", "doc_id": "AVGO_TRANSCRIPT_2025_Q1", "source_units": ["AVGO_TRANSCRIPT_2025_Q1_u_0036", "AVGO_TRANSCRIPT_2025_Q1_u_0037"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q1.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q1", "period": "2025-Q1", "section_id": null, "section_title": null, "speaker": "Vijay Rakesh", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 215, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Yeah. Hi. Thanks. Thanks. Just a question on the networking side. Just wondering how much does up sequentially on the AI side? And any thoughts around M&A\ngoing forward? Still a lot of headlines around the include products, Blue Care, so thanks. On the networking side, as indicated, Q1 showed a bit of a surge. But I don't expect that to be that mix of sixty-forty-sixty is compute and forty percent networking\nto be something that is normal? I think the norm is closer to seventy, thirty, maybe. At best, thirty percent. And so who knows what Q2 is? We cannot see Q2 as\ncontinuing but that's just, at my mind, a temporary flip. The norm will be seventy thirty. If you take it across, a period of time, like six months, a year, that's your\nquestion. M&A, no. I'm too busy we're too busy doing AI and VMware at this point. We're not thinking of it. At this point.", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q1_chunk_0020", "doc_id": "AVGO_TRANSCRIPT_2025_Q1", "source_units": ["AVGO_TRANSCRIPT_2025_Q1_u_0038"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q1.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q1", "period": "2025-Q1", "section_id": null, "section_title": null, "speaker": "Vijay Rakesh", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 150, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Thanks, Hock.\n\nOperator\nThank you. That is all the time we have for our question and answer session. I would now like to turn the call back over to Gu for any closing remarks.\nGu\nThank you, Sherry. Broadcom currently plans to report its earnings for the second quarter of fiscal year 2025 after close of market on Thursday, June 5th, 2025. A\npublic webcast of Broadcom's earnings conference call will follow at 2 PM Pacific. That will conclude our earnings call today. Thank you all for joining. Sherry, you\nmay end the call.\nOperator\nThank you. Ladies and gentlemen, thank you for participating. This concludes today's program. You may now disconnect.", "chunked_at": "2025-11-10T02:19:46Z"}
