{"chunk_id": "META_TRANSCRIPT_2023_Q4_chunk_0000", "doc_id": "META_TRANSCRIPT_2023_Q4", "source_units": ["META_TRANSCRIPT_2023_Q4_u_0000", "META_TRANSCRIPT_2023_Q4_u_0001", "META_TRANSCRIPT_2023_Q4_u_0002", "META_TRANSCRIPT_2023_Q4_u_0003", "META_TRANSCRIPT_2023_Q4_u_0004", "META_TRANSCRIPT_2023_Q4_u_0005", "META_TRANSCRIPT_2023_Q4_u_0006", "META_TRANSCRIPT_2023_Q4_u_0007", "META_TRANSCRIPT_2023_Q4_u_0008", "META_TRANSCRIPT_2023_Q4_u_0009", "META_TRANSCRIPT_2023_Q4_u_0010", "META_TRANSCRIPT_2023_Q4_u_0011", "META_TRANSCRIPT_2023_Q4_u_0012", "META_TRANSCRIPT_2023_Q4_u_0013", "META_TRANSCRIPT_2023_Q4_u_0014", "META_TRANSCRIPT_2023_Q4_u_0015", "META_TRANSCRIPT_2023_Q4_u_0016", "META_TRANSCRIPT_2023_Q4_u_0017", "META_TRANSCRIPT_2023_Q4_u_0018", "META_TRANSCRIPT_2023_Q4_u_0019", "META_TRANSCRIPT_2023_Q4_u_0020", "META_TRANSCRIPT_2023_Q4_u_0021", "META_TRANSCRIPT_2023_Q4_u_0022"], "source_uri": "data/earnings_calls_manual/META/META_FY2023_Q4.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2023, "quarter": "Q4", "period": "2023-Q4", "section_id": null, "section_title": null, "speaker": "Ken Dorell", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 800, "start_token": 0, "end_token": 800, "chunk_type": "windowed_overlap", "overlap_with_prev": 0, "overlap_with_next": 120, "text": "Thank you. Good afternoon and welcome to Meta Platform's Fourth Quarter and Full Year 2023 Earnings Conference Call. Joining me today to discuss our\nresults are Mark Zuckerberg, CEO; and Susan Li, CFO. Before we get started, I would like to take this opportunity to remind you that our remarks today will\ninclude forward-looking statements. Actual results may differ materially from those contemplated by these forward-looking statements. Factors that could cause\nthese results to differ materially are set forth in today's earnings press release and in our quarterly report on Form 10-Q filed with the SEC. Any forward-looking\nstatements that we make on this call are based on assumptions as of today, and we undertake no obligation to update these statements as a result of new\ninformation or future events. During this call, we will present both GAAP and certain non-GAAP financial measures. A reconciliation of GAAP to non-GAAP\nmeasures is included in today's earnings press release. The earnings press release and an accompanying investor presentation are available on our website at\ninvestor.fb.com. And now I'd like to turn the call over to Mark. All right. Hi, everyone. Thanks for joining us. This was a good quarter, and it wrapped up an important year for our community and our company. We estimate that \nthere are more than 3.1 billion people who use at least one of our apps each day. 2023 was our year of efficiency, which focused on making Meta a stronger \ntechnology company and improving our business to give us the stability to deliver our ambitious long-term vision for AI and the metaverse. And last year, not only \ndid we achieve our efficiency goals, but we returned to strong revenue growth, saw strong engagement across our apps; shipped a number of exciting new \nproducts like Threads, Ray-Ban Meta smart glasses and mixed reality in Quest 3; and of course, established a world-class AI effort that's going to be the \nfoundation for many of our future products. I think that being a leaner company is helping us execute better and faster, and we will continue to carry these values \nforward as a permanent part of how we operate. Now moving forward, a major goal, we'll be building the most popular and most advanced AI products and \nservices. And if we succeed, everyone who uses our services will have a world-class AI assistant to help get things done, every creator will have an AI that their \ncommunity can engage with, every business will have an AI that their customers can interact with to buy goods and get support, and every developer will have a \nstate-of-the-art open-source model to build with. I also think that everyone will want a new category of computing devices that let you frictionlessly interact with \nAIs that can see what you see and hear what you hear, like smart glasses. And one thing that became clear to me in the last year is that this next generation of \nservices requires building full general intelligence. Previously, I thought that because many of the tools were social-, commerce- or maybe media-oriented that it \nmight be possible to deliver these products by solving only a subset of AI's challenges. But now it's clear that we're going to need our models to be able to \nreason, plan, code, remember and many other cognitive abilities in order to provide the best versions of the services that we envision. We've been working on \ngeneral intelligence research and FAIR for more than a decade. But now general intelligence will be the theme of our product work as well. Meta has a long \nhistory of building new technologies into our services, and we have a clear long-term playbook for becoming leaders. And there are a few key aspects of this that I \nwant to take some time to go through today. The first is world-class compute infrastructure. I recently shared that, by the end of this year, we'll have about \n350,000 H", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2023_Q4_chunk_0001", "doc_id": "META_TRANSCRIPT_2023_Q4", "source_units": ["META_TRANSCRIPT_2023_Q4_u_0000", "META_TRANSCRIPT_2023_Q4_u_0001", "META_TRANSCRIPT_2023_Q4_u_0002", "META_TRANSCRIPT_2023_Q4_u_0003", "META_TRANSCRIPT_2023_Q4_u_0004", "META_TRANSCRIPT_2023_Q4_u_0005", "META_TRANSCRIPT_2023_Q4_u_0006", "META_TRANSCRIPT_2023_Q4_u_0007", "META_TRANSCRIPT_2023_Q4_u_0008", "META_TRANSCRIPT_2023_Q4_u_0009", "META_TRANSCRIPT_2023_Q4_u_0010", "META_TRANSCRIPT_2023_Q4_u_0011", "META_TRANSCRIPT_2023_Q4_u_0012", "META_TRANSCRIPT_2023_Q4_u_0013", "META_TRANSCRIPT_2023_Q4_u_0014", "META_TRANSCRIPT_2023_Q4_u_0015", "META_TRANSCRIPT_2023_Q4_u_0016", "META_TRANSCRIPT_2023_Q4_u_0017", "META_TRANSCRIPT_2023_Q4_u_0018", "META_TRANSCRIPT_2023_Q4_u_0019", "META_TRANSCRIPT_2023_Q4_u_0020", "META_TRANSCRIPT_2023_Q4_u_0021", "META_TRANSCRIPT_2023_Q4_u_0022"], "source_uri": "data/earnings_calls_manual/META/META_FY2023_Q4.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2023, "quarter": "Q4", "period": "2023-Q4", "section_id": null, "section_title": null, "speaker": "Ken Dorell", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 800, "start_token": 680, "end_token": 1480, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 120, "text": " the best versions of the services that we envision. We've been working on \ngeneral intelligence research and FAIR for more than a decade. But now general intelligence will be the theme of our product work as well. Meta has a long \nhistory of building new technologies into our services, and we have a clear long-term playbook for becoming leaders. And there are a few key aspects of this that I \nwant to take some time to go through today. The first is world-class compute infrastructure. I recently shared that, by the end of this year, we'll have about \n350,000 H100s, and including other GPUs, that will be around 600,000 H100 equivalents of compute. We're well positioned now because of the lessons that we \nlearned from Reels. We initially underbuilt our GPU clusters for Reels. And when we were going through that, I decided that we should build enough capacity to \nsupport both Reels and another Reels-sized AI service that we expected to emerge so we wouldn't be in that situation again. And at the time, the decision was \nsomewhat controversial, and we faced a lot of questions about CapEx spending, but I'm really glad that we did this. Now going forward, we think that training and \noperating future models will be even more compute-intensive. We don't have a clear expectation for exactly how much this will be yet, but the trend has been that \nstate-of-the-art large language models have been trained on roughly 10x the amount of compute each year. And our training clusters are only part of our overall \ninfrastructure, and the rest, obviously, isn't growing as quickly. But overall, we're playing to win here, and I expect us to continue investing aggressively in this \narea. In order to build the most advanced clusters, we're also designing novel data centers and designing our own custom silicons specialized for our workloads. \nThe second part of our playbook is open-source software infrastructure. Our long-standing strategy has been to build an open-source general infrastructure while \nkeeping our specific product implementations proprietary. In the case of AI, the general infrastructure includes our Llama models, including Llama 3, which is \ntraining now, and it's looking great so far, as well as industry standard tools like PyTorch that we've developed. And this approach to open source has unlocked a \nlot of innovation across the industry, and it's something that we believe in deeply. And I know that some people have questions about how we benefit from open \nsourcing, the results of our research and large amounts of compute. So I thought it might be useful to lay out the strategic benefits here. The short version is that \nopen sourcing improves our models. And because there's still significant work to turn our models into products because there will be other open-source models \navailable anyway, we find that there are mostly advantages to being the open-source leader, and it doesn't remove differentiation for our products much anyway. \nAnd more specifically, there are several strategic benefits. First, open-source software is typically safer and more secure as well as more compute-efficient to \noperate due to all the ongoing feedback, scrutiny and development from the community. Now this is a big deal because safety is one of the most important issues \nin AI. Efficiency improvements and lowering the compute costs also benefit everyone, including us. Second, open-source software often becomes an industry \nstandard. And when companies standardize on building with our stack, that then becomes easier to integrate new innovations into our products. That's subtle, but \nthe ability to learn and improve quickly is a huge advantage. And being an industry standard enables that. Third, open source is hugely popular with developers \nand researchers. And we know that people want to work on open systems that will be widely adopted. So this helps us recruit the best people at Meta, which is a \nvery big deal", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2023_Q4_chunk_0002", "doc_id": "META_TRANSCRIPT_2023_Q4", "source_units": ["META_TRANSCRIPT_2023_Q4_u_0000", "META_TRANSCRIPT_2023_Q4_u_0001", "META_TRANSCRIPT_2023_Q4_u_0002", "META_TRANSCRIPT_2023_Q4_u_0003", "META_TRANSCRIPT_2023_Q4_u_0004", "META_TRANSCRIPT_2023_Q4_u_0005", "META_TRANSCRIPT_2023_Q4_u_0006", "META_TRANSCRIPT_2023_Q4_u_0007", "META_TRANSCRIPT_2023_Q4_u_0008", "META_TRANSCRIPT_2023_Q4_u_0009", "META_TRANSCRIPT_2023_Q4_u_0010", "META_TRANSCRIPT_2023_Q4_u_0011", "META_TRANSCRIPT_2023_Q4_u_0012", "META_TRANSCRIPT_2023_Q4_u_0013", "META_TRANSCRIPT_2023_Q4_u_0014", "META_TRANSCRIPT_2023_Q4_u_0015", "META_TRANSCRIPT_2023_Q4_u_0016", "META_TRANSCRIPT_2023_Q4_u_0017", "META_TRANSCRIPT_2023_Q4_u_0018", "META_TRANSCRIPT_2023_Q4_u_0019", "META_TRANSCRIPT_2023_Q4_u_0020", "META_TRANSCRIPT_2023_Q4_u_0021", "META_TRANSCRIPT_2023_Q4_u_0022"], "source_uri": "data/earnings_calls_manual/META/META_FY2023_Q4.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2023, "quarter": "Q4", "period": "2023-Q4", "section_id": null, "section_title": null, "speaker": "Ken Dorell", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 409, "start_token": 1360, "end_token": 1769, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 0, "text": " lowering the compute costs also benefit everyone, including us. Second, open-source software often becomes an industry \nstandard. And when companies standardize on building with our stack, that then becomes easier to integrate new innovations into our products. That's subtle, but \nthe ability to learn and improve quickly is a huge advantage. And being an industry standard enables that. Third, open source is hugely popular with developers \nand researchers. And we know that people want to work on open systems that will be widely adopted. So this helps us recruit the best people at Meta, which is a \nvery big deal for leading in any new technology area. And again, we typically have unique data and build unique product integrations anyway, so providing \ninfrastructure like Llama as open source doesn't reduce our main advantage. This is why our long-standing strategy has been to open source general \ninfrastructure and why I expect it to continue to be the right approach for us going forward. The next part of our playbook is just taking a long-term approach \ntowards the development. While we're working on today's products and models, we're also working on the research that we need to advance for Llama 5, 6 and 7 \nin the coming years and beyond to develop full general intelligence. It's important to have a portfolio of multiyear investments in research projects, but it's also \nimportant to have clear launch vehicles like future Llama models that help focus our work. We've worked on general intelligence in our lab, FAIR, for more than a \ndecade, as I mentioned, and we produced a lot of valuable work. But having clear product targets for delivering general intelligence really focuses this work and \nhelps us build the leading research program. Now the next key part of our playbook is learning from unique data and feedback loops in our products. When \npeople think about data, they typically think about the corpus that you might use to train a model upfront. And on Facebook and Instagram, there are hundreds of", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2023_Q4_chunk_0003", "doc_id": "META_TRANSCRIPT_2023_Q4", "source_units": ["META_TRANSCRIPT_2023_Q4_u_0000", "META_TRANSCRIPT_2023_Q4_u_0001", "META_TRANSCRIPT_2023_Q4_u_0002", "META_TRANSCRIPT_2023_Q4_u_0003", "META_TRANSCRIPT_2023_Q4_u_0004", "META_TRANSCRIPT_2023_Q4_u_0005", "META_TRANSCRIPT_2023_Q4_u_0006", "META_TRANSCRIPT_2023_Q4_u_0007", "META_TRANSCRIPT_2023_Q4_u_0008", "META_TRANSCRIPT_2023_Q4_u_0009", "META_TRANSCRIPT_2023_Q4_u_0010", "META_TRANSCRIPT_2023_Q4_u_0011", "META_TRANSCRIPT_2023_Q4_u_0012", "META_TRANSCRIPT_2023_Q4_u_0013", "META_TRANSCRIPT_2023_Q4_u_0014", "META_TRANSCRIPT_2023_Q4_u_0015", "META_TRANSCRIPT_2023_Q4_u_0016", "META_TRANSCRIPT_2023_Q4_u_0017", "META_TRANSCRIPT_2023_Q4_u_0018", "META_TRANSCRIPT_2023_Q4_u_0019", "META_TRANSCRIPT_2023_Q4_u_0020", "META_TRANSCRIPT_2023_Q4_u_0021", "META_TRANSCRIPT_2023_Q4_u_0022"], "source_uri": "data/earnings_calls_manual/META/META_FY2023_Q4.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2023, "quarter": "Q4", "period": "2023-Q4", "section_id": null, "section_title": null, "speaker": "Ken Dorell", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 800, "start_token": 0, "end_token": 800, "chunk_type": "windowed_overlap", "overlap_with_prev": 0, "overlap_with_next": 120, "text": "billions of publicly shared images and tens of billions of public videos, which we estimate is greater than the common crawl data set. And people share large\nnumbers of public text posts and comments across our services as well. But even more important in the upfront training corpus is the ability to establish the right\nfeedback loops with hundreds of millions of people interacting with AI services across our products. And this feedback is a big part of how we've improved our AI\nsystems so quickly with Reels and Ads, especially over the last couple of years when we had to re-architect it around new rules. Now that brings me to the last\npart of our playbook for building leading services, which is our culture of rapid learning and experimentation across our apps. When we decide that a new\ntechnology, like AI-recommended Reels, is going to be an important part of the future, we're not shy about having multiple teams experimenting with different\nversions across our apps until we get it right. And then we learn what works and we roll it out to everyone. And there used to be this meme that we'd probably\nlaunch Stories on our Settings page at some point. And look, I think it's kind of funny because it gets to a core part of our approach. We start by learning and\ntuning our products until they perform the way we want, and then we roll them out very broadly. And sometimes, occasionally, products will blow up before we're\nready for them to, like Threads, although I'll note that Threads now has more people actively using it today than it did during its initial launch peak. So that one is,\nI think, on track to be a major success. But normally, we learn and we iterate methodically. And we started doing that with our AI services in the fall launching\nMeta AI, our assistant; AI Studio, which the precursor to Creator AIs; our Alpha with Business AIs; and the Ray-Ban Meta smart glasses. And we've been tuning\neach of these, and we're getting closer to rolling them out more widely. So you should expect that in the coming months. From there, we'll focus on rolling out\nservices until they reach hundreds of millions or billions of people. And usually, only when we reach that kind of scale do we start focusing on what monetization\nwill look like. And although in this case, the way the business AIs will help business messaging grow and WhatsApp, Messenger and Instagram is pretty clear. But\nthat's our basic approach, and I'm really excited about pointing our company at developing so many of these awesome things. Now we have 2 major parts of our\nlong-term vision, and in addition to AI, the other part is the metaverse. We've invested heavily in both AI and the metaverse for a long time, and we will continue\nto do so. These days, there are a lot of questions more about AI that I get, and that field is moving very quickly. But I still expect that this next generation of AR,\nVR and MR computing platforms to deliver a realistic sense of presence that will be the foundation for the future of social experiences and almost every other\ncategory of experiences as well. Reality Labs crossed $1 billion in revenue in Q4 for the first time with Quest having a strong holiday season. Quest 3 is off to a\nstrong start, and I expect it to continue to be the most popular mixed reality device. With Quest 3 and Quest 2 both performing well, we saw that the Quest app\nwas actually the most downloaded app in the App Store on Christmas Day. I want to give a shout-out to Asgard's Wrath2, which was developed by one of our\nin-house studios and received IGN's 10 out of 10 masterpiece rating, making it one of the best-rated games out there, not just in VR, but of any game on any\nplatform ever", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2023_Q4_chunk_0004", "doc_id": "META_TRANSCRIPT_2023_Q4", "source_units": ["META_TRANSCRIPT_2023_Q4_u_0000", "META_TRANSCRIPT_2023_Q4_u_0001", "META_TRANSCRIPT_2023_Q4_u_0002", "META_TRANSCRIPT_2023_Q4_u_0003", "META_TRANSCRIPT_2023_Q4_u_0004", "META_TRANSCRIPT_2023_Q4_u_0005", "META_TRANSCRIPT_2023_Q4_u_0006", "META_TRANSCRIPT_2023_Q4_u_0007", "META_TRANSCRIPT_2023_Q4_u_0008", "META_TRANSCRIPT_2023_Q4_u_0009", "META_TRANSCRIPT_2023_Q4_u_0010", "META_TRANSCRIPT_2023_Q4_u_0011", "META_TRANSCRIPT_2023_Q4_u_0012", "META_TRANSCRIPT_2023_Q4_u_0013", "META_TRANSCRIPT_2023_Q4_u_0014", "META_TRANSCRIPT_2023_Q4_u_0015", "META_TRANSCRIPT_2023_Q4_u_0016", "META_TRANSCRIPT_2023_Q4_u_0017", "META_TRANSCRIPT_2023_Q4_u_0018", "META_TRANSCRIPT_2023_Q4_u_0019", "META_TRANSCRIPT_2023_Q4_u_0020", "META_TRANSCRIPT_2023_Q4_u_0021", "META_TRANSCRIPT_2023_Q4_u_0022"], "source_uri": "data/earnings_calls_manual/META/META_FY2023_Q4.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2023, "quarter": "Q4", "period": "2023-Q4", "section_id": null, "section_title": null, "speaker": "Ken Dorell", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 800, "start_token": 680, "end_token": 1480, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 120, "text": "3 is off to a\nstrong start, and I expect it to continue to be the most popular mixed reality device. With Quest 3 and Quest 2 both performing well, we saw that the Quest app\nwas actually the most downloaded app in the App Store on Christmas Day. I want to give a shout-out to Asgard's Wrath2, which was developed by one of our\nin-house studios and received IGN's 10 out of 10 masterpiece rating, making it one of the best-rated games out there, not just in VR, but of any game on any\nplatform ever. So it's a really good sign that we're able to deliver that quality of work at Meta. Horizon is growing quickly, too. It is now on Top 10 Most Used Apps\non Quest, and we have an exciting road map ahead. This is another example of applying the long-term playbook that I discussed earlier with AI but in another\narea. We take the time to build up the core technology and tune the experience. And then when it's ready, we're good at growing things. Now our focus for this\nyear is going to be on growing the mobile version of Horizon as well as the VR One. Ray-Ban Meta smart glasses are also off to a very strong start, both in sales\nand engagement. Our partner, EssilorLuxottica is already planning on making more than we both expected due to high demand. Engagement and retention are\nalso significantly higher than the first version of the glasses. The experience is just a lot better with Meta AI in there as well as there's a higher resolution camera,\nbetter audio and more. And we also have an exciting road map of software improvements ahead, starting with rolling out multimodal AI and then some other really\nexciting new AI features later in the year. I said this before, but I think that people are going to want new categories of devices that seamlessly engage with AIs\nfrequently throughout the AI without having to take out your phone and press a button and point it at what you want to see. And I think that smart glasses are\ngoing to be a compelling form factor for this, and it's a good example of how our AI and metaverse visions are connected. In addition to AI in the metaverse, we're\ncontinuing to improve our Apps and Ads businesses as well. Reels and our discovery engine remain a priority and major driver of engagement, and Messaging\ncontinues to be our focus for building the next revenue pillar of our business before our longer-term work reaches scale. But since I went a bit longer in the other\nareas today, I'm just going to mention a few highlights here. Reels continues to do very well across both Instagram and Facebook. People re-share Reels 3.5\nbillion times every day. Reels is now contributing to our net revenue across our apps. The biggest opportunity going forward is unifying our recommendation\nsystems across Reels and other types of video that will help people discover the best content across our systems no matter what format it's in. WhatsApp is also\ndoing very well. And the most exciting new trend here is that it is succeeding more broadly in the United States, where there's a real appetite for a private, secure\nand cross-platform messaging app that everyone can use. And given the strategic importance of the U.S. and its outsized importance for revenue, this is just a\nhuge opportunity. Threads is also growing steadily with more than 130 million monthly actives. And I'm optimistic that we can keep the pace of improvements in\ngrowth going and show that a friendly, discussion-oriented app can be as widely used as the most popular social apps. All right. That's what I wanted to cover\ntoday. Our communities are growing, and our business is back on track. Once again, a big thank you to all of our employees, partners, shareholders and\neveryone", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2023_Q4_chunk_0005", "doc_id": "META_TRANSCRIPT_2023_Q4", "source_units": ["META_TRANSCRIPT_2023_Q4_u_0000", "META_TRANSCRIPT_2023_Q4_u_0001", "META_TRANSCRIPT_2023_Q4_u_0002", "META_TRANSCRIPT_2023_Q4_u_0003", "META_TRANSCRIPT_2023_Q4_u_0004", "META_TRANSCRIPT_2023_Q4_u_0005", "META_TRANSCRIPT_2023_Q4_u_0006", "META_TRANSCRIPT_2023_Q4_u_0007", "META_TRANSCRIPT_2023_Q4_u_0008", "META_TRANSCRIPT_2023_Q4_u_0009", "META_TRANSCRIPT_2023_Q4_u_0010", "META_TRANSCRIPT_2023_Q4_u_0011", "META_TRANSCRIPT_2023_Q4_u_0012", "META_TRANSCRIPT_2023_Q4_u_0013", "META_TRANSCRIPT_2023_Q4_u_0014", "META_TRANSCRIPT_2023_Q4_u_0015", "META_TRANSCRIPT_2023_Q4_u_0016", "META_TRANSCRIPT_2023_Q4_u_0017", "META_TRANSCRIPT_2023_Q4_u_0018", "META_TRANSCRIPT_2023_Q4_u_0019", "META_TRANSCRIPT_2023_Q4_u_0020", "META_TRANSCRIPT_2023_Q4_u_0021", "META_TRANSCRIPT_2023_Q4_u_0022"], "source_uri": "data/earnings_calls_manual/META/META_FY2023_Q4.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2023, "quarter": "Q4", "period": "2023-Q4", "section_id": null, "section_title": null, "speaker": "Ken Dorell", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 800, "start_token": 1360, "end_token": 2160, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 120, "text": " strategic importance of the U.S. and its outsized importance for revenue, this is just a\nhuge opportunity. Threads is also growing steadily with more than 130 million monthly actives. And I'm optimistic that we can keep the pace of improvements in\ngrowth going and show that a friendly, discussion-oriented app can be as widely used as the most popular social apps. All right. That's what I wanted to cover\ntoday. Our communities are growing, and our business is back on track. Once again, a big thank you to all of our employees, partners, shareholders and\neveryone in our community for sticking with us and for making 2023 such a success. I'm looking forward to another exciting year ahead. And now here's Susan. Thanks, Mark, and good afternoon, everyone. Let's begin with our consolidated results. All comparisons are on a year-over-year basis, unless otherwise noted. \nQ4 total revenue was $40.1 billion, up 25% or 22% on a constant currency basis. Q4 total expenses were $23.7 billion, down 8% compared to last year. In terms \nof the specific line items, cost of revenue decreased 8%, 0driven mainly by lower restructuring costs that were partially offset by higher infrastructure-related \ncosts. R&D increased 8% driven primarily by higher head count-related costs from Family of Apps and Reality Labs as well as higher non-head count-related \nReality Labs operating expenses, which were partially offset by lower restructuring costs. Marketing and sales decreased 29% due mainly to lower marketing \nspend and restructuring costs. G&A decreased 26% due mainly to lower restructuring expenses. We ended the fourth quarter with over 67,300 employees, down \n22% from a year ago while up 2% from Q3 as our hiring efforts have resumed. Fourth quarter operating income was $16.4 billion, representing a 41% operating \nmargin. Our tax rate for the quarter was 17%. Net income was $14 billion or $5.33 per share. Capital expenditures, including principal payments on finance \nleases, were $7.9 billion, driven by investments in servers, data centers and network infrastructure. Free cash flow was $11.5 billion, which reflects a $1.6 billion \npayment of income taxes deferred from prior quarters of 2023. We ended the year with $65.4 billion in cash and marketable securities and $18.4 billion in debt. In \nthe fourth quarter, we repurchased $6.3 billion of our Class A stock, bringing our total share repurchases for the full year to $20 billion. We had $30.9 billion \nremaining on our prior authorization as of December 31. And today, we announced a $50 billion increase in our stock repurchase authorization. Moving now to \nour segment results. I'll begin with our Family of Apps segment. In Q4, we saw continued community growth across the Family of Apps as well as Facebook, \nspecifically. We're sharing today that as previewed when we first introduced our family metrics, we are transitioning away from reporting Facebook-specific \nmetrics. As part of this transition, we will no longer report Facebook daily and monthly active users or family monthly active people. In Q1, we will instead begin \nreporting year-over-year changes in ad impressions and the average price per ad at the regional level while continuing to report family daily active people. For full \nyear 2023, Family of Apps total revenue was $133 billion and ad revenue was $131.9 billion, each up 16% year-over-year. The largest contributors to \nyear-over-year ad revenue growth were the online commerce, CPG, entertainment and media and gaming verticals. The online commerce and gaming verticals \nbenefited from strong demand by advertisers in China reaching people in other markets. In 2023", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2023_Q4_chunk_0006", "doc_id": "META_TRANSCRIPT_2023_Q4", "source_units": ["META_TRANSCRIPT_2023_Q4_u_0000", "META_TRANSCRIPT_2023_Q4_u_0001", "META_TRANSCRIPT_2023_Q4_u_0002", "META_TRANSCRIPT_2023_Q4_u_0003", "META_TRANSCRIPT_2023_Q4_u_0004", "META_TRANSCRIPT_2023_Q4_u_0005", "META_TRANSCRIPT_2023_Q4_u_0006", "META_TRANSCRIPT_2023_Q4_u_0007", "META_TRANSCRIPT_2023_Q4_u_0008", "META_TRANSCRIPT_2023_Q4_u_0009", "META_TRANSCRIPT_2023_Q4_u_0010", "META_TRANSCRIPT_2023_Q4_u_0011", "META_TRANSCRIPT_2023_Q4_u_0012", "META_TRANSCRIPT_2023_Q4_u_0013", "META_TRANSCRIPT_2023_Q4_u_0014", "META_TRANSCRIPT_2023_Q4_u_0015", "META_TRANSCRIPT_2023_Q4_u_0016", "META_TRANSCRIPT_2023_Q4_u_0017", "META_TRANSCRIPT_2023_Q4_u_0018", "META_TRANSCRIPT_2023_Q4_u_0019", "META_TRANSCRIPT_2023_Q4_u_0020", "META_TRANSCRIPT_2023_Q4_u_0021", "META_TRANSCRIPT_2023_Q4_u_0022"], "source_uri": "data/earnings_calls_manual/META/META_FY2023_Q4.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2023, "quarter": "Q4", "period": "2023-Q4", "section_id": null, "section_title": null, "speaker": "Ken Dorell", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 240, "start_token": 2040, "end_token": 2280, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 0, "text": " begin \nreporting year-over-year changes in ad impressions and the average price per ad at the regional level while continuing to report family daily active people. For full \nyear 2023, Family of Apps total revenue was $133 billion and ad revenue was $131.9 billion, each up 16% year-over-year. The largest contributors to \nyear-over-year ad revenue growth were the online commerce, CPG, entertainment and media and gaming verticals. The online commerce and gaming verticals \nbenefited from strong demand by advertisers in China reaching people in other markets. In 2023, revenue from China-based advertisers represented 10% of our \noverall revenue and contributed 5 percentage points to total worldwide revenue growth. Turning back to Q4 results. Q4 total Family of Apps revenue was $39 \nbillion, up 24% year-over-year. Q4 Family of Apps ad revenue was $38.7 billion, up 24% or 21% on a constant currency basis. Within ad revenue, the online \ncommerce vertical was the largest contributor to year-over-year growth, followed by CPG and gaming. On a user geography basis, ad revenue growth was", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2023_Q4_chunk_0007", "doc_id": "META_TRANSCRIPT_2023_Q4", "source_units": ["META_TRANSCRIPT_2023_Q4_u_0000", "META_TRANSCRIPT_2023_Q4_u_0001", "META_TRANSCRIPT_2023_Q4_u_0002", "META_TRANSCRIPT_2023_Q4_u_0003", "META_TRANSCRIPT_2023_Q4_u_0004", "META_TRANSCRIPT_2023_Q4_u_0005", "META_TRANSCRIPT_2023_Q4_u_0006", "META_TRANSCRIPT_2023_Q4_u_0007", "META_TRANSCRIPT_2023_Q4_u_0008", "META_TRANSCRIPT_2023_Q4_u_0009", "META_TRANSCRIPT_2023_Q4_u_0010", "META_TRANSCRIPT_2023_Q4_u_0011", "META_TRANSCRIPT_2023_Q4_u_0012", "META_TRANSCRIPT_2023_Q4_u_0013", "META_TRANSCRIPT_2023_Q4_u_0014", "META_TRANSCRIPT_2023_Q4_u_0015", "META_TRANSCRIPT_2023_Q4_u_0016", "META_TRANSCRIPT_2023_Q4_u_0017", "META_TRANSCRIPT_2023_Q4_u_0018", "META_TRANSCRIPT_2023_Q4_u_0019", "META_TRANSCRIPT_2023_Q4_u_0020", "META_TRANSCRIPT_2023_Q4_u_0021", "META_TRANSCRIPT_2023_Q4_u_0022"], "source_uri": "data/earnings_calls_manual/META/META_FY2023_Q4.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2023, "quarter": "Q4", "period": "2023-Q4", "section_id": null, "section_title": null, "speaker": "Ken Dorell", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 800, "start_token": 0, "end_token": 800, "chunk_type": "windowed_overlap", "overlap_with_prev": 0, "overlap_with_next": 120, "text": "strongest in Europe and Rest of World at 33% and 32%, respectively, followed by Asia Pacific at 23% and North America at 19%. Foreign currency was a tailwind \nto advertising revenue growth in all international regions. In Q4, the total number of ad impressions served across our services increased 21%, and the average \nprice per ad increased 2%. Impression growth was mainly driven by Asia Pacific and Rest of World. Pricing growth was driven by advertiser demand and currency \ntailwinds, which were partially offset by strong impression growth, particularly from lower-monetizing services and regions. Family of Apps other revenue was \n$334 million in Q4, up 82%, driven by business messaging revenue growth from our WhatsApp Business platform. We continue to direct the majority of our \ninvestments toward the development and operation of our Family of Apps. In Q4, Family of Apps expenses were $18 billion, representing approximately 76% of \nour overall expenses. Family of Apps expenses were down 13% due to lower restructuring expenses. Family of Apps operating income was $21 billion, \nrepresenting a 54% operating margin. Within our Reality Labs segment, Q4 revenue was $1.1 billion, up 47%, driven by Quest 3 sales during the holiday season. \nReality Labs expenses were $5.7 billion, up 14% year-over-year due primarily to higher head count-related expenses and non-head count-related R&D spend. \nReality Labs operating loss was $4.6 billion. Turning now to the business outlook. There are 2 primary factors that drive our revenue performance: our ability to \ndeliver engaging experiences for our community and our effectiveness at monetizing that engagement over time. On the first, we remain pleased with \nengagement trends and have strong momentum across our product priorities. We're seeing sustained growth in Reels and Video overall as daily watch time \nacross all video types grew over 25% year-over-year in Q4, driven by ongoing ranking improvements. In-feed recommendations of posts from accounts you're not \nconnected to also continue to drive incremental engagement as we increasingly personalize recommendations, and we expect to deliver further improvements \nthis year. On Instagram, we're making strong progress increasing the freshness of recommended content. And a big focus for Facebook this year will be unifying \nour video experiences and ranking across the app, which should create a more seamless user experience and deliver increasingly relevant video \nrecommendations. On WhatsApp, community growth remains strong, and we're seeing good traction with our Channels product, which has quickly scaled to over \n500 million monthly active users since we rolled it out globally in September. We are also making good progress in areas that have the potential to grow people's \nengagement with our products in the longer term, such as Threads and generative AI. On Threads, we're coming into 2024 with strong product momentum and \nremain focused on introducing additional valuable features and further scaling the community this year. With generative AI, we fully rolled out our Meta AI \nassistant and other AI chat experiences in the U.S. at the end of the year and began testing more than 20 GenAI features across our Family of Apps. Our big \nareas of focus in 2024 will be working towards the launch of Llama 3, expanding the usefulness of our Meta AI assistant and progressing on our AI Studio road \nmap to make it easier for anyone to create an AI. For the experiences in our apps, we'll follow our typical approach of making them great before we lean into \ngrowth and eventually monetization. But this continues to be an exciting area that has the potential to transform how people engage on our services in the years \nahead. Now to the second driver of our revenue performance, increasing monetization efficiency. There are 2 parts to this work. The first part is growing the level \nof ad inventory within organic engagement. Our", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2023_Q4_chunk_0008", "doc_id": "META_TRANSCRIPT_2023_Q4", "source_units": ["META_TRANSCRIPT_2023_Q4_u_0000", "META_TRANSCRIPT_2023_Q4_u_0001", "META_TRANSCRIPT_2023_Q4_u_0002", "META_TRANSCRIPT_2023_Q4_u_0003", "META_TRANSCRIPT_2023_Q4_u_0004", "META_TRANSCRIPT_2023_Q4_u_0005", "META_TRANSCRIPT_2023_Q4_u_0006", "META_TRANSCRIPT_2023_Q4_u_0007", "META_TRANSCRIPT_2023_Q4_u_0008", "META_TRANSCRIPT_2023_Q4_u_0009", "META_TRANSCRIPT_2023_Q4_u_0010", "META_TRANSCRIPT_2023_Q4_u_0011", "META_TRANSCRIPT_2023_Q4_u_0012", "META_TRANSCRIPT_2023_Q4_u_0013", "META_TRANSCRIPT_2023_Q4_u_0014", "META_TRANSCRIPT_2023_Q4_u_0015", "META_TRANSCRIPT_2023_Q4_u_0016", "META_TRANSCRIPT_2023_Q4_u_0017", "META_TRANSCRIPT_2023_Q4_u_0018", "META_TRANSCRIPT_2023_Q4_u_0019", "META_TRANSCRIPT_2023_Q4_u_0020", "META_TRANSCRIPT_2023_Q4_u_0021", "META_TRANSCRIPT_2023_Q4_u_0022"], "source_uri": "data/earnings_calls_manual/META/META_FY2023_Q4.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2023, "quarter": "Q4", "period": "2023-Q4", "section_id": null, "section_title": null, "speaker": "Ken Dorell", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 800, "start_token": 680, "end_token": 1480, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 120, "text": " usefulness of our Meta AI assistant and progressing on our AI Studio road \nmap to make it easier for anyone to create an AI. For the experiences in our apps, we'll follow our typical approach of making them great before we lean into \ngrowth and eventually monetization. But this continues to be an exciting area that has the potential to transform how people engage on our services in the years \nahead. Now to the second driver of our revenue performance, increasing monetization efficiency. There are 2 parts to this work. The first part is growing the level \nof ad inventory within organic engagement. Our approach to optimizing ad levels in our apps has become increasingly sophisticated over the years as we've \ndeveloped a better understanding of the optimal place, time and person to show an ad, which has enabled us to adopt a more dynamic approach to serving apps. \nWe expect to continue that work going forward, while services with relatively lower levels of monetization like video and messaging will serve as additional growth \nopportunities. The other part to increasing monetization efficiency is improving marketing performance. To do this, we're focused on 3 areas. The first is AI. We \ncontinue to leverage AI across our ad systems and product suite. We're delivering continued performance gains from ranking improvements as we adopt larger \nand more advanced models, and this will remain an ongoing area of investment in 2024. We're also building out our Advantage+ portfolio of solutions to help \nadvertisers leverage AI to automate their advertising campaigns. Advertisers can choose to automate part of the campaign creation setup process, such as who \nto show their ad to with Advantage+ audience, or they can automate their campaign completely using Advantage+ shopping, which continues to see strong \ngrowth. We're also now exploring ways to apply this end-to-end automation to new objectives. On the ads creative side, we completed the global rollout of 2 of \nour generative AI features in Q4, Text Variations and Image Expansion, and plan to broaden availability of our background generation feature later in Q1. Initial \nadoption of these features has been strong, and tests are showing promising early performance gains. This will remain a big area of focus for us in 2024. The \nsecond area of our work is helping businesses connect their marketing data and measure results. Here, we're continuing to invest in conversions API to make it \neasier for advertisers to not only adopt but maximize its impact. The last area is investing in new and engaging on-platform ad experiences. Business messaging \nremains a priority here. Click-to-message ads continue to grow, and we're seeing advertisers increasingly use these ads to drive down funnel conversions. Paid \nmessaging is growing quickly, and we are focused on broadening adoption in 2024 by making it easier for businesses to buy marketing messages and more \neasily adopt our Flows product to develop richer in-Thread experiences for consumers. We're also progressing with our early testing on WhatsApp and \nMessenger of AIs for businesses that can provide conversational support in chat. We'll take our time to get these experiences right, but we think this will be a \ncompelling opportunity that we're well positioned to deliver on. Outside of business messaging, we're making strong progress with our shops' ads products, which \ncrossed a $2 billion annual run rate in Q4. Next, I would like to discuss our approach to capital allocation. We are in the fortunate position of being able to invest in \nmany organic opportunities to improve the performance of our core business in the near term while also making 2 significant longer-time horizon investments in AI \nand Reality Labs. AI is a growing area of investment for us in 2024 as we hire to support our road map. We are also investing more in our AI infrastructure \ncapacity this year. And given many of our ambitious forward-looking plans will rely on having sufficient compute capacity, we expect this to", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2023_Q4_chunk_0009", "doc_id": "META_TRANSCRIPT_2023_Q4", "source_units": ["META_TRANSCRIPT_2023_Q4_u_0000", "META_TRANSCRIPT_2023_Q4_u_0001", "META_TRANSCRIPT_2023_Q4_u_0002", "META_TRANSCRIPT_2023_Q4_u_0003", "META_TRANSCRIPT_2023_Q4_u_0004", "META_TRANSCRIPT_2023_Q4_u_0005", "META_TRANSCRIPT_2023_Q4_u_0006", "META_TRANSCRIPT_2023_Q4_u_0007", "META_TRANSCRIPT_2023_Q4_u_0008", "META_TRANSCRIPT_2023_Q4_u_0009", "META_TRANSCRIPT_2023_Q4_u_0010", "META_TRANSCRIPT_2023_Q4_u_0011", "META_TRANSCRIPT_2023_Q4_u_0012", "META_TRANSCRIPT_2023_Q4_u_0013", "META_TRANSCRIPT_2023_Q4_u_0014", "META_TRANSCRIPT_2023_Q4_u_0015", "META_TRANSCRIPT_2023_Q4_u_0016", "META_TRANSCRIPT_2023_Q4_u_0017", "META_TRANSCRIPT_2023_Q4_u_0018", "META_TRANSCRIPT_2023_Q4_u_0019", "META_TRANSCRIPT_2023_Q4_u_0020", "META_TRANSCRIPT_2023_Q4_u_0021", "META_TRANSCRIPT_2023_Q4_u_0022"], "source_uri": "data/earnings_calls_manual/META/META_FY2023_Q4.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2023, "quarter": "Q4", "period": "2023-Q4", "section_id": null, "section_title": null, "speaker": "Ken Dorell", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 789, "start_token": 1360, "end_token": 2149, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 0, "text": " rate in Q4. Next, I would like to discuss our approach to capital allocation. We are in the fortunate position of being able to invest in \nmany organic opportunities to improve the performance of our core business in the near term while also making 2 significant longer-time horizon investments in AI \nand Reality Labs. AI is a growing area of investment for us in 2024 as we hire to support our road map. We are also investing more in our AI infrastructure \ncapacity this year. And given many of our ambitious forward-looking plans will rely on having sufficient compute capacity, we expect this to be an area we invest \nmore aggressively in over the coming years. Reality Labs is the other long-term initiative we continue to invest heavily in as we progress on our efforts to develop \nthe next computing platform. Aside from organic investments, returning capital to shareholders remains important to us. We believe our strong financial position \nand performance will enable us to invest in the business while also continuing to return capital to investors over time. We've historically done so through share \nrepurchases. And while we expect to maintain an active share repurchase program, we are modestly evolving our approach going forward by returning a portion \nof capital through a regular dividend subject to quarterly Board approval. In addition, we continue to monitor the active regulatory landscape, including the \nincreasing legal and regulatory headwinds in the EU and the U.S. that could significantly impact our business and our financial results. Of note, the FTC is \nseeking to substantially modify our existing consent order and impose additional restrictions on our ability to operate. We are contesting this matter, but if we are \nunsuccessful, it would have an adverse impact on our business. Turning now to the revenue outlook. We expect first quarter 2024 total revenue to be in the range \nof $34.5 billion to $37 billion. Our guidance assumes foreign currency is neutral to year-over-year total revenue growth based on current exchange rates. Turning \nnow to the expense outlook. We expect full year 2024 total expenses to be in the range of $94 billion to $99 billion, unchanged from our prior outlook. We \ncontinue to expect a few factors to be drivers of total expense growth in 2024. First, we expect higher infrastructure-related costs this year. Given our increased \ncapital investments in recent years, we expect depreciation expenses in 2024 to increase by a larger amount than in 2023. We also expect to incur higher \noperating costs from running a larger infrastructure footprint. Second, we anticipate growth in payroll expenses as we work down our current hiring underrun and \nadd incremental talent to support priority areas in 2024, which we expect will further shift our workforce composition toward higher-cost technical roles. Finally, for to further scale our ecosystem. Turning now to the CapEx outlook. We anticipate our full year 2024 capital expenditures will be in the range of $30 billion to $37 \nbillion, a $2 billion increase of the high end of our prior range. We expect growth will be driven by investments in servers, including both AI and non-AI hardware, \nand data centers as we ramp up construction on sites with our previously announced new data center architecture. Our updated outlook reflects our evolving \nunderstanding of our AI capacity demands as we anticipate what we may need for the next generations of foundational research and product development. While \nwe are not providing guidance for years beyond 2024, we expect our ambitious long-term AI research and product development efforts will require growing \ninfrastructure investments beyond this year. On to tax. Absent any changes to U.S. tax law, we expect our full year 2024 tax rate to be in the mid-teens. In \nclosing, this was a pivotal year for our company. We increased our operating discipline, delivered strong execution across our product priorities and improved", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2023_Q4_chunk_0010", "doc_id": "META_TRANSCRIPT_2023_Q4", "source_units": ["META_TRANSCRIPT_2023_Q4_u_0000", "META_TRANSCRIPT_2023_Q4_u_0001", "META_TRANSCRIPT_2023_Q4_u_0002", "META_TRANSCRIPT_2023_Q4_u_0003", "META_TRANSCRIPT_2023_Q4_u_0004", "META_TRANSCRIPT_2023_Q4_u_0005", "META_TRANSCRIPT_2023_Q4_u_0006", "META_TRANSCRIPT_2023_Q4_u_0007", "META_TRANSCRIPT_2023_Q4_u_0008", "META_TRANSCRIPT_2023_Q4_u_0009", "META_TRANSCRIPT_2023_Q4_u_0010", "META_TRANSCRIPT_2023_Q4_u_0011", "META_TRANSCRIPT_2023_Q4_u_0012", "META_TRANSCRIPT_2023_Q4_u_0013", "META_TRANSCRIPT_2023_Q4_u_0014", "META_TRANSCRIPT_2023_Q4_u_0015", "META_TRANSCRIPT_2023_Q4_u_0016", "META_TRANSCRIPT_2023_Q4_u_0017", "META_TRANSCRIPT_2023_Q4_u_0018", "META_TRANSCRIPT_2023_Q4_u_0019", "META_TRANSCRIPT_2023_Q4_u_0020", "META_TRANSCRIPT_2023_Q4_u_0021", "META_TRANSCRIPT_2023_Q4_u_0022"], "source_uri": "data/earnings_calls_manual/META/META_FY2023_Q4.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2023, "quarter": "Q4", "period": "2023-Q4", "section_id": null, "section_title": null, "speaker": "Ken Dorell", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 800, "start_token": 0, "end_token": 800, "chunk_type": "windowed_overlap", "overlap_with_prev": 0, "overlap_with_next": 120, "text": "advertising performance for businesses who rely on our services. We will look to build on our priorities in each of those areas in 2024 while advancing our\nambitious longer-term efforts in AI and Reality Labs. With that, Krista, let's open up the call for questions.\nOperator\n[Operator Instructions]. And your first question comes from the line of Brian Nowak from Morgan Stanley. I have two. I appreciate, Mark, the color about sort of the learnings and the data feedback loop. Let me ask you one about sort of the advertising business and all\nof the new machine learning and new GenAI ad tools that you built and rolled out the last year or so. Can you just talk about some of the largest areas of\nimprovement your advertisers say is really driving this inflection of advertising? And what are the areas where you still get the most feedback on for further areas\nof improvement in the ad business that we should think about? And then, Susan, maybe, one, the first quarter guide, specifically on the acceleration implied.\nAnything on -- more color on which surfaces or ad units or regions are sort of giving you confidence in that type of acceleration at this point in the quarter? Thank you, Brian. I can take both of those. On your first question, what is driving strength in the Ads business, we certainly believe that we've been continuing to\ndrive ad performance improvements and year-over-year conversion growth remains strong. And we see this reflected in the feedback that we hear from\nadvertisers also. There are really three areas of our work here that we're very focused on and have been and will continue to be in 2024. First, just creating\nengaging on-platform ad experiences. We see that with formats like click-to-message ads, where we continue to see good momentum. Shops ads, we talked\nabout the $2 billion annual run rate in Q4 after we just opened availability to all U.S. advertisers in Q2. Lead generation ads, another example. So we're really\nfocused on creating engaging on-platform ad experiences. Second, we're really making it easier for advertisers to connect with their marketing data. We're\ncontinuing to invest in features like conversions API, like AEM and making these features easier to adopt, enhancing reporting and other performance. And we've\nseen, again, that those are -- we get very positive feedback on advertisers who use those tools. And then finally, continuing to really use AI in important ways\nacross our ads platform. For a long time, we have invested in building larger and more advanced models that have resulted in more Accurate predictions of\nrelevant ads for people and improved performance for advertisers. And then, of course, we're investing a lot in AI-powered tools and products. So we're really\nscaling our Advantage+ suites across all of the different offerings there, which really helped to automate the ads creation process for different types of\nadvertisers. And we're getting very strong feedback on all of those different features, advantage+ Shopping, obviously, being the first, but Advantage+ Catalog,\nAdvantage+ Creative, Advantage+ Audiences, et cetera. So we feel like these are all really important parts of what has continued to grow improvements in our\nAds business and will continue to going forward. On your second question, which is about the Q1 year-over-year -- sorry, the Q1 revenue guide. This really just\nreflects a lot of the trends we saw in Q4, which is strong, broad-based advertising demand across verticals, particularly within online commerce and gaming. I'll\nalso note that we get the benefit from having February 29 in this quarter. And again, just the improvements that we continue to accrue to the business from all of\nour investments in improving ad performance over time.\nOperator\nYour next question comes from the line of Eric Sheridan from Goldman Sachs.", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2023_Q4_chunk_0011", "doc_id": "META_TRANSCRIPT_2023_Q4", "source_units": ["META_TRANSCRIPT_2023_Q4_u_0000", "META_TRANSCRIPT_2023_Q4_u_0001", "META_TRANSCRIPT_2023_Q4_u_0002", "META_TRANSCRIPT_2023_Q4_u_0003", "META_TRANSCRIPT_2023_Q4_u_0004", "META_TRANSCRIPT_2023_Q4_u_0005", "META_TRANSCRIPT_2023_Q4_u_0006", "META_TRANSCRIPT_2023_Q4_u_0007", "META_TRANSCRIPT_2023_Q4_u_0008", "META_TRANSCRIPT_2023_Q4_u_0009", "META_TRANSCRIPT_2023_Q4_u_0010", "META_TRANSCRIPT_2023_Q4_u_0011", "META_TRANSCRIPT_2023_Q4_u_0012", "META_TRANSCRIPT_2023_Q4_u_0013", "META_TRANSCRIPT_2023_Q4_u_0014", "META_TRANSCRIPT_2023_Q4_u_0015", "META_TRANSCRIPT_2023_Q4_u_0016", "META_TRANSCRIPT_2023_Q4_u_0017", "META_TRANSCRIPT_2023_Q4_u_0018", "META_TRANSCRIPT_2023_Q4_u_0019", "META_TRANSCRIPT_2023_Q4_u_0020", "META_TRANSCRIPT_2023_Q4_u_0021", "META_TRANSCRIPT_2023_Q4_u_0022"], "source_uri": "data/earnings_calls_manual/META/META_FY2023_Q4.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2023, "quarter": "Q4", "period": "2023-Q4", "section_id": null, "section_title": null, "speaker": "Ken Dorell", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 800, "start_token": 680, "end_token": 1480, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 120, "text": " second question, which is about the Q1 year-over-year -- sorry, the Q1 revenue guide. This really just\nreflects a lot of the trends we saw in Q4, which is strong, broad-based advertising demand across verticals, particularly within online commerce and gaming. I'll\nalso note that we get the benefit from having February 29 in this quarter. And again, just the improvements that we continue to accrue to the business from all of\nour investments in improving ad performance over time.\nOperator\nYour next question comes from the line of Eric Sheridan from Goldman Sachs. Maybe two questions, if I can. Mark, coming out of a year like you had with the year of efficiency, what do you see as the key messages you want to share with\ninvestors about what you learned during the year of efficiency and how it might inform running an organization with the scale of ambition and just your\norganizational scale that Meta has on a long-term basis? That would be number one. And then Susan, I went back and looked, I don't think you've ever raised the\nhigh end of your CapEx guidance before, unless I'm mistaken. But with a wide range like that in CapEx, what should we be monitoring for what would push you\ntowards either the lower end or the higher end of that CapEx guidance as you move through 2024? I'll take the first one. So the themes for the year of efficiency were to make us a stronger technology company by becoming leaner and more balanced towards\nour engineering work and more streamlined and to improve our financial performance, primarily with the goal of providing stability so we can invest in these\nlong-term, ambitious visions around AI and metaverse over what we see as the coming decade or more as these things play out. And I think a lot of people\nlooked at what we were doing as if it might have been some kind of short-term thing, which that's never really our focus. But the part about making the company\nleaner, I think, is the more important part to take forward, right? Because obviously, we're in a place now where the business is performing well. And I think the\nobvious question would be, okay, well, given that, should we just -- should we invest a lot more in things? And the biggest thing that's holding me back from doing\nthat is that at this point, I feel like I've really come around to thinking that we operate better as a leaner company. So even though it's always -- there's always\nquestions about like adding a few people here or there to do something. And I guess I just have more of an appreciation about how all of that adds up and in the\nnear term, maybe makes you go a little bit faster. But over the long term, the discipline to kind of hold things to a more streamlined level actually improves the\noverall company performance. So I'm really focused on that. In 2024, we do have a big recruiting backlog from last year because part of the layoffs that we did\nincluded teams basically swapping out certain talent profiles for others. And we still need to hire some of the other talent profiles that we swapped people out for,\nand that will be ongoing through this year. But in terms of new head count that we added to the plan, it's relatively minimal compared to what we would have done\nhistorically. And I sort of expect that for the next period of time going forward, Even beyond 2024. My operating assumption is that we will also try to keep it\nrelatively minimal because I think that -- until we reach a point where we're just really underwater on our ability to execute, I kind of want to keep things lean\nbecause I think that's the right thing for us to do culturally. So that's kind of the best window into how I'm thinking about this. The other piece", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2023_Q4_chunk_0012", "doc_id": "META_TRANSCRIPT_2023_Q4", "source_units": ["META_TRANSCRIPT_2023_Q4_u_0000", "META_TRANSCRIPT_2023_Q4_u_0001", "META_TRANSCRIPT_2023_Q4_u_0002", "META_TRANSCRIPT_2023_Q4_u_0003", "META_TRANSCRIPT_2023_Q4_u_0004", "META_TRANSCRIPT_2023_Q4_u_0005", "META_TRANSCRIPT_2023_Q4_u_0006", "META_TRANSCRIPT_2023_Q4_u_0007", "META_TRANSCRIPT_2023_Q4_u_0008", "META_TRANSCRIPT_2023_Q4_u_0009", "META_TRANSCRIPT_2023_Q4_u_0010", "META_TRANSCRIPT_2023_Q4_u_0011", "META_TRANSCRIPT_2023_Q4_u_0012", "META_TRANSCRIPT_2023_Q4_u_0013", "META_TRANSCRIPT_2023_Q4_u_0014", "META_TRANSCRIPT_2023_Q4_u_0015", "META_TRANSCRIPT_2023_Q4_u_0016", "META_TRANSCRIPT_2023_Q4_u_0017", "META_TRANSCRIPT_2023_Q4_u_0018", "META_TRANSCRIPT_2023_Q4_u_0019", "META_TRANSCRIPT_2023_Q4_u_0020", "META_TRANSCRIPT_2023_Q4_u_0021", "META_TRANSCRIPT_2023_Q4_u_0022"], "source_uri": "data/earnings_calls_manual/META/META_FY2023_Q4.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2023, "quarter": "Q4", "period": "2023-Q4", "section_id": null, "section_title": null, "speaker": "Ken Dorell", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 800, "start_token": 1360, "end_token": 2160, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 120, "text": " to the plan, it's relatively minimal compared to what we would have done\nhistorically. And I sort of expect that for the next period of time going forward, Even beyond 2024. My operating assumption is that we will also try to keep it\nrelatively minimal because I think that -- until we reach a point where we're just really underwater on our ability to execute, I kind of want to keep things lean\nbecause I think that's the right thing for us to do culturally. So that's kind of the best window into how I'm thinking about this. The other piece that, I guess,\nsomewhat dovetails into what Susan is going to talk to you next is that a big part of why I wanted to improve our profitability is to give ourselves the ability to go\nthrough what is a somewhat unpredictable and volatile period over the next 5 or 10 years. There are different risk factors that are geopolitical or regulatory or\ndifferent things, but also the technology landscape is somewhat unknown. And we want the ability to be able to surge investment on things like building out larger\ntraining clusters or just making different investments where that's necessary. And in order to make sure that we have the flexibility to do that, we want to make\nsure that we keep our cost structure to a point where we sort of have some extra space built in. So those are really the 2 points. That was the theme that I laid out\nat the beginning of the year of efficiency last year: make us a stronger technology company and give us the flexibility and stability to execute the long-term goals.\nAnd those remain, I think, the big focuses going forward on that. And I can take the second question, Eric. So we're really continuing to evolve our AI road maps and ambitions and our understanding of the capacity demands\nthat we might have as we train next generations of foundation models and to support all of the associated product development going forward. So the increase in\nthe top end of the range really reflects that evolving understanding of how much demand we may need. And we're also continuing to keep a close eye on supply\navailability. Where we land in that range is a function of both the supply and demand factors I mentioned. And this continues to be a pretty dynamic planning\nprocess for us. And there are also certainly other factors that drive uncertainty. How quickly can we execute on the new data center architecture? How the supply\nchain turns out to unfold over the course of the year? But our expectation is, generally, that we will need to invest more to support our AI work in the years ahead,\nand we're seeing some of that reflected in 2024.\nOperator\nYour next question comes from the line of Mark Shmulik from AllianceBernstein. Mark, you mentioned at the top of the call this vision, kind of everyone having a Meta AI assistant to kind of get things done. Previously, when we were talking\nabout the metaverse from a time horizon perspective, we were looking at a decade to kind of get there. But given kind of the pace of innovation around AI that\nyou've seen, has that time line changed? And like do you think we'll get there quicker? And then second question for Susan. Just quickly on shop ad. I appreciate\nthe color. Obviously, we've had the Amazon partnership news intra-quarter. We know Meta has made a few attempts that are getting kind of more integrated into\nshopping over the last few years. Can you hear some of the learnings and, I guess, what's different this time around? Sure. I can take the first one. I do think that AI is going to make all of the products and services that we use and make better. So it's hard to know exactly how that\nwill play out. But for the work in Reality Labs, specifically, there's a bunch of areas. Like if you take smart glasses, before, we thought that", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2023_Q4_chunk_0013", "doc_id": "META_TRANSCRIPT_2023_Q4", "source_units": ["META_TRANSCRIPT_2023_Q4_u_0000", "META_TRANSCRIPT_2023_Q4_u_0001", "META_TRANSCRIPT_2023_Q4_u_0002", "META_TRANSCRIPT_2023_Q4_u_0003", "META_TRANSCRIPT_2023_Q4_u_0004", "META_TRANSCRIPT_2023_Q4_u_0005", "META_TRANSCRIPT_2023_Q4_u_0006", "META_TRANSCRIPT_2023_Q4_u_0007", "META_TRANSCRIPT_2023_Q4_u_0008", "META_TRANSCRIPT_2023_Q4_u_0009", "META_TRANSCRIPT_2023_Q4_u_0010", "META_TRANSCRIPT_2023_Q4_u_0011", "META_TRANSCRIPT_2023_Q4_u_0012", "META_TRANSCRIPT_2023_Q4_u_0013", "META_TRANSCRIPT_2023_Q4_u_0014", "META_TRANSCRIPT_2023_Q4_u_0015", "META_TRANSCRIPT_2023_Q4_u_0016", "META_TRANSCRIPT_2023_Q4_u_0017", "META_TRANSCRIPT_2023_Q4_u_0018", "META_TRANSCRIPT_2023_Q4_u_0019", "META_TRANSCRIPT_2023_Q4_u_0020", "META_TRANSCRIPT_2023_Q4_u_0021", "META_TRANSCRIPT_2023_Q4_u_0022"], "source_uri": "data/earnings_calls_manual/META/META_FY2023_Q4.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2023, "quarter": "Q4", "period": "2023-Q4", "section_id": null, "section_title": null, "speaker": "Ken Dorell", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 800, "start_token": 2040, "end_token": 2840, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 120, "text": "-quarter. We know Meta has made a few attempts that are getting kind of more integrated into\nshopping over the last few years. Can you hear some of the learnings and, I guess, what's different this time around? Sure. I can take the first one. I do think that AI is going to make all of the products and services that we use and make better. So it's hard to know exactly how that\nwill play out. But for the work in Reality Labs, specifically, there's a bunch of areas. Like if you take smart glasses, before, we thought that we would have to build\nlike full displays and holograms and deliver the sense of presence before that became a mainstream product. And now it seems quite possible that smart glasses\nthat have AI assistance built in will be the killer app, and that the holograms and sense of presence will come later as a -- maybe on the same time horizon we\nwere talking about before but could end up being just as important as we expected. But there could be a big market here even before that. So I think we'll figure\nthat out over the next few years. But yes, I mean, overall, I think the 2 go together pretty hand-in-hand. I would have predicted that a lot of the parts of Reality\nLabs -- I guess the sequence in technology is sometimes surprising. We always kind of expected that as part of building glasses or any of these platforms that\nhaving an AI assistant would be a foundational part of it. But the fact that that's -- that there have just been big strides in that over the last year or 2 is just -- is a\nbig opportunity for these products sooner. So I think it's still unknown exactly how that will play out, but I think we'll know more over the next few years. It's very\nexciting, though. to improve ads performance generally really helps do things like grow conversions year-over-year, improves the performance of direct response ads. We've\ninvested a lot in the Advantage+ set of tools, tools like Advantage+ Shopping. So I would say that our offerings for e-commerce advertisers overall are very\nstrong, and we continue to invest in making them better and more performant. On Shops ads, specifically, this is an area where we are really, I would say,\nfocusing on introducing improvements that continue to make it easier for businesses to onboard 2 shops. So for example, eligible Shopify businesses can now\nonboard to Shops on Facebook and Instagram very seamlessly. And we're making it easier for advertisers to turn their existing ads into Shops ads. And we'll\ncontinue to focus on deepening integrations with partners and leveraging AI to make Shops ads even more performant. You mentioned the Amazon ads pilot, and\nthat's a place where we're partnering with Amazon to make Buy with Prime, to create a more seamless shopping experience on Facebook and Instagram so that\nit's easier for people to purchase directly from an Amazon ad. This is really early, and we're testing this experience with them. But it's another avenue for us to\nexplore how can we make these shopping experience easier for folks on our platform.\nOperator\nYour next question comes from the line of Justin Post from Bank of America. I was wondering if you could help us think about the messaging run rate for revenues and maybe the long-term opportunity and how you think about that going\nforward on a multiyear basis. And then secondly, the guidance for Q1 suggests stable growth at the midpoint despite comps getting tougher. So I'm wondering if\nyou could help us at all think about -- the comps get increasingly tougher as we go through the year, how you're thinking about those comps and how you could\ngrow in the second half. Thanks, Justin. I can take both of those. So on your first question about messaging monetization, right now, the 2 primary avenues that", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2023_Q4_chunk_0014", "doc_id": "META_TRANSCRIPT_2023_Q4", "source_units": ["META_TRANSCRIPT_2023_Q4_u_0000", "META_TRANSCRIPT_2023_Q4_u_0001", "META_TRANSCRIPT_2023_Q4_u_0002", "META_TRANSCRIPT_2023_Q4_u_0003", "META_TRANSCRIPT_2023_Q4_u_0004", "META_TRANSCRIPT_2023_Q4_u_0005", "META_TRANSCRIPT_2023_Q4_u_0006", "META_TRANSCRIPT_2023_Q4_u_0007", "META_TRANSCRIPT_2023_Q4_u_0008", "META_TRANSCRIPT_2023_Q4_u_0009", "META_TRANSCRIPT_2023_Q4_u_0010", "META_TRANSCRIPT_2023_Q4_u_0011", "META_TRANSCRIPT_2023_Q4_u_0012", "META_TRANSCRIPT_2023_Q4_u_0013", "META_TRANSCRIPT_2023_Q4_u_0014", "META_TRANSCRIPT_2023_Q4_u_0015", "META_TRANSCRIPT_2023_Q4_u_0016", "META_TRANSCRIPT_2023_Q4_u_0017", "META_TRANSCRIPT_2023_Q4_u_0018", "META_TRANSCRIPT_2023_Q4_u_0019", "META_TRANSCRIPT_2023_Q4_u_0020", "META_TRANSCRIPT_2023_Q4_u_0021", "META_TRANSCRIPT_2023_Q4_u_0022"], "source_uri": "data/earnings_calls_manual/META/META_FY2023_Q4.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2023, "quarter": "Q4", "period": "2023-Q4", "section_id": null, "section_title": null, "speaker": "Ken Dorell", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 439, "start_token": 2720, "end_token": 3159, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 0, "text": " rate for revenues and maybe the long-term opportunity and how you think about that going\nforward on a multiyear basis. And then secondly, the guidance for Q1 suggests stable growth at the midpoint despite comps getting tougher. So I'm wondering if\nyou could help us at all think about -- the comps get increasingly tougher as we go through the year, how you're thinking about those comps and how you could\ngrow in the second half. Thanks, Justin. I can take both of those. So on your first question about messaging monetization, right now, the 2 primary avenues that we have there are \nclick-to-messaging ads and paid messaging, which we are investing a lot in both to facilitate the full cycle of customer engagement. We saw that revenue growth \nfrom click-to-message ads remained strong in Q4. We see broadening advertiser adoption. And there, I would say that our focus in terms of where we're investing \nis really around enhanced optimization and reporting. So we're really trying to drive down funnel performance, enabling businesses to optimize for purchase. And \nwe've seen strong growth in purchase optimization revenue on click-to-Messenger ads since we've rolled that out. And we're planning to bring purchase \noptimization to click-to-WhatsApp campaigns this year. And across the click-to-messaging ads, we're introducing more robust reporting to help advertisers kind of \nunderstand how people are engaging with them via click-to-messaging ads and what is the value of that engagement. And then, of course, in the longer term, this \nis a place where we're excited about the opportunities for increased automation to really help businesses scale their ability to have conversations with their \nconsumers. On the paid messaging side, this is much earlier, of course, but we're seeing good momentum, driven by particularly strong growth from marketing \nmessages. And we've also seen good results from our updated pricing model that we introduced in June. And here, we're really focused on making paid \nmessaging easier to buy. So we're now testing the ability for businesses to send paid messaging directly on Meta Ads Manager. And then, again, similar to", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2023_Q4_chunk_0015", "doc_id": "META_TRANSCRIPT_2023_Q4", "source_units": ["META_TRANSCRIPT_2023_Q4_u_0000", "META_TRANSCRIPT_2023_Q4_u_0001", "META_TRANSCRIPT_2023_Q4_u_0002", "META_TRANSCRIPT_2023_Q4_u_0003", "META_TRANSCRIPT_2023_Q4_u_0004", "META_TRANSCRIPT_2023_Q4_u_0005", "META_TRANSCRIPT_2023_Q4_u_0006", "META_TRANSCRIPT_2023_Q4_u_0007", "META_TRANSCRIPT_2023_Q4_u_0008", "META_TRANSCRIPT_2023_Q4_u_0009", "META_TRANSCRIPT_2023_Q4_u_0010", "META_TRANSCRIPT_2023_Q4_u_0011", "META_TRANSCRIPT_2023_Q4_u_0012", "META_TRANSCRIPT_2023_Q4_u_0013", "META_TRANSCRIPT_2023_Q4_u_0014", "META_TRANSCRIPT_2023_Q4_u_0015", "META_TRANSCRIPT_2023_Q4_u_0016", "META_TRANSCRIPT_2023_Q4_u_0017", "META_TRANSCRIPT_2023_Q4_u_0018", "META_TRANSCRIPT_2023_Q4_u_0019", "META_TRANSCRIPT_2023_Q4_u_0020", "META_TRANSCRIPT_2023_Q4_u_0021", "META_TRANSCRIPT_2023_Q4_u_0022"], "source_uri": "data/earnings_calls_manual/META/META_FY2023_Q4.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2023, "quarter": "Q4", "period": "2023-Q4", "section_id": null, "section_title": null, "speaker": "Ken Dorell", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 800, "start_token": 0, "end_token": 800, "chunk_type": "windowed_overlap", "overlap_with_prev": 0, "overlap_with_next": 120, "text": "click-to-messaging, we are investing in ways to make it easier to get more done within the app. So here, we launched Flows globally in October, which enables\nbusinesses to offer richer user experiences within WhatsApp, things like selecting a seat on a flight or booking an appointment. We're seeing good early traction,\nand we're focused on just introducing more ways to help businesses easily create flows, and we'll plan on introducing more capabilities here. So there's a lot, I\nwould say, going on in the portfolio of messaging monetization work that we're doing. Now your second question was around the 2024 outlook. And we obviously\nhave not shared any guidance beyond Q1. But our revenue for the full year is going to be influenced by a number of factors, including macro conditions that are\ncertainly harder to predict the further out you go. And over the course of 2024, as you said, we'll also be lapping periods of increasingly strong demand. So we\ndon't provide guidance beyond Q1. There's certainly a range of outcomes, and we'll have a better read on how we will compare to future quarters as we progress\nthrough the year.\nOperator\nYour next question comes from the line of Doug Anmuth from JPMorgan. One for Mark, one for Susan. Mark, I believe you'd shifted FAIR out of Reality Labs into the Family of Apps. Can you just talk about some of the benefits there of\nmoving that group as you pursue general intelligence? And then Susan, can you just walk us through your thought process on adding a dividend to your capital\nreturns at this stage beyond the share repurchases? I can talk to the first one. Yes, the whole reason why we moved FAIR is basically to be closer to the GenAI group. They're both research groups. The GenAI\ngroup basically builds our Llama launch vehicles and products, but also conducts a fair amount of research, too, especially things that are going to be coming into\nthe upcoming versions of Llama. FAIR is focused on more foundational work and longer-term work. So it's, I'd say, more things that might be a couple of years\nout to 10-plus years out. And as we -- I guess, here's one way to think about it. A lot of last year and the work that we're doing with Llama 3 is basically making\nsure that we can scale our efforts to really produce state-of-the-art models. But once we get past that, there's a lot more kind of different research that I think\nwe're going to be doing that's going to take our foundation models in potentially different directions than other players in the industry are going to go in because\nwe're focused on specific vision for what we're building. So it's really important as we think about what's going to be in Llama 5 or 6 or 7 and what cognitive\nabilities we want in there and what modalities we want to build into future multimodal versions of the models. We need to be doing that work in advance and to\nresearch those things. And it helps to -- and even though FAIR and GenAI will continue to be 2 kind of separate groups on different time horizons. I think to have\nsome level of alignment between -- on the vision of what we're building between the 2 of them, so that way, the FAIR team can have in mind, hey, if we research\nthis, then maybe it can intercept Llama 6 or something. Then that, I think, is just going to be more helpful for increasing the ambition and focus of all of the work\nthat we do. It's one of the reasons that I talked about. We did open-ended research on AI for a while. But having a clear product target with these AI agents, I\nthink, is really", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2023_Q4_chunk_0016", "doc_id": "META_TRANSCRIPT_2023_Q4", "source_units": ["META_TRANSCRIPT_2023_Q4_u_0000", "META_TRANSCRIPT_2023_Q4_u_0001", "META_TRANSCRIPT_2023_Q4_u_0002", "META_TRANSCRIPT_2023_Q4_u_0003", "META_TRANSCRIPT_2023_Q4_u_0004", "META_TRANSCRIPT_2023_Q4_u_0005", "META_TRANSCRIPT_2023_Q4_u_0006", "META_TRANSCRIPT_2023_Q4_u_0007", "META_TRANSCRIPT_2023_Q4_u_0008", "META_TRANSCRIPT_2023_Q4_u_0009", "META_TRANSCRIPT_2023_Q4_u_0010", "META_TRANSCRIPT_2023_Q4_u_0011", "META_TRANSCRIPT_2023_Q4_u_0012", "META_TRANSCRIPT_2023_Q4_u_0013", "META_TRANSCRIPT_2023_Q4_u_0014", "META_TRANSCRIPT_2023_Q4_u_0015", "META_TRANSCRIPT_2023_Q4_u_0016", "META_TRANSCRIPT_2023_Q4_u_0017", "META_TRANSCRIPT_2023_Q4_u_0018", "META_TRANSCRIPT_2023_Q4_u_0019", "META_TRANSCRIPT_2023_Q4_u_0020", "META_TRANSCRIPT_2023_Q4_u_0021", "META_TRANSCRIPT_2023_Q4_u_0022"], "source_uri": "data/earnings_calls_manual/META/META_FY2023_Q4.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2023, "quarter": "Q4", "period": "2023-Q4", "section_id": null, "section_title": null, "speaker": "Ken Dorell", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 800, "start_token": 680, "end_token": 1480, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 120, "text": " of alignment between -- on the vision of what we're building between the 2 of them, so that way, the FAIR team can have in mind, hey, if we research\nthis, then maybe it can intercept Llama 6 or something. Then that, I think, is just going to be more helpful for increasing the ambition and focus of all of the work\nthat we do. It's one of the reasons that I talked about. We did open-ended research on AI for a while. But having a clear product target with these AI agents, I\nthink, is really going to help focus the work and give us a feedback loop that's going to increase the productivity and output that we get dramatically. Doug, on your second question about why now in terms of initiating a dividend, returning capital to shareholders remains an important priority for us. And we\nbelieve introducing a dividend really just serves as a nice complement to the existing share repurchase program. The dividend doesn't change how much we will\nbe -- or it doesn't change the way we determine the total amount of capital we return. And we expect that share repurchases will continue to be the primary way\nthat we return capital to shareholders. But introducing a dividend just gives us a more balanced capital return program and some added flexibility in how we return\ncapital in the future.\nOperator\nYour next question comes from the line of Ron Josey from Citi. Mark, I hope your knee is getting better. I wanted to ask you about Apple opening up its App Store in Europe and maybe what role that might play for Meta in\nfurther building out the App Store app install ads and things along those lines. And Susan, as a follow-up to maybe a prior question, you mentioned the potential\naround business messaging and the team -- what the team is doing around really testing with WhatsApp and Messenger. Just talk just how you might see this\nunfold maybe with AI Studio and maybe timing would be helpful. I don't think that the Apple thing is going to have any difference for us because I think that the way that they've implemented it, I would be very surprised if any\ndeveloper chose to go into the alternative App Stores that they have. They've made it so onerous, and I think so at odds with the intent of what the EU regulation\nwas that I think it's just going to be very difficult for anyone, including ourselves, to really seriously entertain what they're doing there. Susan, did you want to add\nanything? No. I was going to take the second question, I think, which was around the rollout of some of the GenAI features from a monetization perspective. And we're -- \nfirst of all, I would say that we don't expect our GenAI products to be a meaningful 2024 driver of revenue. But we certainly expect that they will have the potential \nto be meaningful contributors over time. Right now, the most near-term monetization opportunity is with our ad creative tools. We've talked about some of the \nplaces that we've been rolling those features out broadly with Text Variations and Image Expansion now globally available. And we're seeing those tools receive \nadoption and provide real value for advertisers even at this early stage. And we're going to keep investing in making those more useful and performant, which \nthen leads to more advertiser adoption, and that can be sort of a virtuous feedback loop. Over a longer time frame, the GenAI features that we're bringing to \nbusiness messaging, which I think was where your question originated, we think really represents a compelling opportunity. We're testing AI chats on a very small \nscale today with a few businesses, but it will take time to continue making those AIs increasingly useful. We're hearing good feedback from the businesses testing \nthem, and we expect to make progress this year as we expand our tests further. I'd say one other thing is", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2023_Q4_chunk_0017", "doc_id": "META_TRANSCRIPT_2023_Q4", "source_units": ["META_TRANSCRIPT_2023_Q4_u_0000", "META_TRANSCRIPT_2023_Q4_u_0001", "META_TRANSCRIPT_2023_Q4_u_0002", "META_TRANSCRIPT_2023_Q4_u_0003", "META_TRANSCRIPT_2023_Q4_u_0004", "META_TRANSCRIPT_2023_Q4_u_0005", "META_TRANSCRIPT_2023_Q4_u_0006", "META_TRANSCRIPT_2023_Q4_u_0007", "META_TRANSCRIPT_2023_Q4_u_0008", "META_TRANSCRIPT_2023_Q4_u_0009", "META_TRANSCRIPT_2023_Q4_u_0010", "META_TRANSCRIPT_2023_Q4_u_0011", "META_TRANSCRIPT_2023_Q4_u_0012", "META_TRANSCRIPT_2023_Q4_u_0013", "META_TRANSCRIPT_2023_Q4_u_0014", "META_TRANSCRIPT_2023_Q4_u_0015", "META_TRANSCRIPT_2023_Q4_u_0016", "META_TRANSCRIPT_2023_Q4_u_0017", "META_TRANSCRIPT_2023_Q4_u_0018", "META_TRANSCRIPT_2023_Q4_u_0019", "META_TRANSCRIPT_2023_Q4_u_0020", "META_TRANSCRIPT_2023_Q4_u_0021", "META_TRANSCRIPT_2023_Q4_u_0022"], "source_uri": "data/earnings_calls_manual/META/META_FY2023_Q4.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2023, "quarter": "Q4", "period": "2023-Q4", "section_id": null, "section_title": null, "speaker": "Ken Dorell", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 133, "start_token": 1360, "end_token": 1493, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 0, "text": "then leads to more advertiser adoption, and that can be sort of a virtuous feedback loop. Over a longer time frame, the GenAI features that we're bringing to \nbusiness messaging, which I think was where your question originated, we think really represents a compelling opportunity. We're testing AI chats on a very small \nscale today with a few businesses, but it will take time to continue making those AIs increasingly useful. We're hearing good feedback from the businesses testing \nthem, and we expect to make progress this year as we expand our tests further. I'd say one other thing is just on the consumer side, again, we think GenAI can", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2023_Q4_chunk_0018", "doc_id": "META_TRANSCRIPT_2023_Q4", "source_units": ["META_TRANSCRIPT_2023_Q4_u_0000", "META_TRANSCRIPT_2023_Q4_u_0001", "META_TRANSCRIPT_2023_Q4_u_0002", "META_TRANSCRIPT_2023_Q4_u_0003", "META_TRANSCRIPT_2023_Q4_u_0004", "META_TRANSCRIPT_2023_Q4_u_0005", "META_TRANSCRIPT_2023_Q4_u_0006", "META_TRANSCRIPT_2023_Q4_u_0007", "META_TRANSCRIPT_2023_Q4_u_0008", "META_TRANSCRIPT_2023_Q4_u_0009", "META_TRANSCRIPT_2023_Q4_u_0010", "META_TRANSCRIPT_2023_Q4_u_0011", "META_TRANSCRIPT_2023_Q4_u_0012", "META_TRANSCRIPT_2023_Q4_u_0013", "META_TRANSCRIPT_2023_Q4_u_0014", "META_TRANSCRIPT_2023_Q4_u_0015", "META_TRANSCRIPT_2023_Q4_u_0016", "META_TRANSCRIPT_2023_Q4_u_0017", "META_TRANSCRIPT_2023_Q4_u_0018", "META_TRANSCRIPT_2023_Q4_u_0019", "META_TRANSCRIPT_2023_Q4_u_0020", "META_TRANSCRIPT_2023_Q4_u_0021", "META_TRANSCRIPT_2023_Q4_u_0022"], "source_uri": "data/earnings_calls_manual/META/META_FY2023_Q4.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2023, "quarter": "Q4", "period": "2023-Q4", "section_id": null, "section_title": null, "speaker": "Ken Dorell", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 607, "start_token": 0, "end_token": 0, "chunk_type": "prepared_packed", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "make it easier for people to produce compelling content across all of our apps, including our messaging apps. And our AI assistant certainly provides also added\nutilities. So in all of these areas, I would say, we're following our typical playbook of testing and tuning the experiences until they're very good, and then we'll\ninvest in growth and eventually explore monetization.\nOperator\nYour last question comes from the line of Ross Sandler from Barclays. Mark, just curious what you're seeing with Meta AI at this stage. You talked about rapid iteration of that, given your large audience. So yes, I guess, what's going\non, thus far? Which of the apps in the Family of Apps have seen engagement increase from Meta AI? And do you think that there could be increased commercial\nactivity as either your AI agent or some of the other ones out there get more usage within your apps? Yes. I think having a good assistant is going to be one of the real values that this generation of AI creates as well as giving every creator an opportunity to have\nan assistant or agent that people can engage with and every business and agent and also allowing people to create a bunch of quirky and fun things as well. But\nyes, I think Meta AI is going to be very important across the product. It currently is available in some countries in WhatsApp, Messenger and Instagram. It's at the\nphase where we're not really pushing it super proactively. We've sort of made it available, and as people use it, we're learning from how -- what are the basic\nways that people want to engage with it. We're currently in the tuning phase on this. I mean, we started rolling this out, I think, it was in November or so, maybe\nOctober. And I would expect that, over the course of this year, we are going to start rolling this out much more prominently across our apps. And that was sort of\nwhat I was saying in my opening remarks about the analogy to Stories, where we ran a bunch of experiments, put it out there, got feedback and then eventually\ndid a lot of integrations, even to the point where people were making jokes about us putting Stories in settings, which, for the record, never happened, but I found\nfunny. So I think that we're going to be on that journey this year. We're basically in the learning and tuning phase now. I'm happy with how that's going. We're\ncurrently working on and planning the next set of integrations and places where this is going to be available to people across the products, and I'm really looking\nforward to that. And I think that's going to be one of the big themes for '24 for us. Great. Thank you for joining us today. We appreciate your time, and we look forward to speaking with you again soon.\nOperator\nThis concludes today's conference call. Thank you for your participation, and you may now disconnect.", "chunked_at": "2025-11-10T02:15:59Z"}
