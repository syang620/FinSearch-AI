{"chunk_id": "META_TRANSCRIPT_2024_Q4_chunk_0000", "doc_id": "META_TRANSCRIPT_2024_Q4", "source_units": ["META_TRANSCRIPT_2024_Q4_u_0006", "META_TRANSCRIPT_2024_Q4_u_0007"], "source_uri": "data/earnings_calls_manual/META/META_FY2024_Q4.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2024, "quarter": "Q4", "period": "2024-Q4", "section_id": null, "section_title": null, "speaker": "Eric Sheridan", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 450, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Thank you so much for taking the question. Maybe I can go back to your comments on open source. Can you help us understand how your views continue to\nevolve with respect to the competitive dynamic around your approach with open source versus others in the industry? And how your approach to open source\ncould possibly bend the cost curve and improve return on capital for AI over the medium to long-term? Thanks so much. Yes. I mean on open source, I think the best analogy for us is what we did with open compute, where we weren't first to building the system. So then by the time\nthat we got around to building it, it wasn't really a big advantage to have it be proprietary. So we shared it. And then a lot of the industry adopted what we were\ndoing, contributed innovations back to it. By standardizing it on it, that meant that a bunch of supply chain standardized on building it, which made prices more\nefficient for everyone. I think what we see here is as Llama becomes more used, it's more likely, for example, that silicon providers and others -- other APIs and\ndeveloper platforms will optimize their work more for that and basically drive down the costs of using it and drive improvements that we can, in some cases, use\ntoo. So I think that the strategy will continue to be effective, and yes, I mean, I continue to be optimistic about this. I think it's kind of -- I think it's working. I also\njust think in light of some of the recent news, the new competitor DeepSeek from China, I think it also just puts -- it's one of the things that we're talking about is\nthere's going to be an open source standard globally. And I think for our kind of national advantage, it's important that it's an American standard. So we take that\nseriously, and we want to build the AI system that people around the world are using and I think that if anything, some of the recent news has only strengthened\nour conviction that this is the right thing for us to be focused on.\nOperator\nYour next question comes from the line of Mark Shmulik with Bernstein. Please go ahead.", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2024_Q4_chunk_0001", "doc_id": "META_TRANSCRIPT_2024_Q4", "source_units": ["META_TRANSCRIPT_2024_Q4_u_0008", "META_TRANSCRIPT_2024_Q4_u_0009"], "source_uri": "data/earnings_calls_manual/META/META_FY2024_Q4.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2024, "quarter": "Q4", "period": "2024-Q4", "section_id": null, "section_title": null, "speaker": "Mark Shmulik", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 534, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Yes, thank you for taking my questions. Mark, I appreciate we may get an answer this year. But looking out, as you kind of track the progress of smart glasses,\nOrion and so forth, do you view that as a better form factor to get the most out of the Meta AI assistance you highlighted in your opening remarks? Or is it more\ncomplementary to kind of the in-app experience in the way you've seen people use it today? And then, Susan, the last few quarters, we've kind of seen pricing\ngrowth is the dominant driver of ad revenue growth. Given the efforts you've highlighted around driving deeper, more commercial engagement and better\nadvertiser ROI, how do we just think about the contribution of the formula for ad revenue growth going forward? Thank you. Yes. I mean, I can talk about glasses. I mean it's -- yes, I mean, I've said for a while that I think that glasses are the ideal form factor for an AI device, because\nyou can let an AI assistant on your glasses see what you see and hear what you hear, which gives it the context to be able to understand everything that's going\non in your life that you would want to talk to it about and get context on. So -- but look, I mean, I think the glasses are going to be a very important computing\nplatform in the future. When phones became the primary computing platform, it's not like computers went away. I think we'll have phones for some time. But there\nare a lot of people in the world who have glasses. It's kind of hard for me to imagine that a decade or more from now, all the glasses aren't going to basically be\nAI glasses, as well as a lot of people who don't wear glasses today, finding that to be a useful thing. So I'm incredibly optimistic about this. And like I shared last\nyear, I think one of the big surprises last year was I previously thought that glasses weren't going to become a major form factor until we got these -- the full kind\nof holographic displays that we started showing in the prototype for Orion. But now I think it's pretty clear that AI is actually going to drive at least as much of the\nvalue as the holographic AR is. So that's a cause to be excited. But look, the Ray-Ban Metas were hit. We still don't know what the long-term trajectory for this is\ngoing to be. And I think we're going to learn a lot this year. So I think that this is a really important year for that.", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2024_Q4_chunk_0002", "doc_id": "META_TRANSCRIPT_2024_Q4", "source_units": ["META_TRANSCRIPT_2024_Q4_u_0011", "META_TRANSCRIPT_2024_Q4_u_0012"], "source_uri": "data/earnings_calls_manual/META/META_FY2024_Q4.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2024, "quarter": "Q4", "period": "2024-Q4", "section_id": null, "section_title": null, "speaker": "Justin Post", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 371, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned political changes in the U.S. and better positioning maybe for U.S. companies\nabroad. But how do you think about it in the U.S. as far as usage and advertiser adoption, you got rid of fact checking. So do you think the content could change?\nCould it appeal to more users? Will that impact advertising at all? And then Susan, on Meta AI, I know people are pretty excited about the use case, but also\nthinking about the revenue case. How do you think about monetizing that? Could it be CPC ads? Or how are you thinking about that? Thank you. The question was about fact checking and our content policies. I mean, look, I think we're trying to build the service that we think is the best for people. I believe\nin free expression for quite a while. People don't want to see misinformation, but you need to build an effective system that gives people more context. And I think\nwhat we found over time is that the community note system, I think, is just going to be more effective than the system that we had before. And I'm not afraid to\nadmit when someone does something that's better than us. I think it's sort of our job to go and just do best work and implement the best systems. So I think that\nthere's been a lot of people who have read this announcement is if we somehow don't care about adding context to things that are on our platform that are\nmisinformation, that's not right. I actually think that the community note system, like what X has had for a while is actually just more effective than what we were\ndoing before. And I think our product is going to get better because of it.", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2024_Q4_chunk_0003", "doc_id": "META_TRANSCRIPT_2024_Q4", "source_units": ["META_TRANSCRIPT_2024_Q4_u_0014", "META_TRANSCRIPT_2024_Q4_u_0015"], "source_uri": "data/earnings_calls_manual/META/META_FY2024_Q4.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2024, "quarter": "Q4", "period": "2024-Q4", "section_id": null, "section_title": null, "speaker": "Douglas Anmuth", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 800, "start_token": 0, "end_token": 800, "chunk_type": "windowed_overlap", "overlap_with_prev": 0, "overlap_with_next": 120, "text": "Thanks for taking the questions. One for Mark, one for Susan. Mark, just following up on open source as DeepSeek and other models potentially leverage Llama\nor others to train faster and cheaper. How does this impact in your view? And what could have been for the trajectory of investment required over a multiyear\nperiod? And then, Susan, just as we think about the $60 billion to $65 billion CapEx this year, does the composition change much from last year when you talked\nabout servers as the largest part followed by data centers and networking equipment. And how should we think about that mix between like training and inference\njust following up on Jan's post this week? Thanks. I can start on the DeepSeek question. I think there's a number of novel things that they did that I think we're still digesting. And there are a number of things that\nthey have advances that we will hope to implement in our systems. And that's part of the nature of how this works, whether it's a Chinese competitor or not. I kind\nof expect that every new company that has an advance -- that has a launch is going to have some new advances that the rest of the field learns from. And that's\nsort of how the technology industry goes. I don't know -- it's probably too early to really have a strong opinion on what this means for the trajectory around\ninfrastructure and CapEx and things like that. There are a bunch of trends that are happening here all at once. There's already sort of a debate around how much\nof the compute infrastructure that we're using is going to go towards pretraining versus as you get more of these reasoning time models or reasoning models\nwhere you get more of the intelligence by putting more of the compute into inference, whether just will mix shift how we use our compute infrastructure towards\nthat. That was already something that I think a lot of the other labs and ourselves were starting to think more about and already seemed pretty likely even before\nthis, that -- like of all the compute that we're using, that the largest pieces aren't necessarily going to go towards pre-training. But that doesn't mean that you need\nless compute, because one of the new properties that's emerged is the ability to apply more compute at inference time in order to generate a higher level of\nintelligence and a higher quality of service, which means that as a company that has a strong business model to support this, I think that's generally an advantage\nthat we're now going to be able to provide a higher quality of service than others, who don't necessarily have the business model to support it on a sustainable\nbasis. The other thing is just that when we're building things like Meta AI, but also how we're implementing AI into all the feeds and ad products and things like\nthat, we're just serving billions of people, which is different from, okay, you start to pretrain a model, and that model is sort of agnostic to how many people are\nusing it, like at some level, it's going to be expensive for us to serve all of these people, because we are serving a lot of people. And so I'm not sure what the kind\nof net effect of all of this is. The field continues to move quickly. There's a lot to learn from releases from basically everyone who does something interesting, not\njust the ones over the last month. We'll continue to kind of incorporate that into what we do as well as making novel contributions to the field ourselves And I\ncontinue to think that investing very heavily in CapEx and infra is going to be a strategic advantage over time. It's possible that we'll learn otherwise at some point,\nbut I just think it's way too early to call that. And at this point, I would bet that the ability to build out that kind of infrastructure is going to be a major advantage for\n", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2024_Q4_chunk_0004", "doc_id": "META_TRANSCRIPT_2024_Q4", "source_units": ["META_TRANSCRIPT_2024_Q4_u_0014", "META_TRANSCRIPT_2024_Q4_u_0015"], "source_uri": "data/earnings_calls_manual/META/META_FY2024_Q4.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2024, "quarter": "Q4", "period": "2024-Q4", "section_id": null, "section_title": null, "speaker": "Douglas Anmuth", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 138, "start_token": 680, "end_token": 818, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 0, "text": " learn from releases from basically everyone who does something interesting, not\njust the ones over the last month. We'll continue to kind of incorporate that into what we do as well as making novel contributions to the field ourselves And I\ncontinue to think that investing very heavily in CapEx and infra is going to be a strategic advantage over time. It's possible that we'll learn otherwise at some point,\nbut I just think it's way too early to call that. And at this point, I would bet that the ability to build out that kind of infrastructure is going to be a major advantage for\nboth the quality of the service and being able to serve the scale that we want to.", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2024_Q4_chunk_0005", "doc_id": "META_TRANSCRIPT_2024_Q4", "source_units": ["META_TRANSCRIPT_2024_Q4_u_0017", "META_TRANSCRIPT_2024_Q4_u_0018"], "source_uri": "data/earnings_calls_manual/META/META_FY2024_Q4.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2024, "quarter": "Q4", "period": "2024-Q4", "section_id": null, "section_title": null, "speaker": "Ron Josey", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 388, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Hey, thanks for taking the question. Mark, I want to get back to your comment on getting back to the OG Facebook, and I want to understand a little bit more on\nthe use cases and how that could expand? Video is clearly a benefit. Local marketplace groups have all been positive. So any insights on the OG Facebook? And\nthen back to Meta AI, given the adoption we're seeing on the 600-plus MAUs, just how does the user experience evolved to? What are people doing with Meta\nAI? Thank you. Okay. So for Facebook, a lot of people use Facebook every day, and it's an important part of their lives. And I think that there are a lot of opportunities to make it\nway more culturally influential than it is today. And I think that, that's sort of a fun and interesting goal that will take our product development in some interesting\ndirections that we maybe have a focus on it as much over the last several years. So I don't know that I have anything much more specific on this other than that\nthis is going to be one of my focus areas for this year. I mean, I think it's an investment area and something I'm going to spend some time on it. It might mean that\nin the near-term, we make some trade-offs to kind of focus on some product areas of what we're doing ahead of just kind of maximizing business results in the\nnear term on it. But overall, I'm really excited about doing some exciting stuff here. And I'm not going to get into many specifics now, but we'll get -- we'll follow up\non this over the next, I don't know, call it, a year as we start rolling it out and I think some of this will kind of get back to how Facebook was originally used back in\nthe day. So I think it will be fun.", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2024_Q4_chunk_0006", "doc_id": "META_TRANSCRIPT_2024_Q4", "source_units": ["META_TRANSCRIPT_2024_Q4_u_0020", "META_TRANSCRIPT_2024_Q4_u_0021"], "source_uri": "data/earnings_calls_manual/META/META_FY2024_Q4.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2024, "quarter": "Q4", "period": "2024-Q4", "section_id": null, "section_title": null, "speaker": "Ken Gawrelski", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 680, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Thank you very much. Two for me, please. First, could you talk a little bit -- I know you talked a little bit on the capital intensity side and the recent developments,\nand it's hard to see it's hard to tell yet where things are going? But maybe you could just talk a little bit more near term, '25, the CapEx budget you laid out or the\nCapEx forecast. Could you talk a little bit about the constraints you're seeing or where you're seeing constraints, either internally resources planning or externally\nand any one -- any parts of the ecosystem? And then on the second one, I'm curious, as you think about your needs for hiring and we just think about -- we know\nyou gave the OpEx guide for this year. But as we think about future needs for hiring, could you just give us a sense of how we should think about that? You\nannounced the performance-related reductions earlier this -- for early this year. Could you just talk about how we should be thinking about that '26, '27 and\nbeyond? Thank you. Sure. I'm happy to take both of those. So on your first question on just where do we see constraints in our ability to execute against our CapEx plans. Obviously,\nwe are staying on top of supply availability. That is certainly one of the factors that will influence our CapEx spend in 2025, but we don't really have any updates\nto share on supply availability right now. We are planning to significantly ramp up deployment of GPUs in 2025, and we'll continue to engage with our vendors\nand invest in our own silicon to meet those needs. When you asked how to think about capital intensity, we're not really -- as both Mark and I alluded to in our\nprior comments, I think it is really too early to determine what long-run capital intensity is going to look like. There are so many different factors. The pace of\nadvancement in underlying models, how efficient can they be? What is the adoption and use case of our Gen AI products, what performance gains come from\nnext-generation hardware innovations, both our own and third-party and then ultimately, what monetization or other efficiency gains our AI investments unlock. So\nagain, I think we are sort of early in the journey here, and we don't have -- I would say we don't have kind of anything to share about long-run capital intensity yet.\nYour second question was about thinking about hiring needs. So it's a good segue after infrastructure, employee compensation is the next largest driver of\nexpense growth in 2025. And here, growth in employee comp and headcount more broadly is primarily driven by those areas that I mentioned, infrastructure\nmonetization, generative AI, Reality Labs and regulation and compliance. And those generally are more technical organizations. That means that it is a higher\ncost base relative to business functions where we are also expecting to keep headcount growth constrained. And I would say we are -- we're focused on running\nthe company efficiently. But at the same time, it is -- we feel like we're in a critical period in terms of making sure that we are investing to win, and we want to\nmake sure that we staff those priority areas in a way that really positions us to best do that.", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2024_Q4_chunk_0007", "doc_id": "META_TRANSCRIPT_2024_Q4", "source_units": ["META_TRANSCRIPT_2024_Q4_u_0023", "META_TRANSCRIPT_2024_Q4_u_0024"], "source_uri": "data/earnings_calls_manual/META/META_FY2024_Q4.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2024, "quarter": "Q4", "period": "2024-Q4", "section_id": null, "section_title": null, "speaker": "Ross Sandler", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 746, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Yes. One for Mark, on agents. So we all saw OpenAI's operator demo last week. So Mark, as the industry moves from chat to agentic behavior and more\ncommercial intent moves into these AI products? I guess how are you thinking about monetization potential for Meta AI? And then how might Llama 4 reasoning\nhelp drive some of these new agentic experiences for Meta AI? Thank you. Yes. So I guess a couple of things that I'd say on this. One is when you're thinking about agents and reasoning, a lot of this is about being able to perform\nmultistep tasks. So right now, the way that a lot of these systems work as you kind of say something and then it responds and it's almost chat like. But I think that\nthe direction that it's going is you're going to be able to give it an intent or a task and it's going to be able to go off and use sort of an arbitrary amount of compute\nas much as you want to use on it to be able to do a task. Some of the tasks might be pretty simple for people go buy a specific thing. Some of them might be\nreally hard, like go write an app or optimize this code and like really make it as good as possible. And that type of thing, I think, is just going to start becoming\nmore and more prevalent over the next a year or two. So I think it's very exciting. It's sort of we'll feel in some ways like the current products are just getting\nsmarter and others, it will feel like sort of a new form factor, because it won't be as much like chat. But it's sort of another generation of these products. So I think\nit's just in general, there's a lot to build and be excited about. I guess my note of caution or just my kind of periodic reminder on our product development process,\nif you will, is we build these product. We try to scale them to reach usually 1 billion people or more. And it's at that point once they're at scale that we really start\nfocusing on monetization. So sometimes we'll experiment with monetization before, we're running some experiments with Threads now, for example. But we\ntypically don't really ramp these things up or see them as meaningfully contributing to the business until we reach quite a big scale. So the thing that I think is\ngoing to be meaningful this year is the kind of getting of the AI product to scale. Last year was sort of the introduction and starting to get to be used. This year my\nkind of expectation and hope is that we will be at a sufficient scale and have sufficient kind of flywheel of people using it and improvement from that, that this will\nhave a durable advantage. But that doesn't mean that it's going to be a major contributor to the business. This year the improvements of the business are going to\nbe taking the AI methods and applying them to advertising and recommendations and feeds and things like that. So the actual business opportunity for Meta AI\nand AI studio and business agents and people interacting with these AIs remains outside of '25 for the most part. And I think that's an important thing for us to\ncommunicate and for people to internalize as you're thinking about our prospects here. But nonetheless, we've run a process like this many times. We built a\nproduct. We make it good. We scale it to be large. We build out the business around it. That's what we do. I'm very optimistic, but it's going to take some time.", "chunked_at": "2025-11-10T02:15:59Z"}
