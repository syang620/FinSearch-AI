# MSFT Q3 2024 Earnings Call

**Document ID**: MSFT_2024_Q3
**Ticker**: MSFT
**Year**: 2024
**Quarter**: Q3
**Utterances**: 41

---

---

## Q&A Session

### Exchange 001

**Keith Weiss (Morgan Stanley)**: Thank you, guys for taking the question and congratulations on a fantastic quarter. A lot of excitement in the marketplace around generative AI and the potential
of these technologies, but there’s also a lot of investment going on behind them. It looks like Microsoft is on track to ramp CapEx over 50% year-on-year this year
to over $50 billion. And there’s media speculation of more spending ahead with some reports talking about like $100 billion data center. So obviously, investments
are coming well ahead of the revenue contribution. But what I was hoping for is that you could give us some color on how use as the management team, try to
quantify the potential opportunities that underlie these investments because they are getting very big. And maybe if you could give us some hint on whether
there's any truth to the potential of like $100 billion data center out there? Thank you so much.

**Satya Nadella (CEO)**: Thank you, Keith for the question, let me start and then Amy, you can add. At a high level, the way we, as a management team, talk about it is there are two sides
to this, right? There is training and their inference. Given that we want to be a leader in this big generational shift and paradigm shift in technology, that's on the
training side. We want to be able to allocate the capital required to essentially be training these large foundation models and stay on the leadership position there.
And we've done that successfully all the way today, and you've seen it flow through our P&L, and you can continue to see that going forward. Then Amy
referenced what we also do on the inference side, which is, one, we first innovate and build products. And of course, we have an infrastructure business that's
also dependent on a lot of ISVs building products that run on our infrastructure. And it's all going to be demand driven. In other words, we track – we're closely
what's happening with inference demand, and that's something that we will manage, as Amy said in her remarks very, very closely. So we feel – and obviously,
we've been doing this, quite frankly, Keith, for now multiple years. So this is not the quarter. I realize in the news, it's a lot more in the quarter nowadays. But if
you look at it, we have been doing what is essentially capital allocation to be a leader in AI for multiple years now, and we plan to sort of essentially keep taking
that forward.

### Exchange 002

**Keith Weiss (Morgan Stanley)**: Excellent. Thank you so much.

**Brett Iversen (President)**: Thanks, Keith. Operator, next question please.
Operator
The next question comes from the line of Brent Thill with Jefferies. Please proceed.

### Exchange 003

**Brent Thill (Jefferies)**: Satya, how would you characterize the demand environment? On one hand, you have bookings in Azure both accelerating year-over-year in the quarter, but
we're seeing a lot of future concern hesitation from other vendors we all cover. So, I think everyone love to get your sense of budget health for customers this
year.

**Satya Nadella (CEO)**: Great question, Brent. There are a couple of things I’d say. On the Azure side, which I think is what you specifically asked, we feel very good about the – we are
fundamentally a share taker there because if you look at it from our perspective at this point, Azure has become a protocol for pretty much anybody who is doing
an AI project. And so that's sort of been a significant help for us in terms of acquiring even new customers. Some of the logos I even referenced in my remarks,
our new Azure customers. So, that's one. The second thing that we're also seeing is AI just doesn't sit on its own. So, AI projects obviously start with calls to AI
models, but they also use a vector database. In fact, Azure Search, which is really used by even ChatGPT is one of the fastest-growing services for us. We have
Fabric integration to Azure AI. And so, Cosmos DB integration. So, the data tier, the dev tools is another place where we are seeing great traction. So, we are
seeing adjacent services in Azure that get attached to AI. And lastly, I would say, migrations to Azure as well. So, this is not just all an AI story. We are also
looking at customers, I mean, this is something that we have talked about in the past, which is there's always an optimization cycle, but there's also – as people
optimize, they spend money on new project starts, which will grow and then they'll optimize. So, it's a continuous side of it. So, these are the three trends that are
playing out on Azure in terms of what at least we see on demand side.

### Exchange 004

**Brent Thill (Jefferies)**: Thank you.

**Brett Iversen (President)**: Thanks, Brent. Operator, next question please.
Operator
And the next question comes from the line of Mark Moerdler with Bernstein Research. Please proceed.

### Exchange 005

**Mark Moerdler (Bernstein)**: Thank you very much for taking my question and congratulates on the quarter and the guidance. I want to follow up on the AI, obviously. We’re seeing companies
shifting their IT spending to invest in and learn about AI rather than receiving additional budgets for AI. At some point, for AI to be transformative, as everyone
expects, it needs to be accretive to spending. Satya, when do you believe AI will hit the maturity level, will be net increase to IT or outside of IT spending? And
what would be the leading indicators of that maturation? And Amy, am I characterizing this correctly as it relates to Azure? Some projects are being delayed so
that, that spending could be shifted from core Azure toward Azure AI? Thank you.

**Satya Nadella (CEO)**: Yes. Great set of questions, Mark. Let me just start by saying, a good place to start is to watch what’s happening in terms of standard issues for software teams,
right? I mean if you think about it, they bought tools in the past. Now, you basically buy tools plus Copilot, right? So, you could even say that this is characterized
as perhaps shift of what is OpEx dollars into effectively tool spend because it gives operating leverage to all of the OpEx dollars you’re spending today, right?
That’s really a good example of, I think, what’s going to happen across the board. We see that in customer service. We see that in sales. We see that in
marketing. Anywhere, there’s operations. That’s why I described it as knowledge turns. You can even think of it as lean for knowledge work, right, because it just
reduces waste, increases speed, and customer value. And so, one of the interesting rate limiters here is culture change inside of organizations. When I say
culture change that means process change. And Amy referenced this even in her answer to the first question because at the end of the day companies will have
to take a process, simplify the process, automate the process, and apply these solutions. And so that requires not just technology, but in fact, companies to go do
the hard work of culturally changing how they adopt technology to drive that operating leverage. And this is where we are going to see firm-level performance
differences. So, one of the things we see is any customer who is working closely with us deploying it internally at Microsoft we see it, right. We’re also taking our
own medicine to apply this across every process. And we know that this is not just about technology, it’s about being able to have the methodology that goes with
it. And so, we see it in software development. We see it in customer service. We’re seeing it even in the horizontal use of Copilot today where every day people
are discovering new workflows that they can optimize. And so, that’s like the PC when it became standard issue in early 1990s. That’s the closest analogy I can
come up with. And so, yes, it will take time for it to percolate through the economy, but this is faster diffusion, faster rate of adoption than anything we have seen
in the past, as evidenced even by Copilot, right. It’s faster than any suite we have sold in the past, but it is going to require workflow and process change.

### Exchange 006

**Mark Moerdler (Bernstein)**: Incredibly helpful. Thank you both.

**Brett Iversen (President)**: Thanks, Mark. Operator, next question please.

Operator
The next question comes from the line of Karl Keirstead with UBS. Please proceed.

### Exchange 007

**Karl Keirstead (UBS)**: Thank you. And Satya and Amy, congrats on these outstanding Azure results. I’d love to hone in a little bit on the seven-point lift to Azure growth from AI,
outstanding number, but it’s leveling off a little bit from six points in December. I’m wondering if you could unpack that a little bit. To what extent did the capacity
issues that you Amy highlighted on the call, impact that number? Is there any seasonality? I wouldn’t think so or any other factor that can swing around that
number that you’d advise us to keep in mind? Thanks so much.

### Exchange 008

**Karl Keirstead (UBS)**: Okay. Helpful. Thank you.

**Brett Iversen (President)**: Thanks, Karl. Operator, next question please.
Operator
And the next question comes from the line of Raimo Lenschow with Barclays. Please proceed.

### Exchange 009

**Raimo Lenschow (Barclays)**: Thank you. I have more conceptual question for Satya. If you think about Copilots and what you're doing there, you're kind of impacting a lot of this in businesses
and the opportunities seem very broad-based. How do you think this will play out in the industry between you guys offering certain Copilots versus like the rest of
the industry following and everyone seems to have a Copilot now and seems to be talking about it. How does that impact what do you want to do, your partner
strategy going forward? Thank you.

**Satya Nadella (CEO)**: Yes, it's a great question. So the way we see it play out is, if you think about it, the way Office was used broadly for knowledge work was in the context of
business processes, right? So it's not like – when people do knowledge work, they're not doing knowledge work, they're doing knowledge work and support of
making progress in the context of sales enablement, customer service, revenue ops, supply chain or what have you, right? So that's the first thing to note. And
they do it inside of e-mail. They do it inside of Teams. They do it inside of Excel, PowerPoint, Word and what have you. Now we have the ability to essentially
bridge the work and the work artifacts inside of these knowledge worker tools with the workflow and the business process and the business process data. So
when we think about our Copilot, our Copilot has that ability to integrate, whether it's with ServiceNow, it has the ability to integrate with SAP with Salesforce, with
obviously Dynamics. That's what we are seeing. In fact, you'll hear us talk a lot about it at our developer conference, which is the extensibility and Copilot Studio
is really off to the races in terms of the product that most people are excited because one of the things in the enterprise if you want to ground your Copilot with
enterprise data, which is in all of these SaaS applications and Copilot Studio is the tool to use it, to make that happen. And so that's what we are seeing, which is
we are building a Copilot, which also happens to be an orchestrator of all in other Copilots, which to us appear as extensions. And net-net, what happens is some
of these knowledge worker tools that people have used all the time, right? Because when you think about Teams, when you're having a meeting, you're not doing
a random meeting, the meeting is in the context of some business process. It could be a supply chain meeting where you're trying to understand which suppliers
to bet on or what terms to do. And so now you can access all that data right in the Team's context. So that's I think what's exciting for us, having built all these
horizontal tools, which I would say we're under underappreciated for the amount of work. How people use those tools to make progress on business process, but
we now get to bridge that between the business applications and knowledge worker tools, tomorrow horizontally.

### Exchange 010

**Raimo Lenschow (Barclays)**: Okay. Perfect. Thank you.

**Brett Iversen (President)**: Thanks Raimo. Operator, next question please.
Operator
And the next question comes from the line of Michael Turrin with Wells Fargo. Please proceed.

### Exchange 011

**Michael Turrin (Wells Fargo)**: Hey. Great. Appreciate you taking the question. I wanted to go back to Azure. You've been hinting at stabilization there for the past couple of quarters, but still
very good to see the balance. Maybe you can expand on just what the commercial bookings number, appreciating the variability there does in terms of visibility.
And any characterization you can give us around what you're seeing in areas like cost optimization and core workload growth coming back is just helpful context
for us in unpacking the numbers. Thank you.

### Exchange 012

**Michael Turrin (Wells Fargo)**: Consistent core cloud growth is still pretty exciting to us as well. Thank you.

**Brett Iversen (President)**: Thanks, Michael. Operator, next question please?
Operator
The next question comes from the line of Kirk Materne with Evercore ISI. Please proceed.

### Exchange 013

**Kirk Materne (Evercore)**: Yes. Thanks for taking the question. I'll add my congrats in the quarter. Hey Satya, I was wondering if you could chime in on a discussion that comes up a lot with
investors, which is, is there a sort of data quality problem in the market in terms of being able to take advantage of all these new GenAI capabilities? And I was
just curious, if you could comment on, do you see companies making inroads on sort of addressing that? And do you see that as sort of an inhibitor to AI growth
at all at this point? Thanks.

**Satya Nadella (CEO)**: Yes, it's a great question because there are two sets of things in order to make sense for successful deployment of these new AI capabilities. I mean if you sort of
say this, what is this AI, it does two things, right? There's a new user experience, there is a natural language interface and second thing is it's the reasoning
engine. And the reasoning engine requires good data, and it's good requires, good data for grounding, right? So people talk about something called retrieval
augmented generation. And in that context, having good grounding data that then help with the reasoning, I think, is helpful. And then, of course, people are also
looking to sort of fine-tune or RLHF or essentially take the large model and ground it further. So all of these tools are now available, the sophistication of how to
people can deploy these models across various business processes where there is data and where there is tuning of these models is also getting more
widespread, even at system integrators and other developers are there to help enterprises. So all that's maturing. So we feel good. And this is what I think on the
commercial side, these are some of the harder problems to solve broad consumer, right? I mean I think this is a couple of orders of magnitude of improvements
in, I'll call it, our models before we can sort of have more sophisticated open-ended consumer scenarios. Whereas in the enterprise, these are all things we can
go tackle. Again, I point to get up, if you think about how it's got an entire system, right? It's just not an AI model. It's the, AI – the user experience, scaffolding, the
editor, the chat, then interpreter and the debugger work along with the continuations of the model to help essentially create these reasoning traces, which help the
entire thing work. And effectively, what we are doing with Copilot, Copilot Studio and connectors to all these business systems, think of it as we are creating
GitHub Copilot like scenarios for every business system. That's what I think is going to have both what Amy referenced is business value and better grounding.
But you're absolutely right in saying a lot of work we're doing with Fabric or Cosmos or PostgreSQL is about preparing that data so that it can be integrated with
these AI projects.

### Exchange 014

**Kirk Materne (Evercore)**: Thank you.

**Brett Iversen (President)**: Thanks, Kirk. Operator, we have time for one last question.
Operator
Our last question will come from the line of Alex Zukin with Wolfe Research. Please proceed.
