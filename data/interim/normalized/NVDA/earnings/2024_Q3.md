# NVDA Q3 2024 Earnings Call

**Document ID**: NVDA_2024_Q3
**Ticker**: NVDA
**Year**: 2024
**Quarter**: Q3
**Utterances**: 21

---

---

## Q&A Session

### Exchange 001

**Vivek Arya (Bank of America)**: Thanks for taking my question. Just, Colette, wanted to clarify what China contributions are you expecting in Q4. And then, Jensen, the main question is for you, 
where do you think we are in the adoption curve in terms of your shipments into the generative AI market? Because when I just look at the trajectory of your data 
center, is growth -- it will be close to nearly 30% of all the spending in data center next year. So what metrics are you keeping an eye on to inform you that you

can continue to grow? Just where are we in the adoption curve of your products into the generative AI market? Thank you.

**Colette Kress (CFO)**: So, first let me start with your question, Vivek, on export controls and the impacts that we are seeing in our Q4 outlook and guidance that we provided. We had
seen historically over the last several quarters that China and some of the other impacted destinations to be about 20% to 25% of our Data Center revenue. We
are expecting in our guidance for that to decrease substantially as we move into Q4. The export controls will have a negative effect on our China business. And
we do not have good visibility into the magnitude of that impact even over the long-term. We are though working to expand our Data Center product portfolio to
possibly offer new regulation compliance solutions that do not require a license, these products, they may become available in the next coming months. However,
we don't expect their contribution to be material or meaningful as a percentage of the revenue in Q4.

### Exchange 002

**Aaron Rakers (Wells Fargo)**: Yeah. Thanks for taking the question. I wanted to ask about kind of the networking side of the business. Given the growth rates that you've now cited, I think, it's
155% year-over-year and strong growth sequentially, it looks like that business is like almost approaching $2.5 billion to $3 billion quarterly level. I'm curious of
how you see Ethernet involved evolving and maybe how you would characterize your differentiation of Spectrum-X relative to the traditional Ethernet stack as we
start to think about that becoming part of the networking narrative above and maybe beyond just InfiniBand as we look into next year? Thank you.

### Exchange 003

**Tim Arcuri (UBS)**: Hi. Thanks. I wanted to ask a little bit about the visibility that you have on revenue. I know there's a few moving parts. I guess, on one hand, the purchase
commitments went up a lot again. But on the other hand, China bans would arguably pull in when you can fill the demand beyond China. So I know we're not
even into 2024 yet and it doesn't sound like, Jensen, you think that next year would be a peak in your Data Center revenue, but I just wanted to sort of explicitly
ask you that. Do you think that Data Center can grow even in 2025? Thanks.

### Exchange 004

**Toshiya Hari (Goldman Sachs)**: Hi. Thank you. I wanted to clarify something with Colette real quick, and then I had a question for Jensen as well. Colette, you mentioned that you'll be introducing
regulation-compliant products over the next couple of months. Yet, the contribution to Q4 revenue should be relatively limited. Is that a timing issue and could it
be a source of reacceleration in growth for Data Center in April and beyond or are the price points such that the contribution to revenue going forward should be
relatively limited? And then the question for Jensen, the AI foundry service announcement from last week. I just wanted to ask about that, and hopefully, have you
expand on it. How is the monetization model going to work? Is it primarily services and software revenue? How should we think about the long term opportunity
set? And is this going to be exclusive to Microsoft or do you have plans to expand to other partners as well? Thank you.

**Colette Kress (CFO)**: Thanks, Toshiya. On the question regarding potentially new products that we could provide to our China customers. It's a significant process to both design and
develop these new products. As we discussed, we're going to make sure that we are in full discussions with the U.S. government of our intent to move products
as well. Given our state about where we are in the quarter, we're already several weeks into the quarter. So it's just going to take some time for us to go through
and discussing with our customers the needs and desires of these new products that we have. And moving forward, whether that's medium-term or long-term, it's
just hard to say both the [Technical Difficulty] of what we can produce with the U.S. government and what the interest of our China customers in this. So we stay
still focused on finding that right balance for our China customers, but it's hard to say at this time.

### Exchange 005

**Stacy Rasgon (Bernstein)**: Hi, guys. Thanks for taking my questions. Colette, I wanted to know if it weren't for the China restrictions would the Q4 guide has been higher or are you
supply-constrained in just reshipping stuff that would have gone to China elsewhere? And I guess along those lines you give us a feeling for where your lead
times are right now in data center and just the China redirection such as-is, is it lowering those lead times, because you've got parts that are sort of immediately
available to ship?

**Colette Kress (CFO)**: Yeah. Stacy, let me see if I can help you understand. Yes, there are still situations where we are working on both improving our supply each and every quarter.
We've done a really solid job of ramping every quarter, which has defined our revenue. But with the absence of China for our outlook for Q4, sure, there could
have been some things that we are not supply-constrained that we could have sold, but kind of we would no longer can. So could our guidance had been a little
higher in our Q4? Yes. We are still working on improving our supply on plan, on continuing growing all throughout next year as well towards that.
Operator
Your next question comes from the line of Matt Ramsay of TD Cowen. Your line is open.

### Exchange 006

**Matt Ramsay (Cowen)**: Thank you very much. Congrats, everybody, on the results. Jensen, I had a two-part question for you, and it comes off of sort of one premise. And the premise is, 
I still get a lot of questions from investors thinking about AI training as being NVIDIA's dominant domain and somehow inference, even large model inference 
takes more and more of the TAM that the market will become more competitive. You'll be less differentiated et cetera., et cetera. So I guess the two parts of the

question are: number one, maybe you could spend a little bit of time talking about the evolution of the inference workload as we move to LLMs and how your
company is positioned for that rather than smaller model inference. And second, up until a month or two ago, I never really got any questions at all about the data
processing piece of the AI workloads. So the pieces of manipulating the data before training, between training and inference, after inference and I think that's a
large part of the workload now. Maybe you could talk about how CUDA is enabling acceleration of those pieces of the workload. Thanks.
