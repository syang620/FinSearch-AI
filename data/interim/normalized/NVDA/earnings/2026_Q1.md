# NVDA Q1 2026 Earnings Call

**Document ID**: NVDA_2026_Q1
**Ticker**: NVDA
**Year**: 2026
**Quarter**: Q1
**Utterances**: 20

---

---

## Q&A Session

### Exchange 001

**Joe Moore (Morgan Stanley)**: Great. Thank you. You guys have talked about this scaling up of inference around reasoning models for, you know, at least a year now, and we've really seen
that come to fruition. As you talked about, we've heard it from your customers. Can you give us a sense for how much of that demand you know, you're able to
serve and give us a sense for maybe how big the inference business is for you guys and, you know, do we need full-on NBL72 Rackscale solutions for reasoning
inference going forward?

**Jensen Huang (CEO)**: Well, we would like to serve all of it. And I think we're on track to serve most of it. Grace Blackwell and VLINK72 is the ideal engine today, the ideal computer
thinking machine, if you will, for reasoning AI. There's a couple of reasons for that. The first reason is that the token generation amount, the number of tokens
reasoning goes through, is a hundred, a thousand times more than a one-shot chatbot. You know, it's essentially thinking to itself, breaking down a problem step
by step. It might be planning multiple paths to an answer. It could be using tools, reading PDFs, reading web pages, watching videos, and then producing a result,
an answer. The longer it thinks, the better the answer, the smarter the answer is. And so what we would like to do and the reason why Grace Blackwell was
designed to give such a giant step up in inference performance is so that you could do all this and still get a response as quickly as possible. Compared to
Hopper, Grace Blackwell is some forty times higher speed and throughput. And so this is going to be a huge benefit in driving down the cost while improving the
quality of response with excellent quality of service at the same time. So that's the fundamental reason. That was a core driving reason for Grace Blackwell
MBLink72. Of course, in order to do that, we had to reinvent literally redesign the entire way that these supercomputers are built. But now we're in full production.
It's going to be exciting. It's going to be incredibly exciting.
Sarah
The next question comes from Vivek Arya with Bank of America Securities. Your line is open.

### Exchange 002

**Vivek Arya (Bank of America)**: Thanks for the question. Just clarification for Colette first. So on the China impact, I think previously it was mentioned that at about $15 billion. So you had the $8
billion in Q2. So is there still some left as a headwind for the remaining quarters? How to model that? And then a question, Jensen, for you. Back at GTC, you had
outlined a path towards almost a trillion dollars of AI spending over the next few years. Where are we in that build-out? And do you think it's going to be uniform
that you will see every spender, whether it's CSP, sovereign enterprises, or build-out? Should we expect some periods of digestion in between? Just what are
your customer discussions telling you about how to model growth for next year?

**Colette Kress (CFO)**: Yes, Vivek. Thanks so much for the question. Regarding H20, yes, we recognized $4.6 billion in H20 in Q1. We were unable to ship $2.5 billion, so the total for
Q1 should have been $7 billion. When we look at our Q2, our Q2 is going to be meaningfully down in terms of China data center revenue. And we had highlighted
in terms of the amount of orders that we had planned for H20 in Q2, and that was $8 billion. Now going forward, we did have other orders going forward that we
will not be able to fulfill. That is what was incorporated, therefore, in the amount that we wrote down of the $4.5 billion. That write-down was about inventory and
purchase commitments. And our purchase commitments were about what we expected regarding the orders that we had received. Going forward, though, it's a
bigger issue regarding the amount of the market that we will not be able to serve. We assess that TAM to be close to about $50 billion in the future, as we don't
have a product to enable for China.

### Exchange 003

**Timothy Arcuri (UBS)**: Thanks a lot. Jensen, I wanted to ask about China. It sounds like the July guidance assumes there's no SKU replacement for the H20. But if the president wants
the US to win, it seems like you're going to have to be allowed to ship something into China. So I guess I had two points on that. First of all, have you been
approved to ship a new modified version into China? And are you currently building it, but you just can't ship it in fiscal Q2? And then you were sort of run rating
$7 to $8 billion a quarter into China. Can we get back to those sorts of quarterly run rates once you get something that you're, you know, allowed to ship back into
China? I think we're all trying to figure out how much to add back to our models and when. So, you know, whatever you can say there would be great. Thanks.

**Jensen Huang (CEO)**: The president has a plan. He has a vision. I trust him. With respect to our export controls, it's a set of limits. And the new set of limits pretty much makes it
impossible for us to reduce Hopper any further, you know, for any productive use. And so the new limits, the new limits, you know, it's kind of the end of the road
for Hopper. We have some limited options, and so the key is to understand the limits. The key is to understand the limits and see if we can come up with
interesting products that could continue to serve the Chinese market. We don't have anything at the moment. But we're considering it. We're thinking about it.
Obviously, the limits are quite stringent at the moment. And we have nothing to announce today. And when the time comes, you know, we'll engage the
administration and discuss that.
Sarah
Your final question comes from the line of Aaron Rakers with Wells Fargo. Your line is open.
Jake

Hi. This is Jake on for Aaron. Thanks for taking the question and congrats on a great quarter. I was wondering if you could give some additional color around the
strength you saw within the networking business, particularly around the adoption of your Ethernet solutions at CSPs, as well as any change you're seeing in
network attach rates.
