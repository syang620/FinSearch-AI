{"chunk_id": "MSFT_TRANSCRIPT_2025_Q2_chunk_0000", "doc_id": "MSFT_TRANSCRIPT_2025_Q2", "source_units": ["MSFT_TRANSCRIPT_2025_Q2_u_0004", "MSFT_TRANSCRIPT_2025_Q2_u_0006"], "source_uri": "data/earnings_calls_manual/MSFT/MSFT_FY2025_Q2.pdf", "ticker": "MSFT", "company": "MSFT", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Keith Weiss", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 419, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Hi. Thank you guys for taking the question. And echoing Amy's comments, Brett, congratulations on the new role. It's been a pleasure working with you and best\nof luck in that new role. Looking at the quarter, another really solid quarter when it comes to commercial bookings. But again, we were a little disappointed on\nAzure coming in at the bottom end of the guidance range. Amy, I was hoping you could dig into perhaps what some of those execution issues were, what the\nresolution to those issues were. And do we still feel comfortable in the acceleration into the back half of the year that you were talking about after the June quarter\nand after last quarter? Thank you very much. Yes. I think, Amy, just one thing I'd add, Keith, to your question is, as Amy said, the AI growth rate is actually better than what we expected, and we work through\nsome of the supply stuff and more importantly, some of the workloads are scaling well. And when you look underneath any of these AI workloads, the other thing\nthat is good is the ratio even what we would call just regular storage, data services, app services. So underneath a ChatGPT or a Copilot or even the emerging AI\nworkloads in the enterprise. So that's all good. The enterprise workloads, whether it's SAP or whether it's VMware migrations, what have you, that's also in good\nshape. And it's just the scale place where Amy talked about this nuance, right, how do you really tweak the incentives, go-to-market at a time of platform shifts,\nyou kind of want to make sure you lean into even the new design wins, and you just don't keep doing the stuff that you did in the previous generation. And that's\nthe art form Amy was referencing to make sure you get the right balance. But let me put it this way. You would rather win the new than just protect the past. And\nthat's sort of another thing that we definitely will lean into always.", "chunked_at": "2025-11-10T02:15:19Z"}
{"chunk_id": "MSFT_TRANSCRIPT_2025_Q2_chunk_0001", "doc_id": "MSFT_TRANSCRIPT_2025_Q2", "source_units": ["MSFT_TRANSCRIPT_2025_Q2_u_0007", "MSFT_TRANSCRIPT_2025_Q2_u_0008"], "source_uri": "data/earnings_calls_manual/MSFT/MSFT_FY2025_Q2.pdf", "ticker": "MSFT", "company": "MSFT", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Keith Weiss", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 33, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Excellent. Thanks, Keith. Operator, next question please.\nOperator\nThe next question comes from the line of Mark Moerdler with Bernstein Research. Please proceed.", "chunked_at": "2025-11-10T02:15:19Z"}
{"chunk_id": "MSFT_TRANSCRIPT_2025_Q2_chunk_0002", "doc_id": "MSFT_TRANSCRIPT_2025_Q2", "source_units": ["MSFT_TRANSCRIPT_2025_Q2_u_0009"], "source_uri": "data/earnings_calls_manual/MSFT/MSFT_FY2025_Q2.pdf", "ticker": "MSFT", "company": "MSFT", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Mark Moerdler", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 87, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Thank you very much for taking my question. Can you give more color on what drove the far larger than expected Microsoft AI revenue. We talked a bit about the \nAzure AI component of it. But can you give more color on that? And our estimates are that the Copilot was much bigger than we had expected and growing much\n\nfaster. Any more details on the breakdown of what that Microsoft AI would be great? Thanks.", "chunked_at": "2025-11-10T02:15:19Z"}
{"chunk_id": "MSFT_TRANSCRIPT_2025_Q2_chunk_0003", "doc_id": "MSFT_TRANSCRIPT_2025_Q2", "source_units": ["MSFT_TRANSCRIPT_2025_Q2_u_0011", "MSFT_TRANSCRIPT_2025_Q2_u_0012"], "source_uri": "data/earnings_calls_manual/MSFT/MSFT_FY2025_Q2.pdf", "ticker": "MSFT", "company": "MSFT", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Mark Moerdler", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 34, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Thank you. Thanks, Mark. Operator, next question please.\nOperator\nThe next question comes from the line of Brent Thill with Jefferies. Please proceed.", "chunked_at": "2025-11-10T02:15:19Z"}
{"chunk_id": "MSFT_TRANSCRIPT_2025_Q2_chunk_0004", "doc_id": "MSFT_TRANSCRIPT_2025_Q2", "source_units": ["MSFT_TRANSCRIPT_2025_Q2_u_0013", "MSFT_TRANSCRIPT_2025_Q2_u_0014"], "source_uri": "data/earnings_calls_manual/MSFT/MSFT_FY2025_Q2.pdf", "ticker": "MSFT", "company": "MSFT", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Brent Thill", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 456, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Thanks. Satya, you mentioned DeepSeek a couple of times in your prepared remarks. I think everyone would love your thoughts on what you're seeing there.\nAnd are we seeing AI scale now at lower cost? Are we reaching a mark where you can see that or do we still have some time to go? Thanks for your thoughts on\nthis. Yes. Thanks, Brent. So, yes, in my remarks, I talked about how in some sense, what's happening with AI is no different than what was happening with the regular\ncompute cycle. It's always about bending the curve and then putting more points up the curve. So there's Moore's Law that's working in hyperdrive. Then on top\nof that, there is the AI scaling laws, both the pre-training and the inference time compute that compound and that's all software. You should think of what I said in\nmy remarks, which we have observed for a while, which is 10x on improvements per cycle just because of all the software optimizations on inference. And so\nthat's what you see. And then to that, I think DeepSeek has had some real innovations. And that is some of the things that even OpenAI found in o1. And so we\nare going to, obviously, now that all gets commoditized, and it's going to get broadly used. And the big beneficiaries of any software cycle like that is the\ncustomers, right. Because at the end of the day, if you think about it, right, what was the big lesson learned from client server to cloud, more people bought\nservers except it was called cloud. And so when token prices fall, infants computing prices fall, that means people can consume more, and there'll be more apps\nwritten. And it's interesting to see that when I referenced these models that are pretty powerful, it's unimaginable to think that here we are in sort of beginning of\n'25 where on the PC, you can run a model that required pretty massive cloud infrastructure. So that type of optimizations means AI will be much more ubiquitous.\nAnd so therefore, for a hyperscaler like us, a PC platform provider like us, this is all good news as far as I'm concerned.", "chunked_at": "2025-11-10T02:15:19Z"}
{"chunk_id": "MSFT_TRANSCRIPT_2025_Q2_chunk_0005", "doc_id": "MSFT_TRANSCRIPT_2025_Q2", "source_units": ["MSFT_TRANSCRIPT_2025_Q2_u_0015", "MSFT_TRANSCRIPT_2025_Q2_u_0016"], "source_uri": "data/earnings_calls_manual/MSFT/MSFT_FY2025_Q2.pdf", "ticker": "MSFT", "company": "MSFT", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Brent Thill", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 34, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Thank you. Thanks, Brent. Operator, next question please.\nOperator\nThe next question comes from the line of Karl Keirstead with UBS. Please proceed.", "chunked_at": "2025-11-10T02:15:19Z"}
{"chunk_id": "MSFT_TRANSCRIPT_2025_Q2_chunk_0006", "doc_id": "MSFT_TRANSCRIPT_2025_Q2", "source_units": ["MSFT_TRANSCRIPT_2025_Q2_u_0017", "MSFT_TRANSCRIPT_2025_Q2_u_0018"], "source_uri": "data/earnings_calls_manual/MSFT/MSFT_FY2025_Q2.pdf", "ticker": "MSFT", "company": "MSFT", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Karl Keirstead", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 594, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Thank you. Maybe this one as well for Satya and it's also away from the numbers. But Satya, I wanted to ask you about the Stargate news and the announced\nchanges in the OpenAI relationship last week. It seems that most of your investors have interpreted this as Microsoft, for sure, remaining very committed to\nOpenAI's success. But electing to take more of a backseat in terms of funding OpenAI's future training CapEx needs. I was hoping you might frame your strategic\ndecision here around Stargate, and Amy, whether there's any takeaway for investors from that decision in terms of how you're thinking about CapEx needs over\nthe next several years. Thank you. Yes. Thanks for the question. So we remain very happy with the partnership with OpenAI. And as you saw, they have committed in a big way to Azure and even \nin the bookings what we recognize is just the first tranche of it. And so you'll see given the ROFR we have more benefits of that even into the future. And \nobviously, their success is our success because even all the other commercial arrangements that we detailed out in the blog that we put out even commensurate \nwith that announcement. But to your overall point, the thing that I would say is we are building a pretty fungible fleet, right. We're making sure that there's the right \nbalance between training and inference. It's geo distributed. We are working super hard on all the software oppositions, right. I mean just not the software \noptimizations that come because of what DeepSeek has done, but all the work we have done to, for example, reduce the prices of GPT models, over the years in \npartnership with OpenAI. In fact, we did a lot of the work on the inference optimizations on it and that's been key to driving, right. One of the key things to note in \nAI is you just don't launch the frontier model, but if it's too expensive to serve, it's no good, right. It won't generate any demand. So you've got to have that \noptimization, so that inferencing costs are coming down and they can be consumed broadly. And so that's the fleet physics we are managing. And also,\n\nremember, you don't want to buy too much of anything at one time because the Moore's Law every year is going to give you 2x, your optimization is going to give\nyou 10x. You want to continuously upgrade the fleet, modernize the fleet, age, the fleet, and at the end of the day, have the right ratio of monetization and\ndemand-driven monetization to what you think of as the training expense. So I feel very good about the investment we are making and it's fungible and it just\nallows us to scale more long-term business.", "chunked_at": "2025-11-10T02:15:19Z"}
{"chunk_id": "MSFT_TRANSCRIPT_2025_Q2_chunk_0007", "doc_id": "MSFT_TRANSCRIPT_2025_Q2", "source_units": ["MSFT_TRANSCRIPT_2025_Q2_u_0020", "MSFT_TRANSCRIPT_2025_Q2_u_0021"], "source_uri": "data/earnings_calls_manual/MSFT/MSFT_FY2025_Q2.pdf", "ticker": "MSFT", "company": "MSFT", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Karl Keirstead", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 35, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Thank you. Thanks, Karl. Operator, next question please.\nOperator\nAnd the next question comes from the line of Brad Zelnick with Deutsche Bank. Please proceed.", "chunked_at": "2025-11-10T02:15:19Z"}
{"chunk_id": "MSFT_TRANSCRIPT_2025_Q2_chunk_0008", "doc_id": "MSFT_TRANSCRIPT_2025_Q2", "source_units": ["MSFT_TRANSCRIPT_2025_Q2_u_0022", "MSFT_TRANSCRIPT_2025_Q2_u_0023"], "source_uri": "data/earnings_calls_manual/MSFT/MSFT_FY2025_Q2.pdf", "ticker": "MSFT", "company": "MSFT", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Brad Zelnick", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 371, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Thank you very much for taking my question. And I'll echo my congrats and gratitude to Brett as well. Satya, as we think about Microsoft's very rich Copilot\nportfolio, now having been in market for over a year, with the products and precision only getting better and the cost of inference coming down, how do you think\nabout the journey from here and perhaps the ability to package and evolve the go-to-market to address the broadest range of customers and customer\nrequirements out there? Thanks. Thanks, Brad, for the question. In fact you saw us make two announcements recently. One is on the M365 Copilot side, we now have the Copilot Chat. So this is\nnow going to be broadly deployed across the entire install base effectively because you can go have this now turned on by IT and everybody can start using\nweb-grounded chat with all the enterprise controls right away it has Copilot Studio built in. And so that means they can start building agents. So we think of that\nplus the full Copilot as a good combination that I think will accelerate quite frankly in terms of just seat usage and agent building and what have you. So that's sort\nof one. And the other thing is you also see even on the consumer side, we just yesterday launched o1, the Think Harder feature on Copilot now that's powered by\no1, it's available globally, right. So you can see the benefits of inference optimization and the cost coming down means you can drive more ubiquity of what were\nfeatures that ones were sort of premium tier and that's all definitely something that we will do across, right. The same thing is happening in GitHub Copilot, same\nthing in Security Copilot. So across the length and breadth of our portfolio, you'll see that.", "chunked_at": "2025-11-10T02:15:19Z"}
{"chunk_id": "MSFT_TRANSCRIPT_2025_Q2_chunk_0009", "doc_id": "MSFT_TRANSCRIPT_2025_Q2", "source_units": ["MSFT_TRANSCRIPT_2025_Q2_u_0024", "MSFT_TRANSCRIPT_2025_Q2_u_0025"], "source_uri": "data/earnings_calls_manual/MSFT/MSFT_FY2025_Q2.pdf", "ticker": "MSFT", "company": "MSFT", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Brad Zelnick", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 34, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Thank you. Thanks, Brad. Operator, next question please.\nOperator\nThe next question comes from the line of Brad Reback with Stifel. Please proceed.", "chunked_at": "2025-11-10T02:15:19Z"}
{"chunk_id": "MSFT_TRANSCRIPT_2025_Q2_chunk_0010", "doc_id": "MSFT_TRANSCRIPT_2025_Q2", "source_units": ["MSFT_TRANSCRIPT_2025_Q2_u_0026", "MSFT_TRANSCRIPT_2025_Q2_u_0027"], "source_uri": "data/earnings_calls_manual/MSFT/MSFT_FY2025_Q2.pdf", "ticker": "MSFT", "company": "MSFT", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Brad Reback", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 404, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "That's great. Thank you very much. Satya, if you look out several years, any sense of what percent of inference done on Azure will be done on proprietary models\nversus open models. And with that said, does it matter to Microsoft at the end of the day? Thanks. Yes, it's a good question because at some level, what you're seeing is effectively lots of models that get used in any application, right. When you look underneath \neven a Copilot or a GitHub Copilot or what have you, you already see lots of many different models that you build models, you fine tune models, you distill \nmodels. Some of them are models that you distill into an open source model. So there's going to be a combination. So we've always maintained that it's always \ngood to have frontier models. You want to always build your application with high ambition using the best model that is available and then optimize from there on.\n\nSo that's also another side like there's a temporality to it, right. What you start with as a given COGS profile doesn't need to be the end because you continuously\noptimize for latency and COGS and putting in different mode. And in fact, all that complexity, by the way, has to be managed by a new app server. So one of the\nthings that we are investing heavily on is foundry because from an app developer perspective, you kind of want to keep pace with the flurry of models that are\ncoming in and you want to have an evergreen way for your application to benefit from all that innovation. But not have all the Dev cost or the DevOps cost or what\npeople talk about AIOps costs. So we are also investing significantly in all the app server for any workload to be able to benefit from all these different models,\nopen source, close source, different weight classes. And at the same time, from an operations perspective, it's faster, easier for you.", "chunked_at": "2025-11-10T02:15:19Z"}
{"chunk_id": "MSFT_TRANSCRIPT_2025_Q2_chunk_0011", "doc_id": "MSFT_TRANSCRIPT_2025_Q2", "source_units": ["MSFT_TRANSCRIPT_2025_Q2_u_0028", "MSFT_TRANSCRIPT_2025_Q2_u_0029"], "source_uri": "data/earnings_calls_manual/MSFT/MSFT_FY2025_Q2.pdf", "ticker": "MSFT", "company": "MSFT", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Brad Reback", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 37, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Great. Thank you. Thanks, Brad. Operator, next question please.\nOperator\nAnd the next question comes from the line of Brad Sills with Bank of America. Please proceed.", "chunked_at": "2025-11-10T02:15:19Z"}
{"chunk_id": "MSFT_TRANSCRIPT_2025_Q2_chunk_0012", "doc_id": "MSFT_TRANSCRIPT_2025_Q2", "source_units": ["MSFT_TRANSCRIPT_2025_Q2_u_0034"], "source_uri": "data/earnings_calls_manual/MSFT/MSFT_FY2025_Q2.pdf", "ticker": "MSFT", "company": "MSFT", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Brent Bracelin", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 145, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Thank you for taking the question here. Good afternoon. I wanted to go back to commercial Bookings. Commercial RPO, I think, increased 39 billion sequentially.\nThat's the most we've ever seen on a sequential basis, commercial bookings growth, 75% constant currency. That's 2x higher than we've seen in the last decade.\nI appreciate there's some volatility with this metric, but it does feel like this quarter there was a bit of a sea change relative to momentum on backlog and\nbookings. Can you just talk about maybe the breadth of where that strength came from? Was it broad-based? Was there a couple of large deals? Any color there\nwould be helpful? Thanks.", "chunked_at": "2025-11-10T02:15:19Z"}
{"chunk_id": "MSFT_TRANSCRIPT_2025_Q2_chunk_0013", "doc_id": "MSFT_TRANSCRIPT_2025_Q2", "source_units": ["MSFT_TRANSCRIPT_2025_Q2_u_0036", "MSFT_TRANSCRIPT_2025_Q2_u_0037"], "source_uri": "data/earnings_calls_manual/MSFT/MSFT_FY2025_Q2.pdf", "ticker": "MSFT", "company": "MSFT", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Brent Bracelin", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 41, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Helpful color. Thank you. Thanks, Brad. That wraps up the Q&A portion of today's earnings call. Thank you for joining today and we look forward to speaking with all of you soon.", "chunked_at": "2025-11-10T02:15:19Z"}
