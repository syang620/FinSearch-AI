{"chunk_id": "NVDA_TRANSCRIPT_2026_Q1_chunk_0000", "doc_id": "NVDA_TRANSCRIPT_2026_Q1", "source_units": ["NVDA_TRANSCRIPT_2026_Q1_u_0007", "NVDA_TRANSCRIPT_2026_Q1_u_0008"], "source_uri": "data/earnings_calls_manual/NVDA/NVDA_FY2026_Q1.pdf", "ticker": "NVDA", "company": "NVDA", "doc_type": "earnings_transcript", "fiscal_year": 2026, "quarter": "Q1", "period": "2026-Q1", "section_id": null, "section_title": null, "speaker": "Joe Moore", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 473, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Great. Thank you. You guys have talked about this scaling up of inference around reasoning models for, you know, at least a year now, and we've really seen\nthat come to fruition. As you talked about, we've heard it from your customers. Can you give us a sense for how much of that demand you know, you're able to\nserve and give us a sense for maybe how big the inference business is for you guys and, you know, do we need full-on NBL72 Rackscale solutions for reasoning\ninference going forward? Well, we would like to serve all of it. And I think we're on track to serve most of it. Grace Blackwell and VLINK72 is the ideal engine today, the ideal computer\nthinking machine, if you will, for reasoning AI. There's a couple of reasons for that. The first reason is that the token generation amount, the number of tokens\nreasoning goes through, is a hundred, a thousand times more than a one-shot chatbot. You know, it's essentially thinking to itself, breaking down a problem step\nby step. It might be planning multiple paths to an answer. It could be using tools, reading PDFs, reading web pages, watching videos, and then producing a result,\nan answer. The longer it thinks, the better the answer, the smarter the answer is. And so what we would like to do and the reason why Grace Blackwell was\ndesigned to give such a giant step up in inference performance is so that you could do all this and still get a response as quickly as possible. Compared to\nHopper, Grace Blackwell is some forty times higher speed and throughput. And so this is going to be a huge benefit in driving down the cost while improving the\nquality of response with excellent quality of service at the same time. So that's the fundamental reason. That was a core driving reason for Grace Blackwell\nMBLink72. Of course, in order to do that, we had to reinvent literally redesign the entire way that these supercomputers are built. But now we're in full production.\nIt's going to be exciting. It's going to be incredibly exciting.\nSarah\nThe next question comes from Vivek Arya with Bank of America Securities. Your line is open.", "chunked_at": "2025-11-10T02:18:28Z"}
{"chunk_id": "NVDA_TRANSCRIPT_2026_Q1_chunk_0001", "doc_id": "NVDA_TRANSCRIPT_2026_Q1", "source_units": ["NVDA_TRANSCRIPT_2026_Q1_u_0009", "NVDA_TRANSCRIPT_2026_Q1_u_0010"], "source_uri": "data/earnings_calls_manual/NVDA/NVDA_FY2026_Q1.pdf", "ticker": "NVDA", "company": "NVDA", "doc_type": "earnings_transcript", "fiscal_year": 2026, "quarter": "Q1", "period": "2026-Q1", "section_id": null, "section_title": null, "speaker": "Vivek Arya", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 406, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Thanks for the question. Just clarification for Colette first. So on the China impact, I think previously it was mentioned that at about $15 billion. So you had the $8\nbillion in Q2. So is there still some left as a headwind for the remaining quarters? How to model that? And then a question, Jensen, for you. Back at GTC, you had\noutlined a path towards almost a trillion dollars of AI spending over the next few years. Where are we in that build-out? And do you think it's going to be uniform\nthat you will see every spender, whether it's CSP, sovereign enterprises, or build-out? Should we expect some periods of digestion in between? Just what are\nyour customer discussions telling you about how to model growth for next year? Yes, Vivek. Thanks so much for the question. Regarding H20, yes, we recognized $4.6 billion in H20 in Q1. We were unable to ship $2.5 billion, so the total for\nQ1 should have been $7 billion. When we look at our Q2, our Q2 is going to be meaningfully down in terms of China data center revenue. And we had highlighted\nin terms of the amount of orders that we had planned for H20 in Q2, and that was $8 billion. Now going forward, we did have other orders going forward that we\nwill not be able to fulfill. That is what was incorporated, therefore, in the amount that we wrote down of the $4.5 billion. That write-down was about inventory and\npurchase commitments. And our purchase commitments were about what we expected regarding the orders that we had received. Going forward, though, it's a\nbigger issue regarding the amount of the market that we will not be able to serve. We assess that TAM to be close to about $50 billion in the future, as we don't\nhave a product to enable for China.", "chunked_at": "2025-11-10T02:18:28Z"}
{"chunk_id": "NVDA_TRANSCRIPT_2026_Q1_chunk_0002", "doc_id": "NVDA_TRANSCRIPT_2026_Q1", "source_units": ["NVDA_TRANSCRIPT_2026_Q1_u_0016", "NVDA_TRANSCRIPT_2026_Q1_u_0017"], "source_uri": "data/earnings_calls_manual/NVDA/NVDA_FY2026_Q1.pdf", "ticker": "NVDA", "company": "NVDA", "doc_type": "earnings_transcript", "fiscal_year": 2026, "quarter": "Q1", "period": "2026-Q1", "section_id": null, "section_title": null, "speaker": "Timothy Arcuri", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 472, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Thanks a lot. Jensen, I wanted to ask about China. It sounds like the July guidance assumes there's no SKU replacement for the H20. But if the president wants\nthe US to win, it seems like you're going to have to be allowed to ship something into China. So I guess I had two points on that. First of all, have you been\napproved to ship a new modified version into China? And are you currently building it, but you just can't ship it in fiscal Q2? And then you were sort of run rating\n$7 to $8 billion a quarter into China. Can we get back to those sorts of quarterly run rates once you get something that you're, you know, allowed to ship back into\nChina? I think we're all trying to figure out how much to add back to our models and when. So, you know, whatever you can say there would be great. Thanks. The president has a plan. He has a vision. I trust him. With respect to our export controls, it's a set of limits. And the new set of limits pretty much makes it\nimpossible for us to reduce Hopper any further, you know, for any productive use. And so the new limits, the new limits, you know, it's kind of the end of the road\nfor Hopper. We have some limited options, and so the key is to understand the limits. The key is to understand the limits and see if we can come up with\ninteresting products that could continue to serve the Chinese market. We don't have anything at the moment. But we're considering it. We're thinking about it.\nObviously, the limits are quite stringent at the moment. And we have nothing to announce today. And when the time comes, you know, we'll engage the\nadministration and discuss that.\nSarah\nYour final question comes from the line of Aaron Rakers with Wells Fargo. Your line is open.\nJake\n\nHi. This is Jake on for Aaron. Thanks for taking the question and congrats on a great quarter. I was wondering if you could give some additional color around the\nstrength you saw within the networking business, particularly around the adoption of your Ethernet solutions at CSPs, as well as any change you're seeing in\nnetwork attach rates.", "chunked_at": "2025-11-10T02:18:28Z"}
