{"chunk_id": "AVGO_TRANSCRIPT_2025_Q3_chunk_0000", "doc_id": "AVGO_TRANSCRIPT_2025_Q3", "source_units": ["AVGO_TRANSCRIPT_2025_Q3_u_0000", "AVGO_TRANSCRIPT_2025_Q3_u_0001", "AVGO_TRANSCRIPT_2025_Q3_u_0002", "AVGO_TRANSCRIPT_2025_Q3_u_0003"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q3.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q3", "period": "2025-Q3", "section_id": null, "section_title": null, "speaker": "Ji Yoo", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 800, "start_token": 0, "end_token": 800, "chunk_type": "windowed_overlap", "overlap_with_prev": 0, "overlap_with_next": 120, "text": "Welcome to Broadcom Inc. Third Quarter fiscal year 2025 financial results conference call. At this time, for opening remarks and introductions, I would like to turn\nthe call over to Ji Yoo, Head of Investor Relations of Broadcom Inc. Please go ahead. Thank you, Sherry, and good afternoon, everyone. Joining me on today's\ncall are Hock Tan, President and CEO, Kirsten Spears, Chief Financial Officer, and Charlie Coaz, President, Semiconductor Solutions Group. Broadcom\ndistributed a press release and financial tables after the market closed describing our financial performance for 2025. If you did not receive a copy, you may\nobtain the information from the investors section of Broadcom's website at broadcom.com. This conference call is being webcast live, and an audio replay of the\ncall can be accessed for one year through the Investors section of Broadcom's website. During the prepared comments, Hock and Kirsten will be providing details\nof our third quarter fiscal year 2025 results, guidance for our 2025, as well as commentary regarding the business environment. We will take questions after the\nend of our prepared comments. Please refer to our press release today and our recent filings with the SEC for information on the specific risk factors that could\ncause our actual results to differ materially from the forward-looking statements made on this call. In addition to U.S. GAAP reporting, Broadcom reports certain\nfinancial measures on a non-GAAP basis. A reconciliation between GAAP and non-GAAP measures is included in the tables attached to today's press release.\nComments made during today's call will primarily refer to our non-GAAP financial results. I will now turn the call over to Hock. Thank you, Ji. And thank you everyone for joining us today. In our fiscal Q3 2025, total revenue was a record $16 billion, up 22% year on year. Now revenue\ngrowth was driven by better than expected strength in AI semiconductors, and our continued growth in VMware. Q3 consolidated adjusted EBITDA was a record\n$10.7 billion, up 30% year on year. Now, looking beyond what we are just reporting this quarter, with robust demand from AI bookings, were extremely strong.\nAnd our current consolidated backlog for the company hit a record of $110 billion. Q3 semiconductor revenue was $9.2 billion as year on year growth accelerated\nto 26% year on year. And this accelerated growth was driven by AI Semiconductor revenue of $5.2 billion, which was up 63% year on year and extend the\ntrajectory of robust growth to 10 consecutive quarters. Now let me give you more color on our XPU business, which accelerated to 65% of our AI revenue this\nquarter. Demand for custom AI accelerators from our three customers continued to grow as each of them journeys at their own pace towards compute\nself-sufficiency. And progressively, we continue to gain share with these customers. Now, further to these three customers, as we have previously mentioned, we\nhave been working with other prospects on their own AI accelerators. Last quarter, one of these prospects released production orders to Broadcom. And we have\naccordingly characterized them as a qualified customer for XPUs. And in fact, has secured over $10 billion of orders of AI regs based on our XPUs. And reflecting\nthis, we now expect the outlook for fiscal 2026 AI revenue to improve significantly from what we had indicated last quarter. Turning to AI networking. Demand\ncontinued to be strong. Because networking is becoming critical as LLMs continue to evolve in intelligence and compute classes have to grow bigger. The\nnetwork is the computer. And our customers are facing challenges as they scale to clusters beyond 100,000 compute nodes. For instance, scale up which we all\nknow about, is a difficult challenge.", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q3_chunk_0001", "doc_id": "AVGO_TRANSCRIPT_2025_Q3", "source_units": ["AVGO_TRANSCRIPT_2025_Q3_u_0000", "AVGO_TRANSCRIPT_2025_Q3_u_0001", "AVGO_TRANSCRIPT_2025_Q3_u_0002", "AVGO_TRANSCRIPT_2025_Q3_u_0003"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q3.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q3", "period": "2025-Q3", "section_id": null, "section_title": null, "speaker": "Ji Yoo", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 800, "start_token": 680, "end_token": 1480, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 120, "text": " over $10 billion of orders of AI regs based on our XPUs. And reflecting\nthis, we now expect the outlook for fiscal 2026 AI revenue to improve significantly from what we had indicated last quarter. Turning to AI networking. Demand\ncontinued to be strong. Because networking is becoming critical as LLMs continue to evolve in intelligence and compute classes have to grow bigger. The\nnetwork is the computer. And our customers are facing challenges as they scale to clusters beyond 100,000 compute nodes. For instance, scale up which we all\nknow about, is a difficult challenge. When you are trying to create substantial bandwidth to share memory across multiple GPUs or XPUs with the direct Today's\nAI rank scales up a mere 72 GPUs at 28.8 terabit per second bandwidth using a proprietary NVLink. On the other hand, earlier this year, we have launched\nTomahawk five We've opened AI we've opened Ethernet. Sorry. Which can scale up 512 compute nodes for customers using XPUs. Moving on to scaling out\nacross regs. Today, the current architecture using 51.2 terabit per second requires three tiers of networking switches. In June, we launched Tomahawk six and\nour Ethernet based 102 terabit per second switch which flattens the network. To two tiers. Resulting in lower latency much less power. And when you scale to\nclusters beyond single data center footprint, You now need to scale computing across data centers. And over the past two years, we have deployed our Jericho\nthree Ethernet router with hyperscale customers to just do this. And today, we have launched our next generation Jericho four. Ethernet fabric router with 51.2\nterabit per second deep buffering intelligence intelligent congestion control, to handle classes beyond 200,000 compute nodes crossing multiple data centers. We\nknow the biggest challenge to deploying larger clusters of compute for generative AI will be in networking. And for the past twenty years, Broadcom has\ndeveloped for Ethernet, networking is entirely applicable to the challenges of scale up, scale out, and scale across in generative AI. And turning to our forecast as\nI mentioned earlier, we continue to make steady progress in growing our AI revenue. For Q4, 2025, we forecast AI semiconductor revenue to be approximately\n$6.2 billion, up 66% year on year. Now, turning to non AI semiconductors. Demand continues to be slow to recover. In Q3 revenue of $4 billion was flat\nsequentially. While broadband showed strong sequential growth, Enterprise networking and service storage were down sequentially. Wireless and industrial were\nflat quarter on quarter as we expect. In contrast, in Q4, driven by seasonality, we forecast non AI semiconductor revenue to grow low double digits sequentially to\napproximately $4.6 billion. Broadband, server storage and wireless are expected to improve. While enterprise networking remains down quarter on quarter. Now\nlet me talk about our infrastructure software segment. Q3 Infrastructure Software revenue of $6.8 billion was 17% year on year. Above our outlook of $6.7 billion\nas bookings continue to be strong during the quarter. We booked in fact total contract value over $8.4 billion during Q3. But here's one I'm most excited about.\nAfter two years of engineering development by over 5,000 developers. We deliver on a promise. When we acquired VMware. We release VMware Cloud\nFoundation version nine dot zero a fully integrated cloud platform which can be deployed by enterprise customers on prem or carry to the cloud. It enables\nenterprises to run any application workload including AI workloads, on virtual machines and on modern containers. These provides the real alternative to public\nclub. In Q4, we expect Infrastructure and Software revenue to be approximately $6.7 billion, up 15% year on year. And in", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q3_chunk_0002", "doc_id": "AVGO_TRANSCRIPT_2025_Q3", "source_units": ["AVGO_TRANSCRIPT_2025_Q3_u_0000", "AVGO_TRANSCRIPT_2025_Q3_u_0001", "AVGO_TRANSCRIPT_2025_Q3_u_0002", "AVGO_TRANSCRIPT_2025_Q3_u_0003"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q3.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q3", "period": "2025-Q3", "section_id": null, "section_title": null, "speaker": "Ji Yoo", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 541, "start_token": 1360, "end_token": 1901, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 0, "text": " excited about.\nAfter two years of engineering development by over 5,000 developers. We deliver on a promise. When we acquired VMware. We release VMware Cloud\nFoundation version nine dot zero a fully integrated cloud platform which can be deployed by enterprise customers on prem or carry to the cloud. It enables\nenterprises to run any application workload including AI workloads, on virtual machines and on modern containers. These provides the real alternative to public\nclub. In Q4, we expect Infrastructure and Software revenue to be approximately $6.7 billion, up 15% year on year. And in summary, continued strength in AI and\nVMware would drive our guidance for Q4 consolidated revenue to approximately $17.4 billion, up 24% year on year. And we expect Q4 adjusted EBITDA to be\n67% of revenue. And with that, let me turn the call over to Kirsten. Thank you, Hock. Let me now provide additional detail on our Q3 financial performance. Consolidated revenue was a record $16 billion for the quarter, up 22% \nfrom a year ago. Gross margin was 78.4% of revenue in the quarter, better than we originally guided on higher software revenues and product mix within \nsemiconductors. Consolidated operating expenses were $2 billion of which $1.5 billion was research and development. Q3 operating income was a record $10.5 \nbillion, up 32% from a year ago. On a sequential basis, even as gross margin was down 100 basis points on revenue mix, operating margin increased 20 basis \npoints sequentially to 65.5% on operating leverage. Adjusted EBITDA of $10.7 billion or 67% of revenue was above our guidance of 66%. This figure excludes a \n$142 million of depreciation. Now a review of the P and L for our two segments. Starting with semiconductors. Revenue for our Semiconductor Solutions segment \nwas $9.2 billion with growth accelerating to 26% year on year driven by AI. Semiconductor revenue represented 57% of total revenue in the quarter. Gross margin \nfor our Semiconductor Solutions segment was approximately 67% down 30 basis points year on year on product mix. Operating expenses increased 9% year on \nyear to $951 million on increased investment in R and D for leading edge AI semiconductors. Semiconductor operating margin of 57% was up 130 basis points \nyear on year and flat sequentially. Now moving on to infrastructure software. Revenue for infrastructure software of $6.8 billion was up 17% year on year and", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q3_chunk_0003", "doc_id": "AVGO_TRANSCRIPT_2025_Q3", "source_units": ["AVGO_TRANSCRIPT_2025_Q3_u_0000", "AVGO_TRANSCRIPT_2025_Q3_u_0001", "AVGO_TRANSCRIPT_2025_Q3_u_0002", "AVGO_TRANSCRIPT_2025_Q3_u_0003"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q3.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q3", "period": "2025-Q3", "section_id": null, "section_title": null, "speaker": "Ji Yoo", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 698, "start_token": 0, "end_token": 0, "chunk_type": "prepared_packed", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "represented 43% of revenue. Gross margin for infrastructure software 93% in the quarter compared to 90% a year ago. Operating expenses were $1.1 billion in\nthe quarter, resulting in infrastructure software operating margin of approximately 77%. This compares to operating margin of 67% a year ago reflecting the\ncompletion of the integration of VMware. Moving on to cash flow. Free cash flow in the quarter was $7 billion and represented 44% of revenue. We spent $142\nmillion on capital expenditures. Day sales outstanding were thirty seven days in the third quarter compared to thirty two days a year ago. We ended the third\nquarter with inventory of $2.2 billion up 8% sequentially in anticipation of revenue growth next quarter. Our days of inventory on hand were sixty six days in Q3,\ncompared to sixty nine days in Q2 as we continue to remain disciplined on how we manage inventory across the ecosystem. We ended the third quarter with\n$10.7 billion of cash and $66.3 billion of gross principal debt. The weighted average coupon rate and years to maturity of our $65.8 billion in fixed rate debt is\n3.9% and 6.9 years, respectively. The weighted average interest rate and years to maturity of our $500 million at floating rate debt is 4.7% and 0.2 years,\nrespectively. Turning to capital allocation. Q3, we paid stockholders $2.8 billion of cash dividends, based on a quarterly common stock cash dividend of $0.59 per\nshare. We expect the non GAAP diluted share count to be In Q4, approximately 4.97 billion shares, excluding the potential impact of any share repurchases. Now\nmoving to guidance. Our guidance for Q4 is for consolidated revenue of $17.4 billion up 24% year on year. We forecast semiconductor revenue of approximately\n$10.7 billion up 30% year on year. Within this, we expect Q4 AI semiconductor revenue of $6.2 billion up 66% year on year. We expect infrastructure software\nrevenue of approximately $6.7 billion up 15% year on year. For your modeling purposes, we expect Q4 consolidated gross margin to be down approximately 70\nbasis points sequentially primarily reflecting a higher mix of XPUs and also wireless revenue. As a reminder, consolidated gross margins through the year will be\nimpacted by the revenue mix of infrastructure software and product mix within semiconductors. We expect Q4 adjusted EBITDA to be 67%. We expect the non\nGAAP tax rate for Q4 and fiscal year 2025 to remain at 14%. I will now pass the call back to Hock for some more exciting news. I don't know about exciting, Kirsten, but I do. I thought before we move to questions, I should share an update. The board and I have agreed that I will continue as\nthe CEO of Broadcom through 2030 at least. These are exciting times for Broadcom, and I'm very enthusiastic to continue to drive value for our shareholders.\nOperator, please open up the call for questions.\nOperator\nThank you. Star one one again. Due to time restraints, we ask that you please limit And our first question will come from the line of Ross Seymore with Deutsche\nBank. Your line is open.", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q3_chunk_0004", "doc_id": "AVGO_TRANSCRIPT_2025_Q3", "source_units": ["AVGO_TRANSCRIPT_2025_Q3_u_0006", "AVGO_TRANSCRIPT_2025_Q3_u_0007"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q3.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q3", "period": "2025-Q3", "section_id": null, "section_title": null, "speaker": "Harlan Sur", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 693, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Hi. Good afternoon. Congratulations on a well executed quarter and strong free cash flow. Know everybody's gonna ask a lot of questions on AI, Hock. I'm gonna\nask about the non AI simulators If I look at your guidance for Q4, it looks like the non AI streaming business is gonna be down about 78% year over year on fiscal\ntwenty five if you hit the midpoint of the Q4 guidance. Good news, is that the negative year over year trends have been improving to the year, in fact, think you\nguys are gonna be positive year over year in the fourth quarter. You've characterized it as relatively close to the cyclical bottom, relatively slow to recover.\nHowever, we have seen some green shoots of positivity. Right? Broadband server storage, enterprise networking. You're still driving the DOCSIS four upgrade in\nbroadband, cable, You've got next gen PON upgrades in China and The US in front of you. Enterprise spending on network upgrades is accelerating. So near\nterm, from the cyclical bottom, how should we think about the magnitude of the cyclical upturn? And given your thirty to forty week lead times, are you seeing\ncontinued order improvements in the non AI segment, which would point you to continued cyclical recovery into next fiscal year? Well, you know, then if you take a look at that non AI segment, I mean, you're right. From a year on year Q4 guidance, we are actually up, as you say, slightly.\nCouple one or 2% from a year ago. And it's not much really to shout about at this point. And the and the big issue is the puts and takes. And the puts and takes\nand the bottom line to all this is other than seasonality that we perceive if you look at it short term, we've all looking year on year, but looking sequentially. We see\nin things like wireless and we even start to see some seasonality in server storage these days. We don't kind of all washes out so far. The only consistent trend\nwe've seen over the last three quarters that is moving up strongly is broadband. And nothing else if you look at it from a cyclical point of view, seems to be able to\nsustain an uptrend so far. I don't think it's getting but as a whole, they are not getting worse as you pointed out, Harlan. But they are not showing a v shaped\nrecovery as a whole. That we would like to see to see and expect to see in in cyclical semiconductor cycles. The only thing that gives us some hope is broadband\nat this point. And it is recovering very strongly. But then it was the business that was most impacted in the in the sharp downturn of '24 and early twenty five. So\nagain, one takes that with a grain of salt. But best answer to you for you is non non AI semiconductor is kind of slow to recover as I said. And Q4 year on year is\nup maybe low single digits. Is the best way to to describe it at this point. So I'm expecting to see more of a u shaped recovery in non AI. And perhaps by late\ntwenties mid twenty six, late twenty six, we'll start to see some meaningful recovery. But as of right now, not clear.", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q3_chunk_0005", "doc_id": "AVGO_TRANSCRIPT_2025_Q3", "source_units": ["AVGO_TRANSCRIPT_2025_Q3_u_0008", "AVGO_TRANSCRIPT_2025_Q3_u_0009"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q3.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q3", "period": "2025-Q3", "section_id": null, "section_title": null, "speaker": "Harlan Sur", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 118, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Mhmm. Are are you starting to see that in your order trend in your order book just because your lead times are, like, forty weeks. Right? We are. But we've been tricked before. But we are. The bookings are up, and they are up year on year in excess of 20%. Nothing like what AI bookings look like.\nBut 23% is still pretty good. Right?\nOperator\nThank you. One moment for our next question. That will come from the line of Vivek Arya with Bank of America. Your line is open.", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q3_chunk_0006", "doc_id": "AVGO_TRANSCRIPT_2025_Q3", "source_units": ["AVGO_TRANSCRIPT_2025_Q3_u_0010"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q3.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q3", "period": "2025-Q3", "section_id": null, "section_title": null, "speaker": "Vivek Arya", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 593, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Thanks for taking my question and best wishes for the next part of your tenure. My question is on know, if you could help us quantify what is the new fiscal twenty\nsix AI guidance. Because I think the last call you mentioned '26 could grow at the 60% growth rate. So what is the updated number? Is it, you know, 60% plus the\nthe $10 billion that you mentioned? And sort of related to that, do you expect the custom versus networking mix to stay broadly what it has been this past year or\nor evolve more towards customs? So any quantification on this, you know, networking versus custom mix would be very helpful. Fiscal twenty six. Okay. Let's\nanswer the first part first. If I could be so bold as to suggest to you when I last quarter when I said, hey, the trend of growth of '26 will mirror that of '25. Which is\n50, 60%. Year on year. That's really all I say. I didn't quote a ban. Of course, it comes out 50, percent because that's what '25 is. All I'm saying you want to put\nanother way of it, looking at what I'm saying, which is perhaps more accurate, we're seeing the growth rate accelerate. As opposed to just remain steady at that\n50, 60% We are expecting and seeing 2026 to accelerate more than the growth rate we see in '25. And I know you love me to throw in a number at you, but you\nknow what? We're not supposed to be giving you a forecast for '26, but best way to describe it, it will be fairly material improvement. And the networking versus\ncustom? Ah, good point. Thanks for reminding me. As we see it and a big part of this driver of growth will be experience. And as a to and the reason of repeating\nwhat I said in my remarks, comes from the fact that we are continue to gain share at our three original customers They have to they're on their journey, and each\npassing generation they go more to XPUs. So we are gaining share from this three. We now have the benefit of an additional four four significant customer. I\nwould just say fourth and very significant customer. And that combination will mean more XPUs. And as I said, as the ratio as the as we create more and more\nexperience among four guys, the networking we get the networking with these four guys, but now the mix of networking from outside these four guys will now be a\nsmaller be diluted, be a smaller share. So I expect actually networking percentage of the pool to be a declining percentage. Going into twenty six.\nOperator\nThank you, And one moment for our next question. And that will come from the line of Stacy Rasgon with Bernstein Research. Your line is open.", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q3_chunk_0007", "doc_id": "AVGO_TRANSCRIPT_2025_Q3", "source_units": ["AVGO_TRANSCRIPT_2025_Q3_u_0011", "AVGO_TRANSCRIPT_2025_Q3_u_0012"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q3.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q3", "period": "2025-Q3", "section_id": null, "section_title": null, "speaker": "Stacy Rasgon", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 188, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Hi, guys. Thanks for taking my question. Was wondering if you could help me parse out this $110 billion backlog. Did I that number right? Could you give us some\ncolor on on on the makeup of it? Like, how far out does that go and, like, how much of that $110 billion is AI versus non AI versus software? Well, I guess, Stacy, we generally don't break up backlog. I've just given a total number to give you a sense of how strong the business is as a whole for the\ncompany. And it's largely driven by AI, as a grow in terms of growth. Software continue to add on a steady basis and non AI as as I indicated, has grown double\ndigits. Nothing compared to AI which has grown very strongly. Mhmm. Give you a sense, perhaps, fully 50% of it at least, is semiconductors.", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q3_chunk_0008", "doc_id": "AVGO_TRANSCRIPT_2025_Q3", "source_units": ["AVGO_TRANSCRIPT_2025_Q3_u_0013"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q3.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q3", "period": "2025-Q3", "section_id": null, "section_title": null, "speaker": "Stacy Rasgon", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 25, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Okay. And it's fair to say that of that semiconductor piece, it's gonna be much more AI than non AI?", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q3_chunk_0009", "doc_id": "AVGO_TRANSCRIPT_2025_Q3", "source_units": ["AVGO_TRANSCRIPT_2025_Q3_u_0014", "AVGO_TRANSCRIPT_2025_Q3_u_0016"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q3.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q3", "period": "2025-Q3", "section_id": null, "section_title": null, "speaker": "Stacy Rasgon", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 178, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Yeah. Got it. That's helpful. Thank you.\nOperator\nOne moment for our next question. And that will come from the line of Ben Reitzes with Melius. Your line is open. Ben, you are definitely greedy and definitely overthinking this for me. Thank you. But yeah. You know, that's if asking for qualify, subjective qualification. And, \nfrankly, I I don't wanna give that. I'm not comfortable giving that because sometimes we stumble into production in fairly in time frames that are fairly unexpected \nsurprisingly. Equally, it could get delayed. So I rather not give you any more color on prospects than just tell you these prospects are real prospects and continue \nto be very closely engaged towards developing each of their own experience with every intent of going into substantial production. Like the four we have today\n\nwho are custom.", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q3_chunk_0010", "doc_id": "AVGO_TRANSCRIPT_2025_Q3", "source_units": ["AVGO_TRANSCRIPT_2025_Q3_u_0020", "AVGO_TRANSCRIPT_2025_Q3_u_0021"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q3.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q3", "period": "2025-Q3", "section_id": null, "section_title": null, "speaker": "Jim Schneider", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 771, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Good afternoon. Thanks for taking my question. Hock, I was wondering if you could give us a little bit more color not necessarily on the prospects, which you still\nhave in the pipeline, but how you view the universe of additional prospects beyond the seven you know, customers and prospects you've already identified. Do\nyou still see there being additional prospects that would be worthy of a of a custom chip. And I know you've been relatively know, circumspect in terms of the the\nnumber of customers that are out there and the volume that they can provide and and selective in terms of the opportunities you're interested in. So maybe frame\nfor us the additional prospects as you see them beyond the v seven. Thank you. That's a very good question. And let me let me answer it in a fairly broader basis. Well, as I said before and perhaps said repeat a bit more. We're very send in we\nlook at this market into broad segments. You know, that's one is simply the guys, the parties, the customers, who develop their own LLM. And the rest of the other\nmarket I consider is collectively lump as enterprise. That is markers that run that will run AI workloads for enterprise. Whether it's on prem or GPU XPU or\nwhatever as a service. The enterprise. We don't address that market, to be honest. We That's because that's that's a hard market for us to address. And we're not\nset up to address that. We instead address this LLM market and as I said many times before, it's a very few narrow markets. Few players driving frontier models\non a consistent on a very accelerated trend towards super intelligence for one plagiarizing the term of someone else, but you know what I mean. And the other\nguys who would invest, who need to invest a lot initially, my view on training. Training of ever larger and larger clusters of ever more capable accelerators but also\nas for these guys, you know, they got to be accountable to shareholders or accountable to being able to create cash flows that can sustain their path they start to\nalso invest in inference in a massive way to monetize their models. These are the players we work with. These are individually people or players who spend a lot\nof money on on a lot of compute capacity just that there are only so few of them. And right we have I have indicated, identified seven. Four of which now our\ncustomers Three continues to be prospects we engage with. And we're very picky and still careful. I should say, Shenandoah, picky. Careful. Who qualifies under\nthat. And I indicated it. They have a they are building a platform or have a platform and I'm investing very much on leading LLMs models. And we're severed and I\nthink that's about it. We may get see one more perhaps as a prospect But again, we are very thoughtful and careful about even making that qualification. But right\nnow, for sure, we have seven. And that's for now, it's pretty much what we have.\nOperator\nThank you. One moment for our next question. And that will come from the line of Tom O'Malley with Barclays. Your line is open.\nTom O'Malley\nCongrats on the really good results. I wanted to ask on Jericho four commentary. NVIDIA talked about the XGET switch and now is talking about scale across.\nYou're talking about Jericho four. It sounds like this market is really starting to develop. Maybe you could talk about when you see material uplift in revenue there\nand why it's important to start thinking about those type of switches as we move more towards inferencing. Thank you, Hock.", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q3_chunk_0011", "doc_id": "AVGO_TRANSCRIPT_2025_Q3", "source_units": ["AVGO_TRANSCRIPT_2025_Q3_u_0028", "AVGO_TRANSCRIPT_2025_Q3_u_0029"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q3.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q3", "period": "2025-Q3", "section_id": null, "section_title": null, "speaker": "Joe Moore", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 226, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Great. Thank you. In terms of the fourth customer, I think you've talked in the past about potential customers four and five were more hyperscale. And six and\nseven were more like, you know, the LLM makers themselves. Can you give us a sense for if you could help us categorize that? If not, that's fine. And then the\n$10 billion of orders, can you give us a time frame on that? Thank you. Okay. Yeah. No. It's towards the end of the day, all seven do LLMs Not all of them have a current have a has a huge platform we're talking about. But one could\nimagine eventually, all of them will have or create a platform. So it's hard to differentiate the two. But coming back coming on the second and third and the\ndelivery of the $10 billion, I'll probably be in around, I would say, the second half of our fiscal quarter year 2026. I would say, to be more even more precise, likely\nto be Q3 of our fiscal twenty six.", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q3_chunk_0012", "doc_id": "AVGO_TRANSCRIPT_2025_Q3", "source_units": ["AVGO_TRANSCRIPT_2025_Q3_u_0030", "AVGO_TRANSCRIPT_2025_Q3_u_0031"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q3.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q3", "period": "2025-Q3", "section_id": null, "section_title": null, "speaker": "Joe Moore", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 70, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Okay. Okay. Q3, it starts or Q3 like, how what time frame does it take to deploy $10 billion? Starts and ends in Q3. Alright. Thank you.\nOperator\nOne moment for our next question. And that will come from the line of Joshua Buchhalter with TD Cowen. Your line is open.", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q3_chunk_0013", "doc_id": "AVGO_TRANSCRIPT_2025_Q3", "source_units": ["AVGO_TRANSCRIPT_2025_Q3_u_0032", "AVGO_TRANSCRIPT_2025_Q3_u_0033"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q3.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q3", "period": "2025-Q3", "section_id": null, "section_title": null, "speaker": "Joshua Buchhalter", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 484, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Hey, guys. Thank you for taking my question and congrats on the results. I was hoping you could provide some comments on momentum for your first scale up\nEthernet and how it compares with, you know, UA link and PCIe solutions out there. You know, how big of a how meaningful is it to have the Tomahawk Altros\nproduct out there with a lower latency? And, know, how meaningful do you think scale up Ethernet opportunity could be over the next year as we think about your\nAI networking business? Thank you. Well, that's a good question. And we we ourselves are thinking about that too because to begin with, Ethernet our Ethernet solutions are very disaggregated from\nthe AI's accelerators Anybody does. It's separate. We treat them as separate. Even though you're right, the network is a computer. We have always believed that\nEthernet is open source. Anybody should be able to have choices we keep it separate from my XPU. And but the truth of the matter is for our customers, who use\nthe XPU, we develop and we optimize our networking switches and other components that relate to being able to network signals in the in any classes hand in\nhand with it. In fact, all these XPUs have developed with interface that handles Ethernet. Very, very much so. So that's in a way, we've XPUs with our customers,\nwe are openly enabling. Ethernet as a as a networking protocol of choice. Very, very openly. And it need not be our Ethernet switches. It could be any other, but\nsomebody else Ethernet switches that does it. It just happens to be when the lead in this business so we get that. But beyond it, especially when it comes to a\nclosed system of GPUs, we see less of it. Except in the hyperscalers. Where the hyperscalers are able to architect the GPUs clusters very separate from the\nnetworking side, especially in scale scale out. In which case, on those hyperscalers, we sell a lot a lot of these Ethernet switches that does scaling out. And we\nsuspect when it goes to scaling across now, even more Ethernet that are desegregated from the GPUs that are in the in the place. As far as the XPUs are\nconcerned, for sure, it's all Ethernet.", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q3_chunk_0014", "doc_id": "AVGO_TRANSCRIPT_2025_Q3", "source_units": ["AVGO_TRANSCRIPT_2025_Q3_u_0034", "AVGO_TRANSCRIPT_2025_Q3_u_0036"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q3.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q3", "period": "2025-Q3", "section_id": null, "section_title": null, "speaker": "Joshua Buchhalter", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 713, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Thank you.\nOperator\nOne moment for our next question. That will come from the line of Christopher Rolland with Susquehanna. Your line is open. Thank you for embracing Sue. Thank you. I didn't expect that to come out. And I appreciate that. Well, you know I'm biased, to be honest. But it's so obvious I\ncan't help but being biased. Because Ethernet is well proven. Ethernet is so known to the engineers, the architects that sits in all these hyperscalers. Developing,\ndesigning AI data center, data AI infrastructure. It's the logical thing for them to use. And they are using it. And they are focusing on it. And the development of\nseparate individualized protocol, frankly, You know, it's beyond my imagination why they bother. Ethernet is there. It's been well used. It's proven. It can keep\ngoing up. The only thing people talk about is perhaps latency. Especially in scaling up. Hence, the the the emergence of NVLink. And even then, as I indicated,\nit's not hard for us, and we are not the only one who can who can do that. Quite a few others in Ethernet can do it in the switches. You can just tweak the\nswitches to make the latency super good. Better than NVLink, better than InfiniBand. Less than 250, you know, nanoseconds. Easily. And that's what we did. So\nit's not that hard. And perhaps this is why I say that because we we have been doing it as the in as the Ethernet has been around the last twenty five years at\nlength. So it's there that they know there's no need to go and create some cook up protocols that now you have to bring people around. Ethernet is the way to go\nand we and there's plenty of competition too because it's an open source system. So I think Ethernet is way to go and for sure in developing x XPUs for our\ncustomers, all these experience with the agreement of customers are made compatible interface with Ethernet. And not some fancy other interface that one has\nto keep going as bandwidth increase. And we and and I assure you, we have competition, which is one of the why the hyper scalars like the net. It's not just us.\nThey can find somebody else if for whatever reason they don't like us, and we're open to that. It's always good to do that. It's an open source system and lock and\nthere are players in that market. Not any core system. Switching on to XPU competition, Yeah. You you hear about we hear about competition and all that. It's\njust that it's it's a competition that's it's an area that we always see competition and our only way to secure a position is we try to out invest and now innovate\nanybody else in this game. We have been fortunate to be the first one creating this XPU model of a six. On silicon. And we also have been fortunate to be\nprobably one of the largest IP developers of semiconductor out there. Things like serializer, deserializer, SerDes been able to develop the best packaging been\nable to do redesign things that are very low power. So just have to keep investing in it, which we do. To outrun the the competition in this space. And I believe\nwe're doing a fairly decent job of doing it at this point.", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q3_chunk_0015", "doc_id": "AVGO_TRANSCRIPT_2025_Q3", "source_units": ["AVGO_TRANSCRIPT_2025_Q3_u_0038"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q3.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q3", "period": "2025-Q3", "section_id": null, "section_title": null, "speaker": "Harsh Kumar", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 324, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Hey, guys. Thanks for squeezing me in. Hock, congratulations on all the exciting AI metrics, and thanks for everything you do for Broadcom and sticking around.\nMark, my question is, you've got three to four existing customers that are ramping. As the data centers for AI clusters get bigger and bigger, it makes sense to\nhave differentiation, efficiency, etcetera. Therefore, the case for XPUs why should I not think that your XPU share at these three or four customers that that are\nexisting will be bigger than the GPU share in the longer term. It will be. It's a logical conclusion. Yeah. As you're correct. And we are seeing that step by step. As I\nsay, it's a journey It's a multiyear journey because it's multigenerational. Because this experience don't stay still either. I'm doing multiple versions least two\nversions, two generation version for each of these customers we have. And with each newer generation, they increase the consumption, the usage of the XPU as\nthey gain confidence, as the model improves, they deploy it even more. So that's the logical trend that XPUs will keep in this few customers of ours, whereas they\nare successfully deployed and their software stabilizes the software stack, the libraries that sits on these chips stabilizes and proves itself out. They'll get they'll\nhave the confidence to keep using a higher and higher percentage of their compute footprint in their own XPUs. For sure. And we see that And that's why I say\nwe progressively gain share.", "chunked_at": "2025-11-10T02:19:46Z"}
{"chunk_id": "AVGO_TRANSCRIPT_2025_Q3_chunk_0016", "doc_id": "AVGO_TRANSCRIPT_2025_Q3", "source_units": ["AVGO_TRANSCRIPT_2025_Q3_u_0039"], "source_uri": "data/earnings_calls_manual/AVGO/AVGO_FY2025_Q3.pdf", "ticker": "AVGO", "company": "AVGO", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q3", "period": "2025-Q3", "section_id": null, "section_title": null, "speaker": "Harsh Kumar", "speaker_role": "Analyst", "phase": "qa", "chunk_tokens": 35, "start_token": 0, "end_token": 0, "chunk_type": "qa_exchange", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "Thank you, Hock.\nOperator\nThank you. I would now like to turn the call back over to Ji Yoo, Head of Investor Relations for any closing remarks.", "chunked_at": "2025-11-10T02:19:46Z"}
