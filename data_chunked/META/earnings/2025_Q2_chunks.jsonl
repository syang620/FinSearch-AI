{"chunk_id": "META_TRANSCRIPT_2025_Q2_chunk_0000", "doc_id": "META_TRANSCRIPT_2025_Q2", "source_units": ["META_TRANSCRIPT_2025_Q2_u_0000", "META_TRANSCRIPT_2025_Q2_u_0001", "META_TRANSCRIPT_2025_Q2_u_0002", "META_TRANSCRIPT_2025_Q2_u_0003", "META_TRANSCRIPT_2025_Q2_u_0004", "META_TRANSCRIPT_2025_Q2_u_0005", "META_TRANSCRIPT_2025_Q2_u_0006", "META_TRANSCRIPT_2025_Q2_u_0007", "META_TRANSCRIPT_2025_Q2_u_0008", "META_TRANSCRIPT_2025_Q2_u_0009", "META_TRANSCRIPT_2025_Q2_u_0010", "META_TRANSCRIPT_2025_Q2_u_0011", "META_TRANSCRIPT_2025_Q2_u_0012", "META_TRANSCRIPT_2025_Q2_u_0013", "META_TRANSCRIPT_2025_Q2_u_0014"], "source_uri": "data/earnings_calls_manual/META/META_FY2025_Q2.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Mark Elliot Zuckerberg", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 800, "start_token": 0, "end_token": 800, "chunk_type": "windowed_overlap", "overlap_with_prev": 0, "overlap_with_next": 120, "text": "All right. Thanks, Ken. Thanks, everyone, for joining today. We had another strong quarter with more than 3.4 billion people using at least one of our apps each\nday and strong engagement across the board. Our business continues to perform very well, which enables us to invest heavily in our AI efforts. Over the last few\nmonths, we've begun to see glimpses of our AI systems improving themselves. And the improvement is slow for now, but undeniable and developing\nsuperintelligence, which we define as AI that surpasses human intelligence in every way, we think, is now in sight. Meta's vision is to bring personal\nsuperintelligence to everyone, so that people can direct it towards what they value in their own lives. And we believe that this has the potential to begin an exciting\nnew era of individual empowerment. A lot has been written about all the economic and scientific advances that superintelligence can bring, and I'm extremely\noptimistic about this. But I think that if history is a guide, then an even more important role will be how superintelligence empowers people to be more creative,\ndevelop culture and communities, connect with each other and lead more fulfilling lives. To build this future, we've established Meta Superintelligence Labs, which\nincludes our foundations, product and FAIR teams as well as a new lab that is focused on developing the next generation of our models. We're making good\nprogress towards Llama 4.1 and 4.2, and in parallel, we are also working on our next generation of models that will push the frontier in the next year or so. We are\nbuilding an elite, talent-dense team Alexandr Wang is leading the overall team, Nat Friedman is leading our AI Products and Applied Research, and Shengjia\nZhao is Chief Scientist for the new effort. They are all incredibly talented leaders, and I'm excited to work closely with them and the world-class group of AI\nresearchers and infrastructure and data engineers that we're assembling. I've spent a lot of time building this team this quarter. And the reason that so many\npeople are excited to join is because Meta has all of the ingredients that are required to build leading models and deliver them to billions of people. The people\nwho are joining us are going to have access to unparalleled compute as we build out several multi-gigawatt clusters. Our Prometheus cluster is coming online\nnext year, and we think it's going to be the world's first gigawatt-plus cluster. We're also building out Hyperion, which will be able to scale up to 5 gigawatts over\nseveral years, and we have multiple more titan clusters in development as well. We are making all these investments because we have conviction that\nsuperintelligence is going to improve every aspect of what we do. From a business perspective, I mentioned last quarter that there are five basic opportunities\nthat we are pursuing, improved advertising, more engaging experiences, business messaging, Meta AI and AI devices. So I can go into a bit of detail on each. On\nadvertising, the strong performance this quarter is largely thanks to AI unlocking greater efficiency and gains across our ad system. This quarter, we expanded\nour new AI-powered recommendation model for ads to new surfaces and improved its performance by using more signals and longer context. It's driven roughly\n5% more ad conversions on Instagram and 3% on Facebook. We're also seeing good progress with AI for ad creative with a meaningful percent of our ad\nrevenue now coming from campaigns using one of our generative AI features. This is going to be especially valuable for smaller advertisers with limited budgets.\nWhile agencies will continue the important work to help larger brands apply these tools strategically. The second opportunity is more engaging experiences. AI is\nsignificantly improving our ability to show people content that they're going to find interesting and useful. Advancements in our", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2025_Q2_chunk_0001", "doc_id": "META_TRANSCRIPT_2025_Q2", "source_units": ["META_TRANSCRIPT_2025_Q2_u_0000", "META_TRANSCRIPT_2025_Q2_u_0001", "META_TRANSCRIPT_2025_Q2_u_0002", "META_TRANSCRIPT_2025_Q2_u_0003", "META_TRANSCRIPT_2025_Q2_u_0004", "META_TRANSCRIPT_2025_Q2_u_0005", "META_TRANSCRIPT_2025_Q2_u_0006", "META_TRANSCRIPT_2025_Q2_u_0007", "META_TRANSCRIPT_2025_Q2_u_0008", "META_TRANSCRIPT_2025_Q2_u_0009", "META_TRANSCRIPT_2025_Q2_u_0010", "META_TRANSCRIPT_2025_Q2_u_0011", "META_TRANSCRIPT_2025_Q2_u_0012", "META_TRANSCRIPT_2025_Q2_u_0013", "META_TRANSCRIPT_2025_Q2_u_0014"], "source_uri": "data/earnings_calls_manual/META/META_FY2025_Q2.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Mark Elliot Zuckerberg", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 800, "start_token": 680, "end_token": 1480, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 0, "text": " longer context. It's driven roughly\n5% more ad conversions on Instagram and 3% on Facebook. We're also seeing good progress with AI for ad creative with a meaningful percent of our ad\nrevenue now coming from campaigns using one of our generative AI features. This is going to be especially valuable for smaller advertisers with limited budgets.\nWhile agencies will continue the important work to help larger brands apply these tools strategically. The second opportunity is more engaging experiences. AI is\nsignificantly improving our ability to show people content that they're going to find interesting and useful. Advancements in our recommendation systems have\nimproved quality so much that it has led to a 5% increase in time spent on Facebook and 6% on Instagram, just this quarter. There is a lot of potential for content\nitself to get better too, we're seeing early progress with the launch of our AI video editing tools across Meta AI and our new Edits app. And there's a lot more to do\nhere. The third opportunity is business messaging. I've talked before about how I believe every business will soon have a business AI, just like they have an\ne-mail address, social media account and website. We are starting to see some product market fit in a number of countries where we're testing these agents, and\nwe're integrating these business AIs into ads on Facebook and Instagram as well as directly into e-commerce websites. The fourth opportunity is Meta AI. Its\nreach is already quite impressive with more than 1 billion monthly actives. Our focus is now deepening the experience and making Meta AI the leading personal\nAI. As we continue improving our models, we see engagement grow. So our next generation of models is going to continue to really help here. And the fifth\nopportunity is AI devices. We continue to see strong momentum with our Ray-Ban Meta glasses with sales accelerating. We are also launching new performance\nAI glasses with the Oakley Meta HSTN, they have longer battery life, higher resolution camera and are designed for sports. The percent of people using Meta AI\nis growing, and we are seeing new users AI retention increase too, which is a good sign for that continued use. I think that AI glasses are going to be the main\nway that we integrate superintelligence into our day-to-day lives. So it's important to have all of these different styles and products that appeal to different people\nin different settings. Finally, we're seeing people continue to spend more time with our Quest ecosystem and the community continues to grow steadily. We\nlaunched the Meta Quest 3S Xbox Edition last month, and we're seeing record interest in cloud gaming. And beyond gaming, we continue to see a broader set of\nuse cases with media and web browsing contributing a significant portion of engagement. We're going to have more to share on all of this, especially the Reality\nLabs work at Connect on September 17. So I encourage you all to tune into that. Overall, this has been a busy quarter. Strong business performance and real\nmomentum in assembling both the talent and the compute that we need to build personal superintelligence for everyone. I am very grateful to our teams who are\nworking hard to deliver all of this, and thanks to all of you for being on this journey with us. And now here is Susan.\nSusan J. S. Li\nThanks, Mark, and good afternoon, everyone. Let's begin with our consolidated results. All comparisons are on a year-over-year basis unless otherwise noted. \nQ2 total revenue was $47.5 billion, up 22% on both a reported and constant currency basis. Q2 total expenses were $27.1 billion, up 12% compared to last year. \nIn terms of the specific line items, cost of revenue increased 16%, driven mostly by higher infrastructure costs and payments to partners, partially offset by a", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2025_Q2_chunk_0002", "doc_id": "META_TRANSCRIPT_2025_Q2", "source_units": ["META_TRANSCRIPT_2025_Q2_u_0000", "META_TRANSCRIPT_2025_Q2_u_0001", "META_TRANSCRIPT_2025_Q2_u_0002", "META_TRANSCRIPT_2025_Q2_u_0003", "META_TRANSCRIPT_2025_Q2_u_0004", "META_TRANSCRIPT_2025_Q2_u_0005", "META_TRANSCRIPT_2025_Q2_u_0006", "META_TRANSCRIPT_2025_Q2_u_0007", "META_TRANSCRIPT_2025_Q2_u_0008", "META_TRANSCRIPT_2025_Q2_u_0009", "META_TRANSCRIPT_2025_Q2_u_0010", "META_TRANSCRIPT_2025_Q2_u_0011", "META_TRANSCRIPT_2025_Q2_u_0012", "META_TRANSCRIPT_2025_Q2_u_0013", "META_TRANSCRIPT_2025_Q2_u_0014"], "source_uri": "data/earnings_calls_manual/META/META_FY2025_Q2.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Mark Elliot Zuckerberg", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 800, "start_token": 0, "end_token": 800, "chunk_type": "windowed_overlap", "overlap_with_prev": 0, "overlap_with_next": 120, "text": "benefit from the previously announced extension of sever useful lives. R&D increased 23%, mostly due to higher employee compensation and infrastructure \ncosts. Marketing and sales increased 9% primarily due to an increase in professional services related to our ongoing platform integrity efforts as well as marketing \ncosts, partially offset by lower employee compensation. G&A decreased 27%, driven mostly by lower legal-related costs. We ended Q2 with over 75,900 \nemployees, down 1% quarter-over-quarter, as the vast majority of the employees impacted by performance-related reductions earlier this year were no longer \ncaptured in our head count. This was partially offset by continued hiring in priority areas of monetization, infrastructure, Reality Labs, AI as well as regulation and \ncompliance. Second quarter operating income was $20.4 billion, representing a 43% operating margin. Our tax rate for the quarter was 11%, which reflects \nexcess tax benefits from share-based compensation due to the increase in our share price versus prior periods. Net income was $18.3 billion or $7.14 per share. \nCapital expenditures, including principal payments on finance leases were $17 billion, driven by investments in servers, data centers and network infrastructure. \nFree cash flow was $8.5 billion. We repurchased $9.8 billion of our Class A common stock and paid $1.3 billion in dividends to shareholders. We also made $15.1 \nbillion in nonmarketable equity investments in the second quarter which includes our minority investment in Scale AI, along with other investment activities. We \nended the quarter with $47.1 billion in cash and marketable securities and $28.8 billion in debt. Moving now to our segment results. I'll begin with our Family of \nApps segment. Our community across the Family of Apps continues to grow, and we estimate more than 3.4 billion people used at least one of our Family of \nApps on a daily basis in June. Q2 total Family of Apps revenue was $47.1 billion, up 22% year-over-year. Q2 Family of Apps ad revenue was $46.6 billion, up \n21% or 22% on a constant currency basis. Within that revenue, the online commerce vertical was the largest contributor to year-over-year growth. On a user \ngeography basis, ad revenue growth was strongest in Europe and Rest of World at 24% and 23%, respectively. North America and Asia Pacific grew 21% and \n18%. In Q2, the total number of ad impressions served across our services increased 11%, with growth mainly driven by Asia Pacific. Impression growth \naccelerated across all regions due primarily to engagement tailwinds on both Facebook and Instagram and to a lesser extent, ad load optimizations on Facebook. \nThe average price per ad increased 9%, benefiting from increased advertiser demand, largely driven by improved ad performance. Pricing growth slowed \nmodestly from the first quarter due to the accelerated impression growth in Q2. Family of Apps other revenue was $583 million, up 50%, driven by WhatsApp paid \nmessaging revenue growth as well as Meta Verified subscriptions. We continue to direct the majority of our investments toward the development and operation of \nour Family of Apps. In Q2, Family of Apps expenses were $22.2 billion, representing 82% of our overall expenses. Family of Apps expenses were up 14% and \nmainly due to growth in employee compensation and infrastructure costs, partially offset by lower legal-related costs. Family of Apps operating income was $25 \nbillion, representing a 53% operating margin. Within our Reality Labs segment, Q2 revenue was $370 million up 5% year-over-year due to increased sales of AI \nglasses, partially offset by lower Quest sales. Reality Labs expenses were $4.9 billion, up 1% year-over", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2025_Q2_chunk_0003", "doc_id": "META_TRANSCRIPT_2025_Q2", "source_units": ["META_TRANSCRIPT_2025_Q2_u_0000", "META_TRANSCRIPT_2025_Q2_u_0001", "META_TRANSCRIPT_2025_Q2_u_0002", "META_TRANSCRIPT_2025_Q2_u_0003", "META_TRANSCRIPT_2025_Q2_u_0004", "META_TRANSCRIPT_2025_Q2_u_0005", "META_TRANSCRIPT_2025_Q2_u_0006", "META_TRANSCRIPT_2025_Q2_u_0007", "META_TRANSCRIPT_2025_Q2_u_0008", "META_TRANSCRIPT_2025_Q2_u_0009", "META_TRANSCRIPT_2025_Q2_u_0010", "META_TRANSCRIPT_2025_Q2_u_0011", "META_TRANSCRIPT_2025_Q2_u_0012", "META_TRANSCRIPT_2025_Q2_u_0013", "META_TRANSCRIPT_2025_Q2_u_0014"], "source_uri": "data/earnings_calls_manual/META/META_FY2025_Q2.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Mark Elliot Zuckerberg", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 800, "start_token": 680, "end_token": 1480, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 120, "text": " were $22.2 billion, representing 82% of our overall expenses. Family of Apps expenses were up 14% and \nmainly due to growth in employee compensation and infrastructure costs, partially offset by lower legal-related costs. Family of Apps operating income was $25 \nbillion, representing a 53% operating margin. Within our Reality Labs segment, Q2 revenue was $370 million up 5% year-over-year due to increased sales of AI \nglasses, partially offset by lower Quest sales. Reality Labs expenses were $4.9 billion, up 1% year-over-year, driven by higher non-head count-related technology \ndevelopment costs. Reality Labs operating loss was $4.5 billion. Turning now to the business outlook. There are two primary factors that drive our revenue \nperformance, our ability to deliver engaging experiences for our community and our effectiveness at monetizing that engagement over time. On the first, daily \nactives continue to grow across Facebook, Instagram and WhatsApp as we make additional improvements to our recommendation systems and product \nexperiences. We continue to see momentum with video engagement, in particular. In Q2, Instagram video time was up more than 20% year-over-year globally. \nWe're seeing strong traction on Facebook as well, particularly in the U.S., where video time spent similarly expanded more than 20% year-over-year. These gains \nhave been enabled by ongoing optimizations to our ranking systems to better identify the most relevant content to show. We expect to deliver additional \nimprovements throughout the year as we further scale up our models and make recommendations more adaptive to a person's interests within their session. \nAnother emphasis of our recommendations work is promoting original content. On Instagram, over 2/3 of recommended content in the U.S. now comes from \noriginal posts. In the second half, we'll be focused on further increasing the freshness of original posts, so the right audiences can discover original content from \ncreators soon after it is posted. We are also making good progress on our longer-term ranking innovations that we expect will provide the next leg of \nimprovements over the coming years. Our research efforts to develop cross-surface foundation recommendation models continue to progress. We are also \nseeing promising results from using LLM in Threads recommendation systems. The incorporation of LLMs are now driving a meaningful share of the ranking \nrelated time spent gains on Threads. We're now exploring how to extend the use of LLMs and recommendation systems to our other apps. We're leveraging \nLlama and several other back-end processes as well, including actioning bug reports so we can identify and resolve recurring issues more quickly and efficiently. \nThis has resulted in top line bug reports in the U.S. and Canada in Facebook Feed and notifications dropping by roughly 30% over the past 10 months. The \nprimary way we're using Llama in our apps today is to power Meta AI which is now available in over 200 countries and territories. WhatsApp continues to be the \nlargest driver of queries as people message Meta AI directly for tasks such as information gathering, homework assistance and generating images. Outside of \nWhatsApp, we're seeing Meta AI become an increasingly valuable complement to our content discovery engines. Meta AI usage on Facebook is expanding as \npeople use it to ask about posts they see in Feed and find content across our platform in Search. Another way we expect Meta AI will help with content discovery \nis through the automatic translation and dubbing of foreign language content into the audience's local language. We'll have more to share on our efforts there \nlater this year. Moving to Reality Labs. The growth of Ray-Ban Meta sales accelerated in Q2, with demand still outstripping supply for the most popular SKUs \ndespite increases to our production earlier this year. We're working to ramp supply to better meet consumer demand later this year. Now to the second driver of \nour revenue", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2025_Q2_chunk_0004", "doc_id": "META_TRANSCRIPT_2025_Q2", "source_units": ["META_TRANSCRIPT_2025_Q2_u_0000", "META_TRANSCRIPT_2025_Q2_u_0001", "META_TRANSCRIPT_2025_Q2_u_0002", "META_TRANSCRIPT_2025_Q2_u_0003", "META_TRANSCRIPT_2025_Q2_u_0004", "META_TRANSCRIPT_2025_Q2_u_0005", "META_TRANSCRIPT_2025_Q2_u_0006", "META_TRANSCRIPT_2025_Q2_u_0007", "META_TRANSCRIPT_2025_Q2_u_0008", "META_TRANSCRIPT_2025_Q2_u_0009", "META_TRANSCRIPT_2025_Q2_u_0010", "META_TRANSCRIPT_2025_Q2_u_0011", "META_TRANSCRIPT_2025_Q2_u_0012", "META_TRANSCRIPT_2025_Q2_u_0013", "META_TRANSCRIPT_2025_Q2_u_0014"], "source_uri": "data/earnings_calls_manual/META/META_FY2025_Q2.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Mark Elliot Zuckerberg", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 800, "start_token": 1360, "end_token": 2160, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 120, "text": " find content across our platform in Search. Another way we expect Meta AI will help with content discovery \nis through the automatic translation and dubbing of foreign language content into the audience's local language. We'll have more to share on our efforts there \nlater this year. Moving to Reality Labs. The growth of Ray-Ban Meta sales accelerated in Q2, with demand still outstripping supply for the most popular SKUs \ndespite increases to our production earlier this year. We're working to ramp supply to better meet consumer demand later this year. Now to the second driver of \nour revenue performance, increasing monetization efficiency. The first part of this work is optimizing the level of ads within organic engagement. We continue to \noptimize ad supply across each surface to better deliver ads at the time and place they are most relevant to people. In Q2, we also began introducing ads within \nFeed on Threads and the Updates tab of WhatsApp, which is a separate space away from people's chats. As of May, advertisers globally can now run video and \nimage ads to Threads users in most countries, including the United States. While ad supply remains low and Threads is not expected to be a meaningful \ncontributor to overall impression growth in the near term, we are optimistic about the longer-term opportunity with Threads as the community and engagement \ngrow and monetization scales. On WhatsApp, we are rolling out ads in status and channels, along with channel subscriptions in the Updates tab to help \nbusinesses reach the more than 1.5 billion daily actives who visit that part of the app. We expect the introduction of ads and status will be gradual over the course \nof this year and next, with low levels of expected ad supply initially. We also expect WhatsApp ads and status to earn a lower average price than Facebook or \nInstagram ads for the foreseeable future, due in part towards WhatsApp skew toward lower monetizing markets, and more limited information that can be used for \ntargeting. Given this, we do not expect ads and status to be a meaningful contributor to total impressions or revenue growth for the next few years. The second \npart of increasing monetization efficiency is improving marketing performance. There are three areas of this work that I'll focus on today, improving our ad \nsystems, advancing our ads products, including by building tools that assist in ads creation and evolving our ads platform to drive results that are optimized for \neach business' objectives. First is our ad systems where we're innovating in both the ads retrieval and ranking stages to serve more relevant ads to people. A lot \nof this work involves us continuing to advance the modeling innovations we've introduced previously while expanding their adoption across our platform. The \nAndromeda model architecture we began introducing in the second half of 2024 powers the ads retrieval stage of our ad system, where we select the few \nthousand most relevant ads from tens of millions of potential candidates. In Q2, we made enhancements to Andromeda that enabled it to select more relevant \nand more personalized ads candidates while also expanding coverage to Facebook Reels. These improvements have driven nearly 4% higher conversions on \nFacebook Mobile Feed and Reels. Our new Generative Ads Recommendation system, or GEM, powers the ranking stage of our ad system, which is the part of \nthe process after ads retrieval where we determine which ads to show someone from candidates suggested by our retrieval engine. In Q2, we improved the \nperformance of GEM by further scaling our training capacity and adding organic and ads engagement data on Instagram. We also incorporated new advanced \nsequence modeling techniques that helped us double the length of event sequences we use, enabling our systems to consider a longer history of the content or \nads that a person has engaged with in order to provide better ad selections. The combination of these improvements increased ad conversions by approximately \n5% on Instagram and 3% on Facebook Feed and Reels in Q2. Finally,", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2025_Q2_chunk_0005", "doc_id": "META_TRANSCRIPT_2025_Q2", "source_units": ["META_TRANSCRIPT_2025_Q2_u_0000", "META_TRANSCRIPT_2025_Q2_u_0001", "META_TRANSCRIPT_2025_Q2_u_0002", "META_TRANSCRIPT_2025_Q2_u_0003", "META_TRANSCRIPT_2025_Q2_u_0004", "META_TRANSCRIPT_2025_Q2_u_0005", "META_TRANSCRIPT_2025_Q2_u_0006", "META_TRANSCRIPT_2025_Q2_u_0007", "META_TRANSCRIPT_2025_Q2_u_0008", "META_TRANSCRIPT_2025_Q2_u_0009", "META_TRANSCRIPT_2025_Q2_u_0010", "META_TRANSCRIPT_2025_Q2_u_0011", "META_TRANSCRIPT_2025_Q2_u_0012", "META_TRANSCRIPT_2025_Q2_u_0013", "META_TRANSCRIPT_2025_Q2_u_0014"], "source_uri": "data/earnings_calls_manual/META/META_FY2025_Q2.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Mark Elliot Zuckerberg", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 137, "start_token": 2040, "end_token": 2177, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 0, "text": " ads to show someone from candidates suggested by our retrieval engine. In Q2, we improved the \nperformance of GEM by further scaling our training capacity and adding organic and ads engagement data on Instagram. We also incorporated new advanced \nsequence modeling techniques that helped us double the length of event sequences we use, enabling our systems to consider a longer history of the content or \nads that a person has engaged with in order to provide better ad selections. The combination of these improvements increased ad conversions by approximately \n5% on Instagram and 3% on Facebook Feed and Reels in Q2. Finally, we expanded coverage of our Lattice model architecture in Q2. We first began deploying", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2025_Q2_chunk_0006", "doc_id": "META_TRANSCRIPT_2025_Q2", "source_units": ["META_TRANSCRIPT_2025_Q2_u_0000", "META_TRANSCRIPT_2025_Q2_u_0001", "META_TRANSCRIPT_2025_Q2_u_0002", "META_TRANSCRIPT_2025_Q2_u_0003", "META_TRANSCRIPT_2025_Q2_u_0004", "META_TRANSCRIPT_2025_Q2_u_0005", "META_TRANSCRIPT_2025_Q2_u_0006", "META_TRANSCRIPT_2025_Q2_u_0007", "META_TRANSCRIPT_2025_Q2_u_0008", "META_TRANSCRIPT_2025_Q2_u_0009", "META_TRANSCRIPT_2025_Q2_u_0010", "META_TRANSCRIPT_2025_Q2_u_0011", "META_TRANSCRIPT_2025_Q2_u_0012", "META_TRANSCRIPT_2025_Q2_u_0013", "META_TRANSCRIPT_2025_Q2_u_0014"], "source_uri": "data/earnings_calls_manual/META/META_FY2025_Q2.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Mark Elliot Zuckerberg", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 800, "start_token": 0, "end_token": 800, "chunk_type": "windowed_overlap", "overlap_with_prev": 0, "overlap_with_next": 120, "text": "Lattice in 2023 with our later-stage ads ranking efforts, allowing us to run significantly larger models that generalize learnings across objectives and surfaces in\nplace of numerous smaller ads models that have historically been optimized for individual objectives and surfaces. In April, we began deploying Lattice to\nearlier-stage ads ranking models as well. This is leading not only to greater capacity and engineering efficiency but also improved performance with the recent\nLattice deployments driving a nearly 4% increase in ad conversions across Facebook Feed and Reels in Q2. Next, ad products. Here, we're seeing strong\nmomentum with our Advantage+ suite of AI-powered solutions. In Q2, we completed the rollout of our streamlined campaign creation flow for Advantage+ sales\nand app campaigns, which makes it easier for advertisers to realize the performance benefits from Advantage+ by having it turned on at the beginning. We've\nseen lifts in advertiser adoption of sales and app campaigns since we've expanded availability and are working to complete the rollout for leads campaigns in the\ncoming months. Within our Advantage+ Creative suite, adoption of genAI ad creative tools continues to broaden. Nearly 2 million advertisers are now using our\nvideo generation features, image animation and video expansion, and we're seeing strong results with our text generation tools as we continue to add new\nfeatures. In Q2, we started testing AI-powered translation so that advertisers can automatically translate the caption of their ads to 10 different languages. While\nit's early, we have seen promising performance lifts in our prelaunch tests. We're also continuing to see strong adoption of image expansion among small- and\nmedium-sized advertisers, which speaks to how these tools help businesses who have fewer resources to develop creative. With larger advertisers, we expect\nagencies will continue to be valuable partners in helping apply these new tools to drive performance. Outside of Advantage+, we're seeing good momentum in\nbusiness messaging, particularly in the U.S., where click to message revenue grew more than 40% year-over-year in Q2. The strong U.S. growth is benefiting\nfrom a ramp in adoption of our website to message ads, which drive people to a business's website for more information before choosing to launch a chat with the\nbusiness in one of our messaging apps. Finally, we continue to evolve our ads platform to drive results that are optimized for each business' objectives and the\nway they measure results. In Q2, we completed the global rollout of our incremental attribution feature, which is the only product on the market that optimizes for\nand reports on incremental conversions, which are conversions that would not have happened without a person seeing the ad. We also launched omnichannel\nads globally in Q2 and which enable advertisers to optimize for incremental sales, both in-store and online with just one campaign. In tests, advertisers using\nomnichannel ads have seen a median 15% reduction in total cost per purchase compared to website-only optimization. Next, I would like to discuss our approach\nto capital allocation. Our primary focus remains investing capital back into the business with infrastructure and talent being our top priorities. I'll start with hiring.\nOur approach to adding head count continues to be targeted at the company's highest priority areas. We expect talent additions across all of our priority areas will\ncontinue to drive overall head count growth through this year and 2026. While head count growth in our other functions remains constrained, within AI, we've had\na particular emphasis on recruiting leading talent within the industry, as we build out Meta Superintelligence Labs to accelerate our AI model development and\nproduct initiatives. Next, infrastructure. We expect having sufficient compute capacity will be central to realizing many of the largest opportunities in front of us\nover the coming years. We continue to see very compelling returns from our AI capacity investments in our core ads and organic engagement initiatives and\nexpect to continue investing significantly there in 2026. We also", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2025_Q2_chunk_0007", "doc_id": "META_TRANSCRIPT_2025_Q2", "source_units": ["META_TRANSCRIPT_2025_Q2_u_0000", "META_TRANSCRIPT_2025_Q2_u_0001", "META_TRANSCRIPT_2025_Q2_u_0002", "META_TRANSCRIPT_2025_Q2_u_0003", "META_TRANSCRIPT_2025_Q2_u_0004", "META_TRANSCRIPT_2025_Q2_u_0005", "META_TRANSCRIPT_2025_Q2_u_0006", "META_TRANSCRIPT_2025_Q2_u_0007", "META_TRANSCRIPT_2025_Q2_u_0008", "META_TRANSCRIPT_2025_Q2_u_0009", "META_TRANSCRIPT_2025_Q2_u_0010", "META_TRANSCRIPT_2025_Q2_u_0011", "META_TRANSCRIPT_2025_Q2_u_0012", "META_TRANSCRIPT_2025_Q2_u_0013", "META_TRANSCRIPT_2025_Q2_u_0014"], "source_uri": "data/earnings_calls_manual/META/META_FY2025_Q2.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Mark Elliot Zuckerberg", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 800, "start_token": 680, "end_token": 1480, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 120, "text": " this year and 2026. While head count growth in our other functions remains constrained, within AI, we've had\na particular emphasis on recruiting leading talent within the industry, as we build out Meta Superintelligence Labs to accelerate our AI model development and\nproduct initiatives. Next, infrastructure. We expect having sufficient compute capacity will be central to realizing many of the largest opportunities in front of us\nover the coming years. We continue to see very compelling returns from our AI capacity investments in our core ads and organic engagement initiatives and\nexpect to continue investing significantly there in 2026. We also expect that developing leading AI infrastructure will be a core advantage in developing the best AI\nmodels and product experiences. So we expect to ramp our investments significantly in 2026 to support that work. Moving to our financial outlook. We expect\nthird quarter 2025 total revenue to be in the range of $47.5 billion to $50.5 billion. Our guidance assumes foreign currency is an approximately 1% tailwind to\nyear-over-year total revenue growth, based on current exchange rates. While we are not providing an outlook for fourth quarter revenue, we would expect our\nyear-over-year growth rate in the fourth quarter of 2025 to be slower than the third quarter as we lap a period of stronger growth in the fourth quarter of 2024.\nTurning now to the expense outlook. We expect full year 2025 total expenses to be in the range of $114 billion to $118 billion, narrowed from our prior outlook of\n$113 billion to $118 billion and reflecting a growth rate of 20% to 24% year-over-year. While we're still very early in planning for next year, there are a few factors\nwe expect will provide meaningful upward pressure on our 2026 total expense growth rate. The largest single driver of growth will be infrastructure costs, driven\nby a sharp acceleration in depreciation expense growth and higher operating costs as we continue to scale up our infrastructure fleet. Aside from infrastructure,\nwe expect the second largest driver of growth to be employee compensation as we add technical talent in priority areas and recognize a full year of compensation\nexpenses for employees hired throughout 2025. We expect these factors will result in a 2026 year-over- year expense growth rate that is above the 2025 expense\ngrowth rate. Turning now to the CapEx outlook. We currently expect 2025 capital expenditures, including principal payments on finance leases, to be in the range\nof $66 billion to $72 billion, narrowed from our prior outlook of $64 billion to $72 billion and up approximately $30 billion year-over-year at the midpoint. While the\ninfrastructure planning process remains highly dynamic, we currently expect another year of similarly significant CapEx dollar growth in 2026 as we continue\naggressively pursuing opportunities to bring additional capacity online to meet the needs of our AI efforts and business operations. On to tax. With the enactment\nof the new U.S. tax law, we anticipate a reduction in our U.S. federal cash tax for the remainder of the current year and future years. There are several alternative\nways of implementing the provisions of the act, which we are currently evaluating. While we estimate that the 2025 tax rate will be higher than our Q2 tax rate, we\ncannot quantify the magnitude at this time. In addition, we continue to monitor an active regulatory landscape, including the increasing legal and regulatory\nheadwinds in the EU that could significantly impact our business and our financial results. For example, we continue to engage with the European Commission on\nour Less Personalized Ads offering or LPA, which we introduced in November 2024 and based on feedback from the European Commission in connection with\nthe DMA. As the commission provides further feedback on LPA, we cannot rule out that it may seek to impose further modifications to it that would result in a\nmaterially worse", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2025_Q2_chunk_0008", "doc_id": "META_TRANSCRIPT_2025_Q2", "source_units": ["META_TRANSCRIPT_2025_Q2_u_0000", "META_TRANSCRIPT_2025_Q2_u_0001", "META_TRANSCRIPT_2025_Q2_u_0002", "META_TRANSCRIPT_2025_Q2_u_0003", "META_TRANSCRIPT_2025_Q2_u_0004", "META_TRANSCRIPT_2025_Q2_u_0005", "META_TRANSCRIPT_2025_Q2_u_0006", "META_TRANSCRIPT_2025_Q2_u_0007", "META_TRANSCRIPT_2025_Q2_u_0008", "META_TRANSCRIPT_2025_Q2_u_0009", "META_TRANSCRIPT_2025_Q2_u_0010", "META_TRANSCRIPT_2025_Q2_u_0011", "META_TRANSCRIPT_2025_Q2_u_0012", "META_TRANSCRIPT_2025_Q2_u_0013", "META_TRANSCRIPT_2025_Q2_u_0014"], "source_uri": "data/earnings_calls_manual/META/META_FY2025_Q2.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Mark Elliot Zuckerberg", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 523, "start_token": 1360, "end_token": 1883, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 0, "text": " magnitude at this time. In addition, we continue to monitor an active regulatory landscape, including the increasing legal and regulatory\nheadwinds in the EU that could significantly impact our business and our financial results. For example, we continue to engage with the European Commission on\nour Less Personalized Ads offering or LPA, which we introduced in November 2024 and based on feedback from the European Commission in connection with\nthe DMA. As the commission provides further feedback on LPA, we cannot rule out that it may seek to impose further modifications to it that would result in a\nmaterially worse user and advertiser experience. This could have a significant negative impact on our European revenue as early as later this quarter. We have\nappealed the European Commission's DMA decision, but any modifications to our model may be imposed during the appeal process. In closing, this was another\nstrong quarter for our business as our investments in infrastructure and technical talent continue to improve core ads performance and engagement on our\nplatforms. We expect the significant investments we're making now will allow us to continue leveraging advances in AI to extend those gains and unlock a new\nset of opportunities in the years to come. With that, Krista, let's open up the call for questions.\nOperator\n[Operator Instructions] Your first question comes from the line of Eric Sheridan with Goldman Sachs. Mark, when you think about where the AI parts of your business have been evolving over the last 3 to 6 months, I wanted to know what your key learnings were\nas you went deep into that strategy that informed some of the shifts in both talent, acquisition and compute, coupled with some of the blogs you put out recently in\nterms of how that strategy might have evolved based on those key learnings? And Susan, building on Mark's comments on scaling talent and compute, I want to\nknow if you go a little bit deeper on how we should be thinking about those two components driving some of the commentary you've given around OpEx and\nCapEx over the next 12 to 18 months. Yes, sure. I can start. At a high level, I think that there are all these questions that people have about what are going to be the time lines to get to really strong AI \nor superintelligence or whatever you want to call it. And I guess that each step along the way so far, we've observed the more kind of aggressive assumptions, or \nthe fastest assumptions have been the ones that have most accurately predicted what would happen. And I think that, that just continued to happen over the", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2025_Q2_chunk_0009", "doc_id": "META_TRANSCRIPT_2025_Q2", "source_units": ["META_TRANSCRIPT_2025_Q2_u_0000", "META_TRANSCRIPT_2025_Q2_u_0001", "META_TRANSCRIPT_2025_Q2_u_0002", "META_TRANSCRIPT_2025_Q2_u_0003", "META_TRANSCRIPT_2025_Q2_u_0004", "META_TRANSCRIPT_2025_Q2_u_0005", "META_TRANSCRIPT_2025_Q2_u_0006", "META_TRANSCRIPT_2025_Q2_u_0007", "META_TRANSCRIPT_2025_Q2_u_0008", "META_TRANSCRIPT_2025_Q2_u_0009", "META_TRANSCRIPT_2025_Q2_u_0010", "META_TRANSCRIPT_2025_Q2_u_0011", "META_TRANSCRIPT_2025_Q2_u_0012", "META_TRANSCRIPT_2025_Q2_u_0013", "META_TRANSCRIPT_2025_Q2_u_0014"], "source_uri": "data/earnings_calls_manual/META/META_FY2025_Q2.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Mark Elliot Zuckerberg", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 800, "start_token": 0, "end_token": 800, "chunk_type": "windowed_overlap", "overlap_with_prev": 0, "overlap_with_next": 120, "text": "course of this year, too. And so I've given a number of those anecdotes on these earnings calls in the past. And I think, certainly, some of the work that we're\nseeing with teams internally being able to adapt Llama 4 to build autonomous AI agents that can help improve the Facebook algorithm to increase quality and\nengagement are like -- I mean, that's like a fairly profound thing if you think about it. I mean it's happening in low volume right now. So I'm not sure that, that result\nby itself was a major contributor to this quarter's earnings or anything like that. But I think the trajectory on this stuff is very optimistic. And I think it's one of the\ninteresting challenges in running a business like this now is there's just a very high chance it seems like the world is going to look pretty different in a few years\nfrom now. And on the one hand, there are all these things that we can do, there are improvements to our core products that exist. And then I think we have this\nprinciple that we believe in across the company, which we tell people take superintelligence seriously. And the basic principle is this idea that we think that this is\ngoing to really shape all of our systems sooner rather than later, not necessarily on the trajectory of a quarter or 2, but on the trajectory of a few years. And I think\nthat that's just going to change a lot of the assumptions around how different things work across the company. So anyway, I think it's basically just what we're\ncontinually observing how this works and what the trajectory or the pace of AI progress has been. I think it continues to be on the faster end. And that I think\ninforms a lot of the decisions from everything from the importance and value of having the absolute best and most elite talent-dense team at the company to\nmaking sure that we have a leading compute fleet so that the people here can do -- obviously, the researchers here have more compute per person to be able to\nlead their research and then roll it out to billions of people across our products, making sure that we build and drive these products through all of the different\nthings that we do, which I think is one of the things that our company is the best in the world at is basically when we take a technology, we're good at driving that\nthrough all of our apps and our ad systems and all that stuff, it's not just going to kind of sit on the vine. I think that there's no other company, I think that is as\ngood as us at kind of taking something and kind of getting it in front of billions of people. So yes, I mean, we're just going to push very aggressively on all of that.\nBut at some level, yes, this is -- there's sort of a bet in the trajectory that we're seeing and those are the signals that we're seeing. But we're just trying to read it.\nSusan J. S. Li\nEric, for the second part of your question, we haven't, in fact, kicked off our budgeting process for 2026. So thinking about next year, there are clearly many,\nmany moving pieces in a very dynamic operating environment. But there are certain aspects that we have some visibility into today, including the rough shape of\nour 2026 infrastructure plans. And that flows through into our expense expectations next year. And we also have some visibility into the compensation expense\ngrowth that we'll recognize from the AI talent that we're hiring this year. And so those two things are part of why we gave a little bit of an early preview into the\nexpectations for growth for 2026 total expenses as well as for 2026 CapEx. So on the total expenses side, as I mentioned, we expect infrastructure will be the\nsingle largest contributor to 2026 expense growth", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2025_Q2_chunk_0010", "doc_id": "META_TRANSCRIPT_2025_Q2", "source_units": ["META_TRANSCRIPT_2025_Q2_u_0000", "META_TRANSCRIPT_2025_Q2_u_0001", "META_TRANSCRIPT_2025_Q2_u_0002", "META_TRANSCRIPT_2025_Q2_u_0003", "META_TRANSCRIPT_2025_Q2_u_0004", "META_TRANSCRIPT_2025_Q2_u_0005", "META_TRANSCRIPT_2025_Q2_u_0006", "META_TRANSCRIPT_2025_Q2_u_0007", "META_TRANSCRIPT_2025_Q2_u_0008", "META_TRANSCRIPT_2025_Q2_u_0009", "META_TRANSCRIPT_2025_Q2_u_0010", "META_TRANSCRIPT_2025_Q2_u_0011", "META_TRANSCRIPT_2025_Q2_u_0012", "META_TRANSCRIPT_2025_Q2_u_0013", "META_TRANSCRIPT_2025_Q2_u_0014"], "source_uri": "data/earnings_calls_manual/META/META_FY2025_Q2.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Mark Elliot Zuckerberg", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 800, "start_token": 680, "end_token": 1480, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 120, "text": ", including the rough shape of\nour 2026 infrastructure plans. And that flows through into our expense expectations next year. And we also have some visibility into the compensation expense\ngrowth that we'll recognize from the AI talent that we're hiring this year. And so those two things are part of why we gave a little bit of an early preview into the\nexpectations for growth for 2026 total expenses as well as for 2026 CapEx. So on the total expenses side, as I mentioned, we expect infrastructure will be the\nsingle largest contributor to 2026 expense growth. That's driven primarily by a sharp acceleration in depreciation expense growth in 2026, largely driven by\nrecognizing incremental depreciation from assets that we purchased and place in service in '26 as well as from infrastructure deployed through 2025 that will\nrecognize a full year of depreciation next year. We also expect a greater mix of our CapEx to be in shorter-lived assets in 2025 and '26 than it has been in prior\nyears. And then the other component of infra cost growth next year would come from higher operating expenses, including energy costs, leases, maintenance\nand operational expenses that are associated with maintaining that fleet. And we also expect some increased spend on cloud services in '26 to meet our capacity\nneeds as well as growth in network-related costs. So a lot going on, on the infrastructure side as it contributes to the 2026 total expense number. After that,\nemployee compensation is the next largest driver of expense growth in '26. Again, driven primarily in the investments that we're making in technical talent,\nincluding recognizing a full year of compensation expense for the AI talent we hire this year. I realize this answer is getting a little long, so I'll try to wrap up\nquickly. On the CapEx side, the big driver of our increased CapEx in '26 will be scaling genAI capacity as we build out training capacity that's going to drive higher\nspend across servers, networking, data centers next year. We also expect that we're going to continue investing significantly in core AI in 2026. And again, this is\na pretty -- a very dynamic area of planning, but we wanted to share kind of our early thoughts as things are shaping up.\nOperator\nYour next question comes from the line of Brian Nowak with Morgan Stanley. I have two. The first one, Mark, just to kind of go back to the intelligence labs and sort of the vision for superintelligence. As you sort of sit here now versus 12\nmonths ago, can you just sort of walk us through any changes of technological constraints or technological gating factors that you are most focused on\novercoming in the next 24 months that may have been different than they were in the past, just to make sure you can really lead in the idea of superintelligence\nover the next 10 years? And then the second one to Susan or Mark, one on the core. You've made so many improvements to the core to drive higher\nengagement, recommendations, et cetera. Can you just walk us through a couple of the factors you're still most excited about to come in the next 18 months that\nyou think could drive a further lift to engagement on the core platform? Yes, sure. I mean in terms of the research agenda and a bunch of the areas that we're very focused on, I do think focusing on self- improvement is a very\nimportant area of research. And there's obviously different scaling paradigms, and I don't want to get too much into the detail of research that we're doing on this.\nBut I think that for developing superintelligence, at some level, you're not just going to be learning from people because you're trying to build something that is\nfundamentally smarter than people. So it's going to need to learn how to -- or you", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2025_Q2_chunk_0011", "doc_id": "META_TRANSCRIPT_2025_Q2", "source_units": ["META_TRANSCRIPT_2025_Q2_u_0000", "META_TRANSCRIPT_2025_Q2_u_0001", "META_TRANSCRIPT_2025_Q2_u_0002", "META_TRANSCRIPT_2025_Q2_u_0003", "META_TRANSCRIPT_2025_Q2_u_0004", "META_TRANSCRIPT_2025_Q2_u_0005", "META_TRANSCRIPT_2025_Q2_u_0006", "META_TRANSCRIPT_2025_Q2_u_0007", "META_TRANSCRIPT_2025_Q2_u_0008", "META_TRANSCRIPT_2025_Q2_u_0009", "META_TRANSCRIPT_2025_Q2_u_0010", "META_TRANSCRIPT_2025_Q2_u_0011", "META_TRANSCRIPT_2025_Q2_u_0012", "META_TRANSCRIPT_2025_Q2_u_0013", "META_TRANSCRIPT_2025_Q2_u_0014"], "source_uri": "data/earnings_calls_manual/META/META_FY2025_Q2.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Mark Elliot Zuckerberg", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 522, "start_token": 1360, "end_token": 1882, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 0, "text": " in terms of the research agenda and a bunch of the areas that we're very focused on, I do think focusing on self- improvement is a very\nimportant area of research. And there's obviously different scaling paradigms, and I don't want to get too much into the detail of research that we're doing on this.\nBut I think that for developing superintelligence, at some level, you're not just going to be learning from people because you're trying to build something that is\nfundamentally smarter than people. So it's going to need to learn how to -- or you're going to need to develop a way for it to be able to improve itself. So that, I\nthink, is a very fundamental thing. That is going to have a very broad implications for how we build products, how we run the company, new things that we can\ninvent, new discoveries that can be made, society more broadly. I think that that's just a very fundamental part of this. In terms of the shape of the effort overall, I\nguess I've just gotten a little bit more convinced around the ability for small talent-dense teams to be the optimal configuration for driving frontier research. And it's\na bit of a different setup than we have on our other world- class machine learning system. So if you look at like what we do in Instagram or Facebook or our ad\nsystem, we can very productively have many hundreds or thousands of people basically working on improving those systems, and we have very well-developed\nsystems for kind of individuals to run tests and be able to test a bunch of different things. You don't need every researcher there to have the whole system in their\nhead. But I think for this -- for the leading research on superintelligence, you really want the smallest group that can hold the whole thing in their head, which\ndrives, I think, some of the physics around the team size and how -- and the dynamics around how that works. But I'll hand it over to Susan to talk about more of\nthe practical stuff.\nSusan J. S. Li\nBrian, on the sort of forward-looking road map for the core recommendation engine. There are a handful of shorter-term things that we're focused on in the near \nterm. One is we're focused on making recommendations even more adaptive to what a person is engaging with during their session so that the recommendations \nwe surface are the most relevant to what they're interested in at that moment. And we're making optimizations to help the best content from smaller creators", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2025_Q2_chunk_0012", "doc_id": "META_TRANSCRIPT_2025_Q2", "source_units": ["META_TRANSCRIPT_2025_Q2_u_0000", "META_TRANSCRIPT_2025_Q2_u_0001", "META_TRANSCRIPT_2025_Q2_u_0002", "META_TRANSCRIPT_2025_Q2_u_0003", "META_TRANSCRIPT_2025_Q2_u_0004", "META_TRANSCRIPT_2025_Q2_u_0005", "META_TRANSCRIPT_2025_Q2_u_0006", "META_TRANSCRIPT_2025_Q2_u_0007", "META_TRANSCRIPT_2025_Q2_u_0008", "META_TRANSCRIPT_2025_Q2_u_0009", "META_TRANSCRIPT_2025_Q2_u_0010", "META_TRANSCRIPT_2025_Q2_u_0011", "META_TRANSCRIPT_2025_Q2_u_0012", "META_TRANSCRIPT_2025_Q2_u_0013", "META_TRANSCRIPT_2025_Q2_u_0014"], "source_uri": "data/earnings_calls_manual/META/META_FY2025_Q2.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Mark Elliot Zuckerberg", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 800, "start_token": 0, "end_token": 800, "chunk_type": "windowed_overlap", "overlap_with_prev": 0, "overlap_with_next": 120, "text": "break-out by matching it to the right audiences sooner after it gets posted. And we're also working on improving the ability for our systems to discover more\ndiversified and niche interest for each person through interest exploration and learning explicit user preferences. We're also planning to scale up our models\nfurther and incorporate more advanced techniques that should improve the overall quality of recommendations. But we also have a lot of long-term bets in the\nhopper around areas like developing foundational models that will support recommendations across multiple services. Incorporating LLMs more deeply into our\nrecommendation systems. And a big focus of this work is going to be on optimizing the systems to make them more efficient. So that we can continue to scale up\nthe capacity that we use for our recommendation systems without eroding the ROI that we deliver.\nOperator\nYour next question comes from the line of Doug Anmuth with JPMorgan. One for Mark and one for Susan. Mark, Meta has been a huge proponent of open source AI, has your thinking changed here at all, just as you pursue\nsuperintelligence and push for even greater returns on your significant infrastructure investments? And then, Susan, your comments on '26 CapEx suggest more\nthan $100 billion of spend next year potentially. Do you continue to expect to finance all this yourself? Or could there be opportunities to partner here? Yes. I mean on open source, I don't think that our thinking has particularly changed on this. We've always open sourced some of our models and not open\nsourced everything that we've done. So I would expect that we will continue to produce and share leading open source models. I also think that there are a couple\nof trends that are playing out. One is that we're getting models that are so big that they're just not practical for a lot of other people to use. So it's -- we would kind\nof wrestle with whether it's productive or helpful to share that or if that's really just primarily helping competitors or something like that. So I think that there's that\nconcern. And then obviously, as you approach real superintelligence, I think there is a whole different set of safety concerns that I think we need to take very\nseriously, that I wrote about in my note this morning. But I think the bottom line is, I would expect that we will continue open sourcing work. I expect us to continue\nto be a leader there. And I also expect us to continue to not open source everything that we do, which is a continuation of kind of what we've been kind of working\non. And yes, I mean, I think Susan will talk a little bit more about the infrastructure, but it really is a massive investment. We think it will be good over time. But we\ndo take very seriously that this is a just massive amount of capital to convert into many gigawatts of compute which we think is going to help us produce leading\nresearch and quality products and in running the business, I do look for opportunities to basically convert capital into quality of products that we can deliver for\npeople. But this is certainly a massive bet that we're kind of -- we're focused on, and we want to make sure that what we build accrues to building the best\nproducts that we can deliver to the billions of people who use our services.\nSusan J. S. Li\nDoug, on your second question about how we expect to finance the growing CapEx next year. We certainly expect that we will finance some large share of that\nourselves, but we're also exploring ways to work with financial partners to co-develop data centers. We don't have any finalized transactions to announce, but we\ngenerally believe that there will be models here that will attract significant external financing to support large-scale data center projects that are developed using\nour ability to build world-class infrastructure while providing us with flexibility should our", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2025_Q2_chunk_0013", "doc_id": "META_TRANSCRIPT_2025_Q2", "source_units": ["META_TRANSCRIPT_2025_Q2_u_0000", "META_TRANSCRIPT_2025_Q2_u_0001", "META_TRANSCRIPT_2025_Q2_u_0002", "META_TRANSCRIPT_2025_Q2_u_0003", "META_TRANSCRIPT_2025_Q2_u_0004", "META_TRANSCRIPT_2025_Q2_u_0005", "META_TRANSCRIPT_2025_Q2_u_0006", "META_TRANSCRIPT_2025_Q2_u_0007", "META_TRANSCRIPT_2025_Q2_u_0008", "META_TRANSCRIPT_2025_Q2_u_0009", "META_TRANSCRIPT_2025_Q2_u_0010", "META_TRANSCRIPT_2025_Q2_u_0011", "META_TRANSCRIPT_2025_Q2_u_0012", "META_TRANSCRIPT_2025_Q2_u_0013", "META_TRANSCRIPT_2025_Q2_u_0014"], "source_uri": "data/earnings_calls_manual/META/META_FY2025_Q2.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Mark Elliot Zuckerberg", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 800, "start_token": 680, "end_token": 1480, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 120, "text": " of people who use our services.\nSusan J. S. Li\nDoug, on your second question about how we expect to finance the growing CapEx next year. We certainly expect that we will finance some large share of that\nourselves, but we're also exploring ways to work with financial partners to co-develop data centers. We don't have any finalized transactions to announce, but we\ngenerally believe that there will be models here that will attract significant external financing to support large-scale data center projects that are developed using\nour ability to build world-class infrastructure while providing us with flexibility should our infrastructure requirements change over time. So we are exploring many\ndifferent paths.\nOperator\nYour next question comes from the line of Justin Post with Bank of America. I'll ask another one on infrastructure. Mark, your spend is now approaching some of the biggest hyperscalers out there. Do you think of all this capacity mostly for\ninternal uses? Or do you think there's a way to share or even come up with a business model where leveraging that capacity for external uses? And then Susan,\nwhen you think about the ROI on this CapEx, I'm sure you have internal models, I'm sure you can't share all that, but how are you thinking about the ROI? And\nare you optimistic about the long-term returns?\nSusan J. S. Li\nJustin, I can go ahead and take a crack at both of those. And obviously, Mark, you should feel free to weigh in. Right now, we are focused on ensuring that we\nhave enough capacity for our internal use cases, which includes both all of the core AI work that we do to support the recommendation engine work on the\norganic content side to support all the ads ranking and recommendation work. And then, of course, to make sure that we are building the training capacity that we\nthink we need in order to build frontier AI models. And to make sure that we're preparing ourselves for the types of inference use cases that we think might -- that\nwe might have ahead of us as we eventually focus not only on developing frontier models, but also how we can expand into the kinds of consumer use cases that\nwe think will be hopefully widely useful and engaging for our users. So at present, we're not really thinking about external use cases on the infrastructure, but it's a\ngood question. On your second question, which is really around the sort of ROI on CapEx, there are a couple of things. So again, on the core AI side, we continue\nto see strong ROI. Our ability to measure that is quite good, and we feel sort of very good about the rigorous measurement and returns that we see there. On the\ngenAI side, we are clearly much, much earlier on the return curve and we don't expect that the genAI work is going to be a meaningful driver of revenue this year\nor next year. But we remain generally very optimistic about the monetization opportunities that will open up, and Mark spoke to them in his script, the sort of five\npillars, so I won't repeat them here. And we think that over the medium- to long-term time frame, those are opportunities that are very adjacent and intuitive for\nwhere -- in terms of where our business is today, why they would be big opportunities for us and that there will be sort of big markets attached to each of them. So\nwe, again, are also, I would say -- the last thing I would add here is we are building the infrastructure with fungibility in mind. Obviously, there are a lot of things\nthat you have to build up front in terms of the data center shells, the networking infrastructure, et cetera. But we will be ordering servers, which ultimately will be\nthe biggest bulk of CapEx spend as we need them and when we need them and making sort of the best decisions at those times in terms of figuring", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2025_Q2_chunk_0014", "doc_id": "META_TRANSCRIPT_2025_Q2", "source_units": ["META_TRANSCRIPT_2025_Q2_u_0000", "META_TRANSCRIPT_2025_Q2_u_0001", "META_TRANSCRIPT_2025_Q2_u_0002", "META_TRANSCRIPT_2025_Q2_u_0003", "META_TRANSCRIPT_2025_Q2_u_0004", "META_TRANSCRIPT_2025_Q2_u_0005", "META_TRANSCRIPT_2025_Q2_u_0006", "META_TRANSCRIPT_2025_Q2_u_0007", "META_TRANSCRIPT_2025_Q2_u_0008", "META_TRANSCRIPT_2025_Q2_u_0009", "META_TRANSCRIPT_2025_Q2_u_0010", "META_TRANSCRIPT_2025_Q2_u_0011", "META_TRANSCRIPT_2025_Q2_u_0012", "META_TRANSCRIPT_2025_Q2_u_0013", "META_TRANSCRIPT_2025_Q2_u_0014"], "source_uri": "data/earnings_calls_manual/META/META_FY2025_Q2.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Mark Elliot Zuckerberg", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 131, "start_token": 1360, "end_token": 1491, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 0, "text": " there will be sort of big markets attached to each of them. So\nwe, again, are also, I would say -- the last thing I would add here is we are building the infrastructure with fungibility in mind. Obviously, there are a lot of things\nthat you have to build up front in terms of the data center shells, the networking infrastructure, et cetera. But we will be ordering servers, which ultimately will be\nthe biggest bulk of CapEx spend as we need them and when we need them and making sort of the best decisions at those times in terms of figuring out where\nthe capacity will go to use.\nOperator", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2025_Q2_chunk_0015", "doc_id": "META_TRANSCRIPT_2025_Q2", "source_units": ["META_TRANSCRIPT_2025_Q2_u_0000", "META_TRANSCRIPT_2025_Q2_u_0001", "META_TRANSCRIPT_2025_Q2_u_0002", "META_TRANSCRIPT_2025_Q2_u_0003", "META_TRANSCRIPT_2025_Q2_u_0004", "META_TRANSCRIPT_2025_Q2_u_0005", "META_TRANSCRIPT_2025_Q2_u_0006", "META_TRANSCRIPT_2025_Q2_u_0007", "META_TRANSCRIPT_2025_Q2_u_0008", "META_TRANSCRIPT_2025_Q2_u_0009", "META_TRANSCRIPT_2025_Q2_u_0010", "META_TRANSCRIPT_2025_Q2_u_0011", "META_TRANSCRIPT_2025_Q2_u_0012", "META_TRANSCRIPT_2025_Q2_u_0013", "META_TRANSCRIPT_2025_Q2_u_0014"], "source_uri": "data/earnings_calls_manual/META/META_FY2025_Q2.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Mark Elliot Zuckerberg", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 800, "start_token": 0, "end_token": 800, "chunk_type": "windowed_overlap", "overlap_with_prev": 0, "overlap_with_next": 120, "text": "Your next question comes from the line of Mark Shmulik with Bernstein. Mark, as you go after the superintelligence vision, especially for those of us on the outside, what are kind of some of the markers or KPIs that you're tracking on\nwhether you're on track and making progress? Is it really against kind of those five pillars you outlined above? Or should we be thinking more broadly? And\nSusan, obviously AI delivering great ROI today, all those investments and also building towards kind of longer-term goals, just curious, has there just been any\nchange or adjustment to how you think about the relationship between revenues or core business performance and the cadence of investment? Yes, in terms of what to look at, I mean, what I'm going to look at internally, the quality of the people on the teams, the quality of the models that we're producing,\nthe rate of improvement of our other AI systems across the company and the extent to which the leading kind of foundation models that we're building contribute\nto improving all of the other AI systems and kind of everything that we're doing around the company. Then I think you just get into our standard product and\nbusiness playbook, which is translating that technology into new products, which will first scale to billions of people and then over time, we will monetize. But I\nthink that there's going to be some lag in that, right? And that, I think, is kind of always the way that we work is, whether we're building some new social product or\nthis, something like Meta AI or a new product around this, we're going to work on getting to leading scale, building the highest quality product, focused on that for\na few years. And then once we're really confident in that position, then we'll focus on ramping up the business around it. So it's -- I mean, going back to the last\nquestion a little bit, it's sort of when you compare this business to some of the cloud businesses, it's like we do have this delay where we focus on building\nresearch and then doing research and then ramping consumer products, and it often does take some period of time before we really are ramping up the business\naround it. I think that's kind of a known property of our business and the cycle around it. But I guess, on the flip side, we believe that if you are building\nsuperintelligence, you should use all of your GPUs to make it so that you're serving your customers really well with that. And we think that there's going to be a\nmuch higher return than we can do by generating that directly rather than just kind of renting or leasing out the infrastructure at other companies.\nSusan J. S. Li\nOn the second part of your question, we've said in the past that our primary focus from a profitability perspective is driving consolidated operating profit growth\nover time. And it won't be linear. In some years, we'll deliver above-average profit growth. And in years where we're making big investments, I think we will see\nthat impact the amount of operating profit growth that we can deliver. And at the moment, we see a lot of attractive investment opportunities that we believe are\ngoing to set us up to deliver compelling profit growth in the coming years for all of our investors. And so we're focused on constraining investments elsewhere as\nwe pursue those investments. But we really believe that this is a time for us to really make investments in the future of AI as I think it will open up both new\nopportunities for us in addition to strengthen our core business.\nOperator\nYour next question comes from the line of Ron Josey with Citi. Mark, I wanted to ask you on Meta AI, and I think you talked about in the call just growing engagement overall, particularly on WhatsApp. And now we have 1\nbillion users on the", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2025_Q2_chunk_0016", "doc_id": "META_TRANSCRIPT_2025_Q2", "source_units": ["META_TRANSCRIPT_2025_Q2_u_0000", "META_TRANSCRIPT_2025_Q2_u_0001", "META_TRANSCRIPT_2025_Q2_u_0002", "META_TRANSCRIPT_2025_Q2_u_0003", "META_TRANSCRIPT_2025_Q2_u_0004", "META_TRANSCRIPT_2025_Q2_u_0005", "META_TRANSCRIPT_2025_Q2_u_0006", "META_TRANSCRIPT_2025_Q2_u_0007", "META_TRANSCRIPT_2025_Q2_u_0008", "META_TRANSCRIPT_2025_Q2_u_0009", "META_TRANSCRIPT_2025_Q2_u_0010", "META_TRANSCRIPT_2025_Q2_u_0011", "META_TRANSCRIPT_2025_Q2_u_0012", "META_TRANSCRIPT_2025_Q2_u_0013", "META_TRANSCRIPT_2025_Q2_u_0014"], "source_uri": "data/earnings_calls_manual/META/META_FY2025_Q2.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Mark Elliot Zuckerberg", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 800, "start_token": 680, "end_token": 1480, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 120, "text": " investors. And so we're focused on constraining investments elsewhere as\nwe pursue those investments. But we really believe that this is a time for us to really make investments in the future of AI as I think it will open up both new\nopportunities for us in addition to strengthen our core business.\nOperator\nYour next question comes from the line of Ron Josey with Citi. Mark, I wanted to ask you on Meta AI, and I think you talked about in the call just growing engagement overall, particularly on WhatsApp. And now we have 1\nbillion users on the platform and the focus is now on driving personalization. So I want to understand a little bit more how these next-gen models can help drive\nadoption here, particularly with Behemoth coming online at some point. And then as people are using that Meta AI with WhatsApp, thoughts on search and\nqueries and potentially monetizing that. Yes, I'm not going to get super deep into the road map on this, but the basic -- we do see that as we continue improving the models behind Meta AI and post\ntraining and just engagement increases and as we swap in the updated models, when we go from Llama 4 to Llama 4.1 when we have that, we expect that just --\nthe models are inherently pretty general. So it's -- yes, you focus on specific areas, but in general, it just sort of gets better at a lot of different things that people\nwant to ask it or want to do with it. And I think with each version, both like what we're doing on a week-to-week basis in terms of continuing to train it, and when\nwe drop kind of new generations or big dot releases of each generation, that will improve engagement, too. So we're focused on that. I'm not going to go into the\nspecific research areas or capabilities that we're planning on dropping in the future. But obviously, I'm pretty excited about it.\nOperator\nThe last question comes from the line of use of Youssef Squali with Truist Securities. I have two. So Mark, the Ray-Ban initiative has been a [ hallmark ] for you guys so far. Where are we on the development of glasses? And has that new\ncomputational platform that you've talked about in the past, is it moving faster or slower than you thought? And as you leverage Meta AI, do you believe glasses\nultimately replace smartphones? Or do you need the new form factor that's AI first? And then, Susan, just quickly, how do you guys see SBC progressing over the\nnext couple of years? Is it fair to assume it will grow materially faster than the revenue and OpEx? And how do you minimize shareholder dilution? Yes, I can talk a bit about the glasses. Yes, I mean, I'm very excited about the progress that we're making. I think both the Ray-Ban Metas and I'm very excited \nabout the Oakley Meta, the HSTNs too. And other things that we have planned. Yes, I mean, this product category is clearly doing quite well. And I think it's good \nfor a lot of things. It is stylish eyewear, so people like wearing them just as glasses. It has a bunch of interesting functionality. And then the use of Meta AI in them \njust continues to grow, and the percent of people who are using it for that on a daily basis is increasing, and that's all good to see. I mean, I continue to think that \nglasses are basically going to be the ideal form factor for AI because you can let an AI see what you see throughout the day, hear what you hear, talk to you. \nOnce you get a display in there, whether it's the kind of wide holographic field of view like we showed with Orion or just a smaller display that might", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2025_Q2_chunk_0017", "doc_id": "META_TRANSCRIPT_2025_Q2", "source_units": ["META_TRANSCRIPT_2025_Q2_u_0000", "META_TRANSCRIPT_2025_Q2_u_0001", "META_TRANSCRIPT_2025_Q2_u_0002", "META_TRANSCRIPT_2025_Q2_u_0003", "META_TRANSCRIPT_2025_Q2_u_0004", "META_TRANSCRIPT_2025_Q2_u_0005", "META_TRANSCRIPT_2025_Q2_u_0006", "META_TRANSCRIPT_2025_Q2_u_0007", "META_TRANSCRIPT_2025_Q2_u_0008", "META_TRANSCRIPT_2025_Q2_u_0009", "META_TRANSCRIPT_2025_Q2_u_0010", "META_TRANSCRIPT_2025_Q2_u_0011", "META_TRANSCRIPT_2025_Q2_u_0012", "META_TRANSCRIPT_2025_Q2_u_0013", "META_TRANSCRIPT_2025_Q2_u_0014"], "source_uri": "data/earnings_calls_manual/META/META_FY2025_Q2.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Mark Elliot Zuckerberg", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 123, "start_token": 1360, "end_token": 1483, "chunk_type": "windowed_overlap", "overlap_with_prev": 120, "overlap_with_next": 0, "text": ". And then the use of Meta AI in them \njust continues to grow, and the percent of people who are using it for that on a daily basis is increasing, and that's all good to see. I mean, I continue to think that \nglasses are basically going to be the ideal form factor for AI because you can let an AI see what you see throughout the day, hear what you hear, talk to you. \nOnce you get a display in there, whether it's the kind of wide holographic field of view like we showed with Orion or just a smaller display that might be good for", "chunked_at": "2025-11-10T02:15:59Z"}
{"chunk_id": "META_TRANSCRIPT_2025_Q2_chunk_0018", "doc_id": "META_TRANSCRIPT_2025_Q2", "source_units": ["META_TRANSCRIPT_2025_Q2_u_0000", "META_TRANSCRIPT_2025_Q2_u_0001", "META_TRANSCRIPT_2025_Q2_u_0002", "META_TRANSCRIPT_2025_Q2_u_0003", "META_TRANSCRIPT_2025_Q2_u_0004", "META_TRANSCRIPT_2025_Q2_u_0005", "META_TRANSCRIPT_2025_Q2_u_0006", "META_TRANSCRIPT_2025_Q2_u_0007", "META_TRANSCRIPT_2025_Q2_u_0008", "META_TRANSCRIPT_2025_Q2_u_0009", "META_TRANSCRIPT_2025_Q2_u_0010", "META_TRANSCRIPT_2025_Q2_u_0011", "META_TRANSCRIPT_2025_Q2_u_0012", "META_TRANSCRIPT_2025_Q2_u_0013", "META_TRANSCRIPT_2025_Q2_u_0014"], "source_uri": "data/earnings_calls_manual/META/META_FY2025_Q2.pdf", "ticker": "META", "company": "META", "doc_type": "earnings_transcript", "fiscal_year": 2025, "quarter": "Q2", "period": "2025-Q2", "section_id": null, "section_title": null, "speaker": "Mark Elliot Zuckerberg", "speaker_role": "unknown", "phase": "prepared_remarks", "chunk_tokens": 792, "start_token": 0, "end_token": 0, "chunk_type": "prepared_packed", "overlap_with_prev": 0, "overlap_with_next": 0, "text": "displaying some information, and that's also going to unlock a lot of value where you can just interact with an AI system throughout the day in this multimodal\nway. It can see the content around you, it can generate a UI for you, show you information and be helpful. I mean, I personally think that just like if -- I wear\ncontact lenses, I feel like if I didn't have my vision corrected, I'd be sort of at a cognitive disadvantage going through the world. And I think in the future, if you\ndon't have glasses that have AI or some way to interact with AI, I think you're kind of similarly, probably be at a pretty significant cognitive disadvantage compared\nto other people and who you're working with, or competing against. So I think that this is a pretty fundamental form factor. There are a lot of different versions of it.\nRight now, we're building ones that I think are stylish, but aren't focused on the display. I think there's a whole set of different things to explore with displays. This\nis kind of what we've been maxing out with Reality Labs over the last 5 to 10 years is basically doing the research on all of these different things. And it's a -- I\ndon't know, 10 years ago, I would have -- like the other thing that's awesome about glasses is, they are going to be the ideal way to blend the physical and digital\nworlds together. So the whole metaverse vision, I think, is going to end up being extremely important, too, and AI is going to accelerate that, too. It -- just that if\nyou'd asked me 5 years ago, whether we'd have kind of holograms that created immersive experiences or superintelligence first, I think most people would have\nthought that you'd get the holograms first. And it's this interesting kind of quirk of the tech industry that I think we're going to end up having really strong AI first.\nBut because we've been investing in this, I think we're just several years ahead on building out glasses. And I think that that's something that we're excited to\nkeep on investing in heavily because I think it's going to be a really important part of the future.\nKenneth J. Dorell\nYoussef, we didn't quite get your second question, do you mind just repeating it? Sure. Just as you look at the spend on stock-based compensation over the next couple of years with all these hires, I'm assuming that we're going to see that\nmaterially -- or grow materially faster maybe than revenue and OpEx. And I just want to know how -- what you guys are doing to plan to minimize shareholder\ndilution. Is it mostly buybacks or anything else?\nSusan J. S. Li\nThanks, Youssef. So I mean, the impact of the sort of increased compensation costs, including SBC, of our AI hires this year is reflected in the revised 2025\nexpense outlook and in the -- the comments I made about sort of 2026 expense outlook. Those are obviously a big driver of 2026 expense growth as we\nrecognize the full year of compensation for the additional talent we're bringing on. Having said that, so we factored that into our sort of expense outlook. Having\nsaid that, we certainly -- we are very focused on making sure on keeping an eye on dilution. And we generally believe that our strong financial position is going to\nallow us to support these investments while continuing to repurchase shares as part of the sort of buyback program that offsets equity compensation and as well\nas provide quarterly cash dividend distributions to our investors.\nKenneth J. Dorell\nGreat. Thank you, everyone, for joining us today. We look forward to speaking with you again soon.", "chunked_at": "2025-11-10T02:15:59Z"}
