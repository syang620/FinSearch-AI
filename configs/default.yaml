# Default configuration for FinSearch-AI

data:
  raw_path: data/raw
  interim_path: data/interim
  processed_path: data/processed
  chunk_size: 512
  chunk_overlap: 128

embeddings:
  model: "BAAI/bge-small-en-v1.5"
  dimension: 384
  batch_size: 32

retrieval:
  use_hybrid: true
  dense_weight: 0.7
  sparse_weight: 0.3
  top_k: 20

reranking:
  enabled: true
  model: "cross-encoder/ms-marco-MiniLM-L-12-v2"
  top_k: 5

generation:
  model: "gpt-4"
  temperature: 0.1
  max_tokens: 1000

evaluation:
  metrics:
    - precision_at_k
    - recall_at_k
    - mrr
    - ndcg
  k_values: [1, 3, 5, 10, 20]

logging:
  level: INFO
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
